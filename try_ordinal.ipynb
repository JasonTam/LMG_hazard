{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/afs/ee.cooper.edu/user/t/a/tam8/documents/ml_misc/semi_supervised/')\n",
    "import coreg\n",
    "reload(coreg)\n",
    "import trireg\n",
    "reload(trireg)\n",
    "sys.path.append('/afs/ee.cooper.edu/user/t/a/tam8/documents/ml_misc/ordinal/')\n",
    "import simple\n",
    "reload(simple)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "\n",
    "import transformers as tforms\n",
    "reload(tforms)\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion, make_union\n",
    "\n",
    "import metrics\n",
    "reload(metrics)\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC, SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, ElasticNet, Ridge, Lasso, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import Counter\n",
    "import minirank as mr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "\n",
    "def wgmean(x, w):\n",
    "    return np.exp(np.sum(w*np.log(x), axis=1) / np.sum(w, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import cPickle as pickle\n",
    "train_pd  = pd.read_pickle('saved/train_pd_enc.p')\n",
    "test_pd  = pd.read_pickle('saved/test_pd_enc.p')\n",
    "labels = pd.read_pickle('saved/labels.p')\n",
    "test_ind = pickle.load(open('saved/test_ind.p'))\n",
    "y_binned = np.load('saved/y_binned.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50999,)\n",
      "(50999, 111)\n",
      "(51000, 111)\n",
      "50\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "train = np.array(train_pd)\n",
    "test = np.array(test_pd)\n",
    "\n",
    "X_train = train.astype(float)\n",
    "X_test = test.astype(float)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "pipe_x = make_pipeline(\n",
    "    make_union(\n",
    "        tforms.IdentityTformer(),\n",
    "#         make_pipeline(AddTformer(1), BoxCoxTformer()),\n",
    "#         AnscombeTformer(),\n",
    "    ),\n",
    "    StandardScaler(),\n",
    ")\n",
    "pipe_y = make_pipeline(\n",
    "#     tforms.IdentityTformer(),\n",
    "#     tforms.BoxCoxTformer(),\n",
    "#     tforms.LogTfortforms.mer(),\n",
    "#     tforms.AnscombeTformer(),\n",
    "#     tforms.FreemanTukeyTformer(),\n",
    "#     tforms.ArcsinhTformer(),\n",
    "    StandardScaler(),\n",
    "    \n",
    ")\n",
    "pipe_x.fit(np.r_[X_train, X_test])\n",
    "\n",
    "\n",
    "X_train = pipe_x.transform(X_train)\n",
    "X_test = pipe_x.transform(X_test)\n",
    "# y_train = pipe_y.fit_transform(y_train)\n",
    "\n",
    "# small_n = 5000\n",
    "# X_train = X_train[:small_n,:]\n",
    "# y_train = y_train[:small_n]\n",
    "# y_binned = y_binned[:small_n]\n",
    "\n",
    "print y_train.shape\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print len(np.unique(y_train))\n",
    "print len(np.unique(y_binned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  4  1  1  1  1  5  1  1  1  7 15  1  4 14  1  1  1  4  1  4  4  8 16  5\n",
      "  1  6  7  1  1  1  7  5  1  6  4  1  1  8  1  1  4  7  5  1  4  4  4  1  1]\n",
      "[1 3 1 1 1 1 3 1 1 1 4 5 1 3 5 1 1 1 3 1 3 3 4 5 3 1 3 4 1 1 1 4 3 1 3 3 1\n",
      " 1 4 1 1 3 4 3 1 3 3 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "print y_train[:50]\n",
    "print y_binned[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 580\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, MaxoutDense, Reshape\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adadelta, Adagrad, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "losses = []\n",
    "from keras.callbacks import Callback\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        pass\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('val_loss'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# binary classification model\n",
    "model = Sequential()\n",
    "\n",
    "hidden_size = 256\n",
    "\n",
    "model.add(Dense(111, hidden_size))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(PReLU(hidden_size))\n",
    "model.add(MaxoutDense(hidden_size, hidden_size, 2))\n",
    "model.add(BatchNormalization(hidden_size))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(hidden_size, hidden_size))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(PReLU(hidden_size))\n",
    "model.add(MaxoutDense(hidden_size, hidden_size, 2))\n",
    "model.add(BatchNormalization(hidden_size))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(hidden_size, hidden_size))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(PReLU(hidden_size))\n",
    "model.add(MaxoutDense(hidden_size, hidden_size, 2))\n",
    "model.add(BatchNormalization(hidden_size))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(hidden_size, 2))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', \n",
    "#               optimizer='rmsprop', \n",
    "#               class_mode='binary')\n",
    "# model.save_weights('saved/nn_weights', overwrite=True)\n",
    "\n",
    "nn_params = {'model': model,\n",
    "             'optimizer': 'rmsprop',\n",
    "             'loss': 'binary_crossentropy'}\n",
    "clf_nn = KerasClassifier(**nn_params)\n",
    "\n",
    "label_bin_tform = lambda y: np_utils.to_categorical(y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 0 Train time: 0.250 s\tPred time: 0.269 s\tScore [0.3143241579939952]\n",
      "Score avg ensemble 0.314324157994\n",
      "Fold 1 Train time: 0.211 s\tPred time: 0.266 s\tScore [0.3332024658469817]\n",
      "Score avg ensemble 0.333202465847\n",
      "Fold 2 Train time: 0.220 s\tPred time: 0.265 s\tScore [0.33503433745908395]\n",
      "Score avg ensemble 0.335034337459\n",
      "done\n",
      "Score: [ 0.32752032]\n",
      "Base Score: 0.327520320433\n",
      "lol [] nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.XGBRegressor(\n",
    "    objective=\"reg:linear\",\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.01,\n",
    "#     gamma=0.0,\n",
    "    max_depth=8,\n",
    "    min_child_weight=5,\n",
    "#     max_delta_step=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "#     scale_pos_weight=1.0,\n",
    "    base_score=0.5,\n",
    "    nthread=7,\n",
    "    seed=np.random.randint(0,100),\n",
    "    silent=True,\n",
    ")\n",
    "\n",
    "gbm_bin = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "#     gamma=0.0,\n",
    "    max_depth=8,\n",
    "    min_child_weight=5,\n",
    "#     max_delta_step=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "#     scale_pos_weight=1.0,\n",
    "    base_score=0.5,\n",
    "    nthread=8,\n",
    "    seed=np.random.randint(0,100),\n",
    "    silent=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# clf0 = simple.SimpleOrdinalClassifier(gbm_bin, n_jobs=1)\n",
    "# clf0 = simple.SimpleOrdinalClassifier(GaussianNB(), n_jobs=1)\n",
    "# clf0 = simple.SimpleOrdinalClassifier(base_estimator_type=GaussianNB, base_estimator_params={}, n_jobs=1)\n",
    "# clf0 = simple.SimpleOrdinalClassifier(SVC(probability=True), n_jobs=8)\n",
    "# clf0 = simple.SimpleOrdinalClassifier(clf_nn, n_jobs=1)\n",
    "clf0 = simple.SimpleOrdinalClassifier(base_estimator_type=KerasClassifier,\n",
    "                                      base_estimator_params=nn_params,\n",
    "                                      label_transformer=label_bin_tform,\n",
    "                                      n_jobs=1)\n",
    "\n",
    "\n",
    "# clfs = [clf0, gbm]\n",
    "clfs = [LinearRegression()]\n",
    "# clfs = [clf1, clf2, ]\n",
    "\n",
    "\n",
    "# h = [clone(clf1), clone(clf2)]\n",
    "# clf = coreg.CoReg(h=h, T=5, verbose=True, n_jobs=1)\n",
    "\n",
    "scores = []\n",
    "scores_base = []\n",
    "lols = []\n",
    "n_reps = 1\n",
    "k = 3\n",
    "for reps in range(n_reps):\n",
    "    skf = StratifiedKFold(y_train, n_folds=k,\n",
    "                          shuffle=True,\n",
    "                          random_state=np.random.randint(0,100))\n",
    "    for ii, (train, valid) in enumerate(skf):\n",
    "        \n",
    "        \n",
    "#         history = LossHistory()   # for keras\n",
    "        print 'Fold %d' % ii,\n",
    "        X_train_k = X_train[train]\n",
    "        X_valid_k = X_train[valid]\n",
    "        y_train_k = y_train[train]\n",
    "        y_valid_k = y_train[valid]\n",
    "        y_train_binned_k = y_binned[train]\n",
    "        y_valid_binned_k = y_binned[valid]     \n",
    "        \n",
    "        \n",
    "        X_all = np.r_[X_train_k, X_valid_k]\n",
    "        y_all = np.r_[y_train_k, np.nan*np.ones(len(y_valid_k))]\n",
    "        \n",
    "        tic = time()\n",
    "#         clf.fit(X_train_k, y_train_k)\n",
    "#         clf.fit(X_all, y_all)\n",
    "        \n",
    "        for clf in clfs:\n",
    "#             clf.fit(X_train_k, y_train_k)\n",
    "#             clf.fit(X_train_k, y_train_binned_k)\n",
    "            clf.fit(X_train_k, y_train_binned_k,\n",
    "                   nb_epoch=60, batch_size=1024*16, )\n",
    "    \n",
    "    \n",
    "        \n",
    "        # Minirank\n",
    "#         w, theta = mr.ordinal_logistic_fit(X_train_k, y_train_k, verbose=False,\n",
    "#                                 solver='TNC')\n",
    "\n",
    "        \n",
    "        toc = time() - tic\n",
    "        print 'Train time: %2.3f s\\t' % toc,\n",
    "        tic = time()\n",
    "\n",
    "        \n",
    "        \n",
    "#         valid_preds = [clf.predict_weighted(X_valid_k,) \n",
    "#                        if hasattr(clf, 'predict_weighted') \n",
    "#                        else clf.predict(X_valid_k)\n",
    "#                        for clf in clfs]\n",
    "        \n",
    "        valid_preds = [clf.predict_weighted(X_valid_k, batch_size=1024*16) \n",
    "               if hasattr(clf, 'predict_weighted') \n",
    "               else clf.predict(X_valid_k)\n",
    "               for clf in clfs]\n",
    "        \n",
    "        try:\n",
    "            lol = metrics.normalized_gini(y_valid_k, \n",
    "                                          clfs[0].predict_weighted(X_valid_k, geometric=True))\n",
    "            lols.append(lol)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Minirank\n",
    "#         valid_preds = mr.ordinal_logistic_predict(w, theta, X_valid_k)\n",
    "        \n",
    "        valid_base_preds = np.mean([clf.predict(X_valid_k) for clf in clfs\n",
    "                                   ], \n",
    "                                   axis=0)\n",
    "\n",
    "        \n",
    "        score = [metrics.normalized_gini(y_valid_k, v) for v in valid_preds]\n",
    "        score_base = metrics.normalized_gini(y_valid_k, valid_base_preds)\n",
    "        \n",
    "        toc_pred = time() - tic\n",
    "        print 'Pred time: %2.3f s\\t' % toc_pred, \n",
    "        \n",
    "        print 'Score', score\n",
    "        print 'Score avg ensemble', score_base\n",
    "        scores.append(score)\n",
    "        scores_base.append(score_base)\n",
    "        \n",
    "#         break\n",
    "        \n",
    "        \n",
    "print \"done\"\n",
    "print 'Score:', np.array(scores).mean(axis=0)\n",
    "print 'Base Score:', np.array(scores_base).mean()\n",
    "print 'lol', lols, np.mean(lols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.267811596932\n",
      "0.293322383929\n"
     ]
    }
   ],
   "source": [
    "q = [500, 1000, 5000, 10000]\n",
    "t_train = [0.68, 1.9, 27, ]\n",
    "t_pred = [0.32, 1.25, 27, ]\n",
    "\n",
    "# gbm is ~ 0.381  @ 30 sec per fold?\n",
    "# gbm on binned labels ~ 0.378 @ 30 sec per fold... ~_~\n",
    "# ordinal nn binned is like 0.34 with stdscaling X 60 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print scores\n",
    "print scores_base\n",
    "print lol\n",
    "# print scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37712908899661984"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.normalized_gini(y_valid_k, clfs[0].predict_weighted(X_valid_k, geometric=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until val error hasn't decreased in 20 rounds.\n",
      "[0]\ttrain-rmse:5.307869\tval-rmse:5.343077\n",
      "[1]\ttrain-rmse:5.281321\tval-rmse:5.318596\n",
      "[2]\ttrain-rmse:5.255945\tval-rmse:5.294526\n",
      "[3]\ttrain-rmse:5.230171\tval-rmse:5.270779\n",
      "[4]\ttrain-rmse:5.204879\tval-rmse:5.247344\n",
      "[5]\ttrain-rmse:5.179912\tval-rmse:5.223663\n",
      "[6]\ttrain-rmse:5.155277\tval-rmse:5.201127\n",
      "[7]\ttrain-rmse:5.131289\tval-rmse:5.178530\n",
      "[8]\ttrain-rmse:5.106847\tval-rmse:5.155623\n",
      "[9]\ttrain-rmse:5.083262\tval-rmse:5.133870\n",
      "[10]\ttrain-rmse:5.060019\tval-rmse:5.112049\n",
      "[11]\ttrain-rmse:5.036912\tval-rmse:5.090539\n",
      "[12]\ttrain-rmse:5.014286\tval-rmse:5.069273\n",
      "[13]\ttrain-rmse:4.992133\tval-rmse:5.048791\n",
      "[14]\ttrain-rmse:4.970232\tval-rmse:5.028564\n",
      "[15]\ttrain-rmse:4.948495\tval-rmse:5.008514\n",
      "[16]\ttrain-rmse:4.926886\tval-rmse:4.988660\n",
      "[17]\ttrain-rmse:4.905847\tval-rmse:4.968964\n",
      "[18]\ttrain-rmse:4.885324\tval-rmse:4.950142\n",
      "[19]\ttrain-rmse:4.864790\tval-rmse:4.931548\n",
      "[20]\ttrain-rmse:4.844736\tval-rmse:4.913131\n",
      "[21]\ttrain-rmse:4.824436\tval-rmse:4.894755\n",
      "[22]\ttrain-rmse:4.804891\tval-rmse:4.876829\n",
      "[23]\ttrain-rmse:4.785651\tval-rmse:4.859264\n",
      "[24]\ttrain-rmse:4.766748\tval-rmse:4.841847\n",
      "[25]\ttrain-rmse:4.747534\tval-rmse:4.824380\n",
      "[26]\ttrain-rmse:4.729258\tval-rmse:4.807530\n",
      "[27]\ttrain-rmse:4.711006\tval-rmse:4.790677\n",
      "[28]\ttrain-rmse:4.693344\tval-rmse:4.774575\n",
      "[29]\ttrain-rmse:4.676068\tval-rmse:4.758445\n",
      "[30]\ttrain-rmse:4.658556\tval-rmse:4.742767\n",
      "[31]\ttrain-rmse:4.641462\tval-rmse:4.727221\n",
      "[32]\ttrain-rmse:4.624254\tval-rmse:4.711662\n",
      "[33]\ttrain-rmse:4.607634\tval-rmse:4.696906\n",
      "[34]\ttrain-rmse:4.591357\tval-rmse:4.682038\n",
      "[35]\ttrain-rmse:4.575218\tval-rmse:4.667524\n",
      "[36]\ttrain-rmse:4.558876\tval-rmse:4.653050\n",
      "[37]\ttrain-rmse:4.543152\tval-rmse:4.639037\n",
      "[38]\ttrain-rmse:4.527828\tval-rmse:4.625430\n",
      "[39]\ttrain-rmse:4.512540\tval-rmse:4.611552\n",
      "[40]\ttrain-rmse:4.497216\tval-rmse:4.597854\n",
      "[41]\ttrain-rmse:4.482461\tval-rmse:4.584805\n",
      "[42]\ttrain-rmse:4.467847\tval-rmse:4.571914\n",
      "[43]\ttrain-rmse:4.453568\tval-rmse:4.559201\n",
      "[44]\ttrain-rmse:4.439602\tval-rmse:4.546682\n",
      "[45]\ttrain-rmse:4.425851\tval-rmse:4.534162\n",
      "[46]\ttrain-rmse:4.412116\tval-rmse:4.522023\n",
      "[47]\ttrain-rmse:4.397965\tval-rmse:4.509600\n",
      "[48]\ttrain-rmse:4.384781\tval-rmse:4.497926\n",
      "[49]\ttrain-rmse:4.371819\tval-rmse:4.486414\n",
      "[50]\ttrain-rmse:4.358352\tval-rmse:4.474885\n",
      "[51]\ttrain-rmse:4.345748\tval-rmse:4.463623\n",
      "[52]\ttrain-rmse:4.333182\tval-rmse:4.452551\n",
      "[53]\ttrain-rmse:4.321092\tval-rmse:4.441903\n",
      "[54]\ttrain-rmse:4.308636\tval-rmse:4.431278\n",
      "[55]\ttrain-rmse:4.296546\tval-rmse:4.421048\n",
      "[56]\ttrain-rmse:4.284906\tval-rmse:4.411060\n",
      "[57]\ttrain-rmse:4.273143\tval-rmse:4.400913\n",
      "[58]\ttrain-rmse:4.261837\tval-rmse:4.390986\n",
      "[59]\ttrain-rmse:4.250501\tval-rmse:4.380999\n",
      "[60]\ttrain-rmse:4.239527\tval-rmse:4.371633\n",
      "[61]\ttrain-rmse:4.228522\tval-rmse:4.361990\n",
      "[62]\ttrain-rmse:4.217688\tval-rmse:4.352844\n",
      "[63]\ttrain-rmse:4.206760\tval-rmse:4.343695\n",
      "[64]\ttrain-rmse:4.196308\tval-rmse:4.335100\n",
      "[65]\ttrain-rmse:4.185697\tval-rmse:4.326276\n",
      "[66]\ttrain-rmse:4.175061\tval-rmse:4.317665\n",
      "[67]\ttrain-rmse:4.164824\tval-rmse:4.309113\n",
      "[68]\ttrain-rmse:4.154792\tval-rmse:4.300454\n",
      "[69]\ttrain-rmse:4.144782\tval-rmse:4.292202\n",
      "[70]\ttrain-rmse:4.135098\tval-rmse:4.284051\n",
      "[71]\ttrain-rmse:4.125657\tval-rmse:4.275906\n",
      "[72]\ttrain-rmse:4.115846\tval-rmse:4.268247\n",
      "[73]\ttrain-rmse:4.106532\tval-rmse:4.260499\n",
      "[74]\ttrain-rmse:4.096971\tval-rmse:4.253093\n",
      "[75]\ttrain-rmse:4.087845\tval-rmse:4.245746\n",
      "[76]\ttrain-rmse:4.079154\tval-rmse:4.238405\n",
      "[77]\ttrain-rmse:4.070279\tval-rmse:4.231310\n",
      "[78]\ttrain-rmse:4.062114\tval-rmse:4.224489\n",
      "[79]\ttrain-rmse:4.053614\tval-rmse:4.217627\n",
      "[80]\ttrain-rmse:4.045203\tval-rmse:4.210763\n",
      "[81]\ttrain-rmse:4.036523\tval-rmse:4.204068\n",
      "[82]\ttrain-rmse:4.028667\tval-rmse:4.197572\n",
      "[83]\ttrain-rmse:4.020732\tval-rmse:4.191040\n",
      "[84]\ttrain-rmse:4.013219\tval-rmse:4.184697\n",
      "[85]\ttrain-rmse:4.006016\tval-rmse:4.178577\n",
      "[86]\ttrain-rmse:3.998232\tval-rmse:4.172398\n",
      "[87]\ttrain-rmse:3.990741\tval-rmse:4.166438\n",
      "[88]\ttrain-rmse:3.983410\tval-rmse:4.160578\n",
      "[89]\ttrain-rmse:3.975942\tval-rmse:4.154686\n",
      "[90]\ttrain-rmse:3.968832\tval-rmse:4.149076\n",
      "[91]\ttrain-rmse:3.961534\tval-rmse:4.143114\n",
      "[92]\ttrain-rmse:3.954241\tval-rmse:4.137426\n",
      "[93]\ttrain-rmse:3.947130\tval-rmse:4.131823\n",
      "[94]\ttrain-rmse:3.940440\tval-rmse:4.126472\n",
      "[95]\ttrain-rmse:3.933786\tval-rmse:4.121117\n",
      "[96]\ttrain-rmse:3.927397\tval-rmse:4.115662\n",
      "[97]\ttrain-rmse:3.920834\tval-rmse:4.110525\n",
      "[98]\ttrain-rmse:3.914488\tval-rmse:4.105772\n",
      "[99]\ttrain-rmse:3.908108\tval-rmse:4.100756\n",
      "[100]\ttrain-rmse:3.901755\tval-rmse:4.095971\n",
      "[101]\ttrain-rmse:3.895748\tval-rmse:4.091106\n",
      "[102]\ttrain-rmse:3.889385\tval-rmse:4.086593\n",
      "[103]\ttrain-rmse:3.883515\tval-rmse:4.081917\n",
      "[104]\ttrain-rmse:3.877740\tval-rmse:4.077312\n",
      "[105]\ttrain-rmse:3.871722\tval-rmse:4.072911\n",
      "[106]\ttrain-rmse:3.865968\tval-rmse:4.068591\n",
      "[107]\ttrain-rmse:3.860115\tval-rmse:4.064291\n",
      "[108]\ttrain-rmse:3.854326\tval-rmse:4.060091\n",
      "[109]\ttrain-rmse:3.848628\tval-rmse:4.055937\n",
      "[110]\ttrain-rmse:3.843077\tval-rmse:4.051856\n",
      "[111]\ttrain-rmse:3.837362\tval-rmse:4.047800\n",
      "[112]\ttrain-rmse:3.832211\tval-rmse:4.043962\n",
      "[113]\ttrain-rmse:3.826887\tval-rmse:4.040118\n",
      "[114]\ttrain-rmse:3.821989\tval-rmse:4.036289\n",
      "[115]\ttrain-rmse:3.817095\tval-rmse:4.032615\n",
      "[116]\ttrain-rmse:3.811970\tval-rmse:4.028965\n",
      "[117]\ttrain-rmse:3.807372\tval-rmse:4.025530\n",
      "[118]\ttrain-rmse:3.802232\tval-rmse:4.021904\n",
      "[119]\ttrain-rmse:3.797522\tval-rmse:4.018677\n",
      "[120]\ttrain-rmse:3.793004\tval-rmse:4.015311\n",
      "[121]\ttrain-rmse:3.788291\tval-rmse:4.012204\n",
      "[122]\ttrain-rmse:3.783784\tval-rmse:4.008797\n",
      "[123]\ttrain-rmse:3.779211\tval-rmse:4.005577\n",
      "[124]\ttrain-rmse:3.774553\tval-rmse:4.002467\n",
      "[125]\ttrain-rmse:3.770131\tval-rmse:3.999237\n",
      "[126]\ttrain-rmse:3.765765\tval-rmse:3.996186\n",
      "[127]\ttrain-rmse:3.761670\tval-rmse:3.993280\n",
      "[128]\ttrain-rmse:3.757344\tval-rmse:3.990122\n",
      "[129]\ttrain-rmse:3.753129\tval-rmse:3.987094\n",
      "[130]\ttrain-rmse:3.748871\tval-rmse:3.984071\n",
      "[131]\ttrain-rmse:3.745009\tval-rmse:3.981468\n",
      "[132]\ttrain-rmse:3.740838\tval-rmse:3.978636\n",
      "[133]\ttrain-rmse:3.736802\tval-rmse:3.975910\n",
      "[134]\ttrain-rmse:3.732904\tval-rmse:3.973488\n",
      "[135]\ttrain-rmse:3.729122\tval-rmse:3.970866\n",
      "[136]\ttrain-rmse:3.725292\tval-rmse:3.968313\n",
      "[137]\ttrain-rmse:3.721323\tval-rmse:3.965752\n",
      "[138]\ttrain-rmse:3.717472\tval-rmse:3.963264\n",
      "[139]\ttrain-rmse:3.713821\tval-rmse:3.960693\n",
      "[140]\ttrain-rmse:3.710145\tval-rmse:3.958267\n",
      "[141]\ttrain-rmse:3.706320\tval-rmse:3.955963\n",
      "[142]\ttrain-rmse:3.702582\tval-rmse:3.953712\n",
      "[143]\ttrain-rmse:3.698740\tval-rmse:3.951447\n",
      "[144]\ttrain-rmse:3.695558\tval-rmse:3.949254\n",
      "[145]\ttrain-rmse:3.692350\tval-rmse:3.947230\n",
      "[146]\ttrain-rmse:3.689173\tval-rmse:3.945075\n",
      "[147]\ttrain-rmse:3.685827\tval-rmse:3.942932\n",
      "[148]\ttrain-rmse:3.682315\tval-rmse:3.940763\n",
      "[149]\ttrain-rmse:3.678918\tval-rmse:3.938715\n",
      "[150]\ttrain-rmse:3.675830\tval-rmse:3.936641\n",
      "[151]\ttrain-rmse:3.672426\tval-rmse:3.934719\n",
      "[152]\ttrain-rmse:3.669239\tval-rmse:3.932883\n",
      "[153]\ttrain-rmse:3.666117\tval-rmse:3.930835\n",
      "[154]\ttrain-rmse:3.663043\tval-rmse:3.928723\n",
      "[155]\ttrain-rmse:3.660281\tval-rmse:3.926831\n",
      "[156]\ttrain-rmse:3.657272\tval-rmse:3.925045\n",
      "[157]\ttrain-rmse:3.654447\tval-rmse:3.923220\n",
      "[158]\ttrain-rmse:3.651202\tval-rmse:3.921416\n",
      "[159]\ttrain-rmse:3.648190\tval-rmse:3.919283\n",
      "[160]\ttrain-rmse:3.645368\tval-rmse:3.917633\n",
      "[161]\ttrain-rmse:3.642601\tval-rmse:3.915805\n",
      "[162]\ttrain-rmse:3.639773\tval-rmse:3.914338\n",
      "[163]\ttrain-rmse:3.636695\tval-rmse:3.912632\n",
      "[164]\ttrain-rmse:3.633692\tval-rmse:3.910933\n",
      "[165]\ttrain-rmse:3.630956\tval-rmse:3.909357\n",
      "[166]\ttrain-rmse:3.628461\tval-rmse:3.907795\n",
      "[167]\ttrain-rmse:3.625492\tval-rmse:3.906410\n",
      "[168]\ttrain-rmse:3.622774\tval-rmse:3.905076\n",
      "[169]\ttrain-rmse:3.620135\tval-rmse:3.903648\n",
      "[170]\ttrain-rmse:3.617586\tval-rmse:3.902361\n",
      "[171]\ttrain-rmse:3.614944\tval-rmse:3.900892\n",
      "[172]\ttrain-rmse:3.612258\tval-rmse:3.899539\n",
      "[173]\ttrain-rmse:3.610016\tval-rmse:3.898257\n",
      "[174]\ttrain-rmse:3.607428\tval-rmse:3.896921\n",
      "[175]\ttrain-rmse:3.604974\tval-rmse:3.895691\n",
      "[176]\ttrain-rmse:3.602659\tval-rmse:3.894384\n",
      "[177]\ttrain-rmse:3.600509\tval-rmse:3.893205\n",
      "[178]\ttrain-rmse:3.598026\tval-rmse:3.891773\n",
      "[179]\ttrain-rmse:3.595854\tval-rmse:3.890473\n",
      "[180]\ttrain-rmse:3.593649\tval-rmse:3.889248\n",
      "[181]\ttrain-rmse:3.591402\tval-rmse:3.888019\n",
      "[182]\ttrain-rmse:3.589339\tval-rmse:3.886874\n",
      "[183]\ttrain-rmse:3.587305\tval-rmse:3.885769\n",
      "[184]\ttrain-rmse:3.585020\tval-rmse:3.884393\n",
      "[185]\ttrain-rmse:3.582749\tval-rmse:3.883362\n",
      "[186]\ttrain-rmse:3.580679\tval-rmse:3.882112\n",
      "[187]\ttrain-rmse:3.578556\tval-rmse:3.881249\n",
      "[188]\ttrain-rmse:3.576076\tval-rmse:3.880042\n",
      "[189]\ttrain-rmse:3.573800\tval-rmse:3.878848\n",
      "[190]\ttrain-rmse:3.571797\tval-rmse:3.877767\n",
      "[191]\ttrain-rmse:3.569749\tval-rmse:3.876727\n",
      "[192]\ttrain-rmse:3.567758\tval-rmse:3.875804\n",
      "[193]\ttrain-rmse:3.565783\tval-rmse:3.874819\n",
      "[194]\ttrain-rmse:3.563751\tval-rmse:3.873849\n",
      "[195]\ttrain-rmse:3.561685\tval-rmse:3.872887\n",
      "[196]\ttrain-rmse:3.559881\tval-rmse:3.872028\n",
      "[197]\ttrain-rmse:3.557795\tval-rmse:3.871304\n",
      "[198]\ttrain-rmse:3.555767\tval-rmse:3.870404\n",
      "[199]\ttrain-rmse:3.553946\tval-rmse:3.869613\n",
      "[200]\ttrain-rmse:3.551924\tval-rmse:3.868639\n",
      "[201]\ttrain-rmse:3.549945\tval-rmse:3.867864\n",
      "[202]\ttrain-rmse:3.548144\tval-rmse:3.867027\n",
      "[203]\ttrain-rmse:3.546626\tval-rmse:3.866249\n",
      "[204]\ttrain-rmse:3.544462\tval-rmse:3.865425\n",
      "[205]\ttrain-rmse:3.542557\tval-rmse:3.864695\n",
      "[206]\ttrain-rmse:3.541058\tval-rmse:3.864030\n",
      "[207]\ttrain-rmse:3.539386\tval-rmse:3.863282\n",
      "[208]\ttrain-rmse:3.537569\tval-rmse:3.862611\n",
      "[209]\ttrain-rmse:3.536036\tval-rmse:3.861770\n",
      "[210]\ttrain-rmse:3.534353\tval-rmse:3.861089\n",
      "[211]\ttrain-rmse:3.532825\tval-rmse:3.860476\n",
      "[212]\ttrain-rmse:3.531103\tval-rmse:3.859645\n",
      "[213]\ttrain-rmse:3.529398\tval-rmse:3.858859\n",
      "[214]\ttrain-rmse:3.527549\tval-rmse:3.858111\n",
      "[215]\ttrain-rmse:3.525962\tval-rmse:3.857567\n",
      "[216]\ttrain-rmse:3.524380\tval-rmse:3.856834\n",
      "[217]\ttrain-rmse:3.522964\tval-rmse:3.856073\n",
      "[218]\ttrain-rmse:3.521205\tval-rmse:3.855497\n",
      "[219]\ttrain-rmse:3.519284\tval-rmse:3.854950\n",
      "[220]\ttrain-rmse:3.517645\tval-rmse:3.854367\n",
      "[221]\ttrain-rmse:3.515976\tval-rmse:3.853770\n",
      "[222]\ttrain-rmse:3.514694\tval-rmse:3.853254\n",
      "[223]\ttrain-rmse:3.513056\tval-rmse:3.852657\n",
      "[224]\ttrain-rmse:3.511506\tval-rmse:3.852173\n",
      "[225]\ttrain-rmse:3.509909\tval-rmse:3.851567\n",
      "[226]\ttrain-rmse:3.508258\tval-rmse:3.850988\n",
      "[227]\ttrain-rmse:3.506849\tval-rmse:3.850345\n",
      "[228]\ttrain-rmse:3.505389\tval-rmse:3.849743\n",
      "[229]\ttrain-rmse:3.504267\tval-rmse:3.849367\n",
      "[230]\ttrain-rmse:3.502683\tval-rmse:3.848653\n",
      "[231]\ttrain-rmse:3.501063\tval-rmse:3.847948\n",
      "[232]\ttrain-rmse:3.499439\tval-rmse:3.847479\n",
      "[233]\ttrain-rmse:3.498034\tval-rmse:3.847058\n",
      "[234]\ttrain-rmse:3.496478\tval-rmse:3.846575\n",
      "[235]\ttrain-rmse:3.495102\tval-rmse:3.846097\n",
      "[236]\ttrain-rmse:3.493685\tval-rmse:3.845516\n",
      "[237]\ttrain-rmse:3.491909\tval-rmse:3.844942\n",
      "[238]\ttrain-rmse:3.490429\tval-rmse:3.844414\n",
      "[239]\ttrain-rmse:3.489052\tval-rmse:3.844035\n",
      "[240]\ttrain-rmse:3.487662\tval-rmse:3.843711\n",
      "[241]\ttrain-rmse:3.486282\tval-rmse:3.843228\n",
      "[242]\ttrain-rmse:3.485030\tval-rmse:3.842748\n",
      "[243]\ttrain-rmse:3.483482\tval-rmse:3.842286\n",
      "[244]\ttrain-rmse:3.481982\tval-rmse:3.841876\n",
      "[245]\ttrain-rmse:3.480728\tval-rmse:3.841389\n",
      "[246]\ttrain-rmse:3.479568\tval-rmse:3.841033\n",
      "[247]\ttrain-rmse:3.478061\tval-rmse:3.840526\n",
      "[248]\ttrain-rmse:3.476502\tval-rmse:3.840085\n",
      "[249]\ttrain-rmse:3.475290\tval-rmse:3.839750\n",
      "[250]\ttrain-rmse:3.474015\tval-rmse:3.839207\n",
      "[251]\ttrain-rmse:3.472769\tval-rmse:3.838875\n",
      "[252]\ttrain-rmse:3.471527\tval-rmse:3.838515\n",
      "[253]\ttrain-rmse:3.470632\tval-rmse:3.838215\n",
      "[254]\ttrain-rmse:3.469443\tval-rmse:3.837785\n",
      "[255]\ttrain-rmse:3.468536\tval-rmse:3.837406\n",
      "[256]\ttrain-rmse:3.467308\tval-rmse:3.836959\n",
      "[257]\ttrain-rmse:3.466019\tval-rmse:3.836484\n",
      "[258]\ttrain-rmse:3.464728\tval-rmse:3.836140\n",
      "[259]\ttrain-rmse:3.463384\tval-rmse:3.835793\n",
      "[260]\ttrain-rmse:3.462317\tval-rmse:3.835396\n",
      "[261]\ttrain-rmse:3.460659\tval-rmse:3.834803\n",
      "[262]\ttrain-rmse:3.459264\tval-rmse:3.834324\n",
      "[263]\ttrain-rmse:3.457716\tval-rmse:3.833969\n",
      "[264]\ttrain-rmse:3.456452\tval-rmse:3.833757\n",
      "[265]\ttrain-rmse:3.455022\tval-rmse:3.833287\n",
      "[266]\ttrain-rmse:3.453833\tval-rmse:3.832983\n",
      "[267]\ttrain-rmse:3.452454\tval-rmse:3.832547\n",
      "[268]\ttrain-rmse:3.451140\tval-rmse:3.832237\n",
      "[269]\ttrain-rmse:3.450044\tval-rmse:3.831966\n",
      "[270]\ttrain-rmse:3.448694\tval-rmse:3.831738\n",
      "[271]\ttrain-rmse:3.447547\tval-rmse:3.831559\n",
      "[272]\ttrain-rmse:3.446076\tval-rmse:3.831144\n",
      "[273]\ttrain-rmse:3.445083\tval-rmse:3.830821\n",
      "[274]\ttrain-rmse:3.443812\tval-rmse:3.830599\n",
      "[275]\ttrain-rmse:3.442362\tval-rmse:3.830234\n",
      "[276]\ttrain-rmse:3.441349\tval-rmse:3.829888\n",
      "[277]\ttrain-rmse:3.440076\tval-rmse:3.829629\n",
      "[278]\ttrain-rmse:3.438688\tval-rmse:3.829274\n",
      "[279]\ttrain-rmse:3.437703\tval-rmse:3.828891\n",
      "[280]\ttrain-rmse:3.436676\tval-rmse:3.828695\n",
      "[281]\ttrain-rmse:3.435416\tval-rmse:3.828359\n",
      "[282]\ttrain-rmse:3.434083\tval-rmse:3.827988\n",
      "[283]\ttrain-rmse:3.432809\tval-rmse:3.827585\n",
      "[284]\ttrain-rmse:3.431584\tval-rmse:3.827313\n",
      "[285]\ttrain-rmse:3.430091\tval-rmse:3.826829\n",
      "[286]\ttrain-rmse:3.428931\tval-rmse:3.826546\n",
      "[287]\ttrain-rmse:3.427736\tval-rmse:3.826219\n",
      "[288]\ttrain-rmse:3.426461\tval-rmse:3.826076\n",
      "[289]\ttrain-rmse:3.425369\tval-rmse:3.825797\n",
      "[290]\ttrain-rmse:3.424212\tval-rmse:3.825475\n",
      "[291]\ttrain-rmse:3.422904\tval-rmse:3.825217\n",
      "[292]\ttrain-rmse:3.421819\tval-rmse:3.824913\n",
      "[293]\ttrain-rmse:3.420834\tval-rmse:3.824654\n",
      "[294]\ttrain-rmse:3.419832\tval-rmse:3.824365\n",
      "[295]\ttrain-rmse:3.418862\tval-rmse:3.824259\n",
      "[296]\ttrain-rmse:3.417884\tval-rmse:3.824038\n",
      "[297]\ttrain-rmse:3.417238\tval-rmse:3.823909\n",
      "[298]\ttrain-rmse:3.416265\tval-rmse:3.823674\n",
      "[299]\ttrain-rmse:3.415165\tval-rmse:3.823420\n",
      "[300]\ttrain-rmse:3.414134\tval-rmse:3.823164\n",
      "[301]\ttrain-rmse:3.413056\tval-rmse:3.822879\n",
      "[302]\ttrain-rmse:3.412081\tval-rmse:3.822685\n",
      "[303]\ttrain-rmse:3.411172\tval-rmse:3.822407\n",
      "[304]\ttrain-rmse:3.410432\tval-rmse:3.822288\n",
      "[305]\ttrain-rmse:3.409629\tval-rmse:3.822128\n",
      "[306]\ttrain-rmse:3.408846\tval-rmse:3.821989\n",
      "[307]\ttrain-rmse:3.407636\tval-rmse:3.821684\n",
      "[308]\ttrain-rmse:3.406712\tval-rmse:3.821463\n",
      "[309]\ttrain-rmse:3.405889\tval-rmse:3.821386\n",
      "[310]\ttrain-rmse:3.404819\tval-rmse:3.821161\n",
      "[311]\ttrain-rmse:3.403753\tval-rmse:3.821130\n",
      "[312]\ttrain-rmse:3.402974\tval-rmse:3.820979\n",
      "[313]\ttrain-rmse:3.401902\tval-rmse:3.820775\n",
      "[314]\ttrain-rmse:3.400994\tval-rmse:3.820740\n",
      "[315]\ttrain-rmse:3.400063\tval-rmse:3.820588\n",
      "[316]\ttrain-rmse:3.398886\tval-rmse:3.820320\n",
      "[317]\ttrain-rmse:3.397720\tval-rmse:3.820163\n",
      "[318]\ttrain-rmse:3.396858\tval-rmse:3.820056\n",
      "[319]\ttrain-rmse:3.395789\tval-rmse:3.819904\n",
      "[320]\ttrain-rmse:3.395047\tval-rmse:3.819757\n",
      "[321]\ttrain-rmse:3.394333\tval-rmse:3.819523\n",
      "[322]\ttrain-rmse:3.393543\tval-rmse:3.819330\n",
      "[323]\ttrain-rmse:3.392669\tval-rmse:3.819348\n",
      "[324]\ttrain-rmse:3.391697\tval-rmse:3.819127\n",
      "[325]\ttrain-rmse:3.390674\tval-rmse:3.818915\n",
      "[326]\ttrain-rmse:3.389496\tval-rmse:3.818653\n",
      "[327]\ttrain-rmse:3.388777\tval-rmse:3.818404\n",
      "[328]\ttrain-rmse:3.388093\tval-rmse:3.818280\n",
      "[329]\ttrain-rmse:3.387233\tval-rmse:3.818063\n",
      "[330]\ttrain-rmse:3.386093\tval-rmse:3.817872\n",
      "[331]\ttrain-rmse:3.385078\tval-rmse:3.817837\n",
      "[332]\ttrain-rmse:3.383987\tval-rmse:3.817740\n",
      "[333]\ttrain-rmse:3.383197\tval-rmse:3.817664\n",
      "[334]\ttrain-rmse:3.382224\tval-rmse:3.817587\n",
      "[335]\ttrain-rmse:3.381336\tval-rmse:3.817428\n",
      "[336]\ttrain-rmse:3.380534\tval-rmse:3.817344\n",
      "[337]\ttrain-rmse:3.379792\tval-rmse:3.817151\n",
      "[338]\ttrain-rmse:3.378960\tval-rmse:3.817024\n",
      "[339]\ttrain-rmse:3.378264\tval-rmse:3.816885\n",
      "[340]\ttrain-rmse:3.377398\tval-rmse:3.816739\n",
      "[341]\ttrain-rmse:3.376535\tval-rmse:3.816656\n",
      "[342]\ttrain-rmse:3.375186\tval-rmse:3.816334\n",
      "[343]\ttrain-rmse:3.373910\tval-rmse:3.816204\n",
      "[344]\ttrain-rmse:3.372978\tval-rmse:3.816046\n",
      "[345]\ttrain-rmse:3.371756\tval-rmse:3.815906\n",
      "[346]\ttrain-rmse:3.370870\tval-rmse:3.815738\n",
      "[347]\ttrain-rmse:3.369696\tval-rmse:3.815584\n",
      "[348]\ttrain-rmse:3.369123\tval-rmse:3.815482\n",
      "[349]\ttrain-rmse:3.368534\tval-rmse:3.815349\n",
      "[350]\ttrain-rmse:3.367736\tval-rmse:3.815223\n",
      "[351]\ttrain-rmse:3.366935\tval-rmse:3.815201\n",
      "[352]\ttrain-rmse:3.366496\tval-rmse:3.815151\n",
      "[353]\ttrain-rmse:3.365395\tval-rmse:3.815069\n",
      "[354]\ttrain-rmse:3.364524\tval-rmse:3.814974\n",
      "[355]\ttrain-rmse:3.363333\tval-rmse:3.814777\n",
      "[356]\ttrain-rmse:3.362660\tval-rmse:3.814706\n",
      "[357]\ttrain-rmse:3.361744\tval-rmse:3.814727\n",
      "[358]\ttrain-rmse:3.361187\tval-rmse:3.814685\n",
      "[359]\ttrain-rmse:3.360640\tval-rmse:3.814650\n",
      "[360]\ttrain-rmse:3.359626\tval-rmse:3.814639\n",
      "[361]\ttrain-rmse:3.358860\tval-rmse:3.814402\n",
      "[362]\ttrain-rmse:3.358161\tval-rmse:3.814308\n",
      "[363]\ttrain-rmse:3.357448\tval-rmse:3.814219\n",
      "[364]\ttrain-rmse:3.356442\tval-rmse:3.813993\n",
      "[365]\ttrain-rmse:3.355446\tval-rmse:3.813913\n",
      "[366]\ttrain-rmse:3.354528\tval-rmse:3.813721\n",
      "[367]\ttrain-rmse:3.353650\tval-rmse:3.813538\n",
      "[368]\ttrain-rmse:3.353102\tval-rmse:3.813440\n",
      "[369]\ttrain-rmse:3.352372\tval-rmse:3.813353\n",
      "[370]\ttrain-rmse:3.351799\tval-rmse:3.813306\n",
      "[371]\ttrain-rmse:3.351148\tval-rmse:3.813218\n",
      "[372]\ttrain-rmse:3.350006\tval-rmse:3.813164\n",
      "[373]\ttrain-rmse:3.348622\tval-rmse:3.812947\n",
      "[374]\ttrain-rmse:3.347918\tval-rmse:3.812881\n",
      "[375]\ttrain-rmse:3.347289\tval-rmse:3.812760\n",
      "[376]\ttrain-rmse:3.346485\tval-rmse:3.812724\n",
      "[377]\ttrain-rmse:3.345910\tval-rmse:3.812702\n",
      "[378]\ttrain-rmse:3.345268\tval-rmse:3.812701\n",
      "[379]\ttrain-rmse:3.344697\tval-rmse:3.812567\n",
      "[380]\ttrain-rmse:3.343838\tval-rmse:3.812546\n",
      "[381]\ttrain-rmse:3.342962\tval-rmse:3.812384\n",
      "[382]\ttrain-rmse:3.342139\tval-rmse:3.812222\n",
      "[383]\ttrain-rmse:3.341132\tval-rmse:3.812126\n",
      "[384]\ttrain-rmse:3.340425\tval-rmse:3.811996\n",
      "[385]\ttrain-rmse:3.339881\tval-rmse:3.812013\n",
      "[386]\ttrain-rmse:3.338821\tval-rmse:3.811880\n",
      "[387]\ttrain-rmse:3.337913\tval-rmse:3.811671\n",
      "[388]\ttrain-rmse:3.337229\tval-rmse:3.811668\n",
      "[389]\ttrain-rmse:3.336070\tval-rmse:3.811506\n",
      "[390]\ttrain-rmse:3.335092\tval-rmse:3.811336\n",
      "[391]\ttrain-rmse:3.334467\tval-rmse:3.811283\n",
      "[392]\ttrain-rmse:3.333724\tval-rmse:3.811295\n",
      "[393]\ttrain-rmse:3.333342\tval-rmse:3.811299\n",
      "[394]\ttrain-rmse:3.332457\tval-rmse:3.811297\n",
      "[395]\ttrain-rmse:3.331676\tval-rmse:3.811237\n",
      "[396]\ttrain-rmse:3.330455\tval-rmse:3.811131\n",
      "[397]\ttrain-rmse:3.329702\tval-rmse:3.810991\n",
      "[398]\ttrain-rmse:3.328983\tval-rmse:3.810848\n",
      "[399]\ttrain-rmse:3.328196\tval-rmse:3.810776\n",
      "[400]\ttrain-rmse:3.327206\tval-rmse:3.810545\n",
      "[401]\ttrain-rmse:3.326562\tval-rmse:3.810503\n",
      "[402]\ttrain-rmse:3.325611\tval-rmse:3.810475\n",
      "[403]\ttrain-rmse:3.324707\tval-rmse:3.810277\n",
      "[404]\ttrain-rmse:3.323753\tval-rmse:3.810113\n",
      "[405]\ttrain-rmse:3.323000\tval-rmse:3.809986\n",
      "[406]\ttrain-rmse:3.321975\tval-rmse:3.809891\n",
      "[407]\ttrain-rmse:3.321549\tval-rmse:3.809789\n",
      "[408]\ttrain-rmse:3.321143\tval-rmse:3.809749\n",
      "[409]\ttrain-rmse:3.320400\tval-rmse:3.809596\n",
      "[410]\ttrain-rmse:3.320083\tval-rmse:3.809535\n",
      "[411]\ttrain-rmse:3.319651\tval-rmse:3.809511\n",
      "[412]\ttrain-rmse:3.318882\tval-rmse:3.809496\n",
      "[413]\ttrain-rmse:3.318185\tval-rmse:3.809392\n",
      "[414]\ttrain-rmse:3.317692\tval-rmse:3.809323\n",
      "[415]\ttrain-rmse:3.316932\tval-rmse:3.809225\n",
      "[416]\ttrain-rmse:3.316150\tval-rmse:3.809117\n",
      "[417]\ttrain-rmse:3.315286\tval-rmse:3.809042\n",
      "[418]\ttrain-rmse:3.314334\tval-rmse:3.809142\n",
      "[419]\ttrain-rmse:3.313650\tval-rmse:3.809089\n",
      "[420]\ttrain-rmse:3.312828\tval-rmse:3.809103\n",
      "[421]\ttrain-rmse:3.312357\tval-rmse:3.809087\n",
      "[422]\ttrain-rmse:3.311511\tval-rmse:3.809062\n",
      "[423]\ttrain-rmse:3.310633\tval-rmse:3.809163\n",
      "[424]\ttrain-rmse:3.309682\tval-rmse:3.809213\n",
      "[425]\ttrain-rmse:3.308879\tval-rmse:3.809198\n",
      "[426]\ttrain-rmse:3.308269\tval-rmse:3.809162\n",
      "[427]\ttrain-rmse:3.307173\tval-rmse:3.808978\n",
      "[428]\ttrain-rmse:3.306521\tval-rmse:3.808995\n",
      "[429]\ttrain-rmse:3.306222\tval-rmse:3.808919\n",
      "[430]\ttrain-rmse:3.305377\tval-rmse:3.808795\n",
      "[431]\ttrain-rmse:3.304404\tval-rmse:3.808822\n",
      "[432]\ttrain-rmse:3.303772\tval-rmse:3.808753\n",
      "[433]\ttrain-rmse:3.302860\tval-rmse:3.808757\n",
      "[434]\ttrain-rmse:3.302490\tval-rmse:3.808741\n",
      "[435]\ttrain-rmse:3.301764\tval-rmse:3.808758\n",
      "[436]\ttrain-rmse:3.301271\tval-rmse:3.808767\n",
      "[437]\ttrain-rmse:3.300392\tval-rmse:3.808801\n",
      "[438]\ttrain-rmse:3.299762\tval-rmse:3.808748\n",
      "[439]\ttrain-rmse:3.298946\tval-rmse:3.808700\n",
      "[440]\ttrain-rmse:3.298240\tval-rmse:3.808690\n",
      "[441]\ttrain-rmse:3.297682\tval-rmse:3.808702\n",
      "[442]\ttrain-rmse:3.296842\tval-rmse:3.808717\n",
      "[443]\ttrain-rmse:3.296045\tval-rmse:3.808655\n",
      "[444]\ttrain-rmse:3.295703\tval-rmse:3.808586\n",
      "[445]\ttrain-rmse:3.295292\tval-rmse:3.808592\n",
      "[446]\ttrain-rmse:3.294917\tval-rmse:3.808572\n",
      "[447]\ttrain-rmse:3.294356\tval-rmse:3.808545\n",
      "[448]\ttrain-rmse:3.293759\tval-rmse:3.808448\n",
      "[449]\ttrain-rmse:3.293372\tval-rmse:3.808399\n",
      "[450]\ttrain-rmse:3.292785\tval-rmse:3.808361\n",
      "[451]\ttrain-rmse:3.292453\tval-rmse:3.808385\n",
      "[452]\ttrain-rmse:3.291326\tval-rmse:3.808368\n",
      "[453]\ttrain-rmse:3.290848\tval-rmse:3.808380\n",
      "[454]\ttrain-rmse:3.290061\tval-rmse:3.808499\n",
      "[455]\ttrain-rmse:3.289503\tval-rmse:3.808507\n",
      "[456]\ttrain-rmse:3.288893\tval-rmse:3.808512\n",
      "[457]\ttrain-rmse:3.288472\tval-rmse:3.808493\n",
      "[458]\ttrain-rmse:3.287654\tval-rmse:3.808396\n",
      "[459]\ttrain-rmse:3.287112\tval-rmse:3.808410\n",
      "[460]\ttrain-rmse:3.286507\tval-rmse:3.808381\n",
      "[461]\ttrain-rmse:3.285659\tval-rmse:3.808367\n",
      "[462]\ttrain-rmse:3.284630\tval-rmse:3.808371\n",
      "[463]\ttrain-rmse:3.284032\tval-rmse:3.808360\n",
      "[464]\ttrain-rmse:3.283122\tval-rmse:3.808274\n",
      "[465]\ttrain-rmse:3.282220\tval-rmse:3.808219\n",
      "[466]\ttrain-rmse:3.281653\tval-rmse:3.808102\n",
      "[467]\ttrain-rmse:3.280813\tval-rmse:3.808022\n",
      "[468]\ttrain-rmse:3.280406\tval-rmse:3.807956\n",
      "[469]\ttrain-rmse:3.280027\tval-rmse:3.807921\n",
      "[470]\ttrain-rmse:3.279335\tval-rmse:3.807891\n",
      "[471]\ttrain-rmse:3.278810\tval-rmse:3.807909\n",
      "[472]\ttrain-rmse:3.278289\tval-rmse:3.807913\n",
      "[473]\ttrain-rmse:3.277661\tval-rmse:3.807821\n",
      "[474]\ttrain-rmse:3.277069\tval-rmse:3.807781\n",
      "[475]\ttrain-rmse:3.276720\tval-rmse:3.807803\n",
      "[476]\ttrain-rmse:3.275832\tval-rmse:3.807835\n",
      "[477]\ttrain-rmse:3.275033\tval-rmse:3.807648\n",
      "[478]\ttrain-rmse:3.274606\tval-rmse:3.807614\n",
      "[479]\ttrain-rmse:3.273648\tval-rmse:3.807691\n",
      "[480]\ttrain-rmse:3.272956\tval-rmse:3.807686\n",
      "[481]\ttrain-rmse:3.272099\tval-rmse:3.807609\n",
      "[482]\ttrain-rmse:3.271450\tval-rmse:3.807488\n",
      "[483]\ttrain-rmse:3.270935\tval-rmse:3.807432\n",
      "[484]\ttrain-rmse:3.270526\tval-rmse:3.807415\n",
      "[485]\ttrain-rmse:3.269527\tval-rmse:3.807329\n",
      "[486]\ttrain-rmse:3.268920\tval-rmse:3.807300\n",
      "[487]\ttrain-rmse:3.268445\tval-rmse:3.807262\n",
      "[488]\ttrain-rmse:3.267775\tval-rmse:3.807245\n",
      "[489]\ttrain-rmse:3.267200\tval-rmse:3.807181\n",
      "[490]\ttrain-rmse:3.266639\tval-rmse:3.807050\n",
      "[491]\ttrain-rmse:3.266280\tval-rmse:3.807003\n",
      "[492]\ttrain-rmse:3.265730\tval-rmse:3.807091\n",
      "[493]\ttrain-rmse:3.265267\tval-rmse:3.807106\n",
      "[494]\ttrain-rmse:3.265001\tval-rmse:3.807133\n",
      "[495]\ttrain-rmse:3.264234\tval-rmse:3.807162\n",
      "[496]\ttrain-rmse:3.263636\tval-rmse:3.807126\n",
      "[497]\ttrain-rmse:3.262893\tval-rmse:3.807133\n",
      "[498]\ttrain-rmse:3.262122\tval-rmse:3.807057\n",
      "[499]\ttrain-rmse:3.261201\tval-rmse:3.807111\n",
      "[500]\ttrain-rmse:3.260626\tval-rmse:3.807029\n",
      "[501]\ttrain-rmse:3.259676\tval-rmse:3.806962\n",
      "[502]\ttrain-rmse:3.259371\tval-rmse:3.806950\n",
      "[503]\ttrain-rmse:3.259061\tval-rmse:3.806926\n",
      "[504]\ttrain-rmse:3.258666\tval-rmse:3.806906\n",
      "[505]\ttrain-rmse:3.257984\tval-rmse:3.806826\n",
      "[506]\ttrain-rmse:3.257423\tval-rmse:3.806822\n",
      "[507]\ttrain-rmse:3.256840\tval-rmse:3.806768\n",
      "[508]\ttrain-rmse:3.256489\tval-rmse:3.806790\n",
      "[509]\ttrain-rmse:3.255708\tval-rmse:3.806778\n",
      "[510]\ttrain-rmse:3.255137\tval-rmse:3.806814\n",
      "[511]\ttrain-rmse:3.253992\tval-rmse:3.806670\n",
      "[512]\ttrain-rmse:3.253365\tval-rmse:3.806535\n",
      "[513]\ttrain-rmse:3.252803\tval-rmse:3.806504\n",
      "[514]\ttrain-rmse:3.252367\tval-rmse:3.806533\n",
      "[515]\ttrain-rmse:3.251880\tval-rmse:3.806478\n",
      "[516]\ttrain-rmse:3.251359\tval-rmse:3.806469\n",
      "[517]\ttrain-rmse:3.250529\tval-rmse:3.806470\n",
      "[518]\ttrain-rmse:3.249751\tval-rmse:3.806404\n",
      "[519]\ttrain-rmse:3.249137\tval-rmse:3.806346\n",
      "[520]\ttrain-rmse:3.248368\tval-rmse:3.806340\n",
      "[521]\ttrain-rmse:3.247854\tval-rmse:3.806262\n",
      "[522]\ttrain-rmse:3.246884\tval-rmse:3.806301\n",
      "[523]\ttrain-rmse:3.246417\tval-rmse:3.806269\n",
      "[524]\ttrain-rmse:3.245797\tval-rmse:3.806278\n",
      "[525]\ttrain-rmse:3.244920\tval-rmse:3.806226\n",
      "[526]\ttrain-rmse:3.244484\tval-rmse:3.806275\n",
      "[527]\ttrain-rmse:3.244017\tval-rmse:3.806291\n",
      "[528]\ttrain-rmse:3.243520\tval-rmse:3.806262\n",
      "[529]\ttrain-rmse:3.243004\tval-rmse:3.806191\n",
      "[530]\ttrain-rmse:3.242565\tval-rmse:3.806158\n",
      "[531]\ttrain-rmse:3.241957\tval-rmse:3.806110\n",
      "[532]\ttrain-rmse:3.241565\tval-rmse:3.806123\n",
      "[533]\ttrain-rmse:3.241168\tval-rmse:3.806110\n",
      "[534]\ttrain-rmse:3.240737\tval-rmse:3.805997\n",
      "[535]\ttrain-rmse:3.239940\tval-rmse:3.805994\n",
      "[536]\ttrain-rmse:3.239102\tval-rmse:3.806005\n",
      "[537]\ttrain-rmse:3.237957\tval-rmse:3.805980\n",
      "[538]\ttrain-rmse:3.237504\tval-rmse:3.806026\n",
      "[539]\ttrain-rmse:3.236927\tval-rmse:3.805981\n",
      "[540]\ttrain-rmse:3.236479\tval-rmse:3.805988\n",
      "[541]\ttrain-rmse:3.235797\tval-rmse:3.805893\n",
      "[542]\ttrain-rmse:3.235004\tval-rmse:3.805921\n",
      "[543]\ttrain-rmse:3.234470\tval-rmse:3.805970\n",
      "[544]\ttrain-rmse:3.233936\tval-rmse:3.805977\n",
      "[545]\ttrain-rmse:3.233432\tval-rmse:3.806029\n",
      "[546]\ttrain-rmse:3.232681\tval-rmse:3.805987\n",
      "[547]\ttrain-rmse:3.232209\tval-rmse:3.805887\n",
      "[548]\ttrain-rmse:3.231497\tval-rmse:3.805960\n",
      "[549]\ttrain-rmse:3.230870\tval-rmse:3.805925\n",
      "[550]\ttrain-rmse:3.230457\tval-rmse:3.805905\n",
      "[551]\ttrain-rmse:3.229916\tval-rmse:3.805900\n",
      "[552]\ttrain-rmse:3.229117\tval-rmse:3.805848\n",
      "[553]\ttrain-rmse:3.228636\tval-rmse:3.805856\n",
      "[554]\ttrain-rmse:3.228184\tval-rmse:3.805805\n",
      "[555]\ttrain-rmse:3.227853\tval-rmse:3.805771\n",
      "[556]\ttrain-rmse:3.227180\tval-rmse:3.805655\n",
      "[557]\ttrain-rmse:3.226163\tval-rmse:3.805566\n",
      "[558]\ttrain-rmse:3.225273\tval-rmse:3.805526\n",
      "[559]\ttrain-rmse:3.224597\tval-rmse:3.805602\n",
      "[560]\ttrain-rmse:3.224405\tval-rmse:3.805603\n",
      "[561]\ttrain-rmse:3.224067\tval-rmse:3.805546\n",
      "[562]\ttrain-rmse:3.223407\tval-rmse:3.805450\n",
      "[563]\ttrain-rmse:3.222731\tval-rmse:3.805387\n",
      "[564]\ttrain-rmse:3.221858\tval-rmse:3.805391\n",
      "[565]\ttrain-rmse:3.221277\tval-rmse:3.805324\n",
      "[566]\ttrain-rmse:3.220318\tval-rmse:3.805291\n",
      "[567]\ttrain-rmse:3.219858\tval-rmse:3.805161\n",
      "[568]\ttrain-rmse:3.219103\tval-rmse:3.805156\n",
      "[569]\ttrain-rmse:3.218658\tval-rmse:3.805162\n",
      "[570]\ttrain-rmse:3.217790\tval-rmse:3.805132\n",
      "[571]\ttrain-rmse:3.217083\tval-rmse:3.805068\n",
      "[572]\ttrain-rmse:3.216289\tval-rmse:3.805131\n",
      "[573]\ttrain-rmse:3.215767\tval-rmse:3.805168\n",
      "[574]\ttrain-rmse:3.215370\tval-rmse:3.805154\n",
      "[575]\ttrain-rmse:3.214765\tval-rmse:3.805082\n",
      "[576]\ttrain-rmse:3.214074\tval-rmse:3.805100\n",
      "[577]\ttrain-rmse:3.213266\tval-rmse:3.805130\n",
      "[578]\ttrain-rmse:3.212853\tval-rmse:3.805168\n",
      "[579]\ttrain-rmse:3.212103\tval-rmse:3.805125\n",
      "[580]\ttrain-rmse:3.211450\tval-rmse:3.805024\n",
      "[581]\ttrain-rmse:3.210585\tval-rmse:3.805019\n",
      "[582]\ttrain-rmse:3.210024\tval-rmse:3.805087\n",
      "[583]\ttrain-rmse:3.209534\tval-rmse:3.805051\n",
      "[584]\ttrain-rmse:3.208701\tval-rmse:3.804952\n",
      "[585]\ttrain-rmse:3.208124\tval-rmse:3.804958\n",
      "[586]\ttrain-rmse:3.207598\tval-rmse:3.805006\n",
      "[587]\ttrain-rmse:3.207242\tval-rmse:3.805004\n",
      "[588]\ttrain-rmse:3.206859\tval-rmse:3.805011\n",
      "[589]\ttrain-rmse:3.206611\tval-rmse:3.804986\n",
      "[590]\ttrain-rmse:3.205904\tval-rmse:3.805030\n",
      "[591]\ttrain-rmse:3.204998\tval-rmse:3.805051\n",
      "[592]\ttrain-rmse:3.204603\tval-rmse:3.805073\n",
      "[593]\ttrain-rmse:3.203680\tval-rmse:3.805154\n",
      "[594]\ttrain-rmse:3.203165\tval-rmse:3.805161\n",
      "[595]\ttrain-rmse:3.202563\tval-rmse:3.805240\n",
      "[596]\ttrain-rmse:3.202037\tval-rmse:3.805196\n",
      "[597]\ttrain-rmse:3.201552\tval-rmse:3.805156\n",
      "[598]\ttrain-rmse:3.201224\tval-rmse:3.805148\n",
      "[599]\ttrain-rmse:3.200510\tval-rmse:3.805112\n",
      "[600]\ttrain-rmse:3.199880\tval-rmse:3.805068\n",
      "[601]\ttrain-rmse:3.199131\tval-rmse:3.805073\n",
      "[602]\ttrain-rmse:3.198667\tval-rmse:3.805104\n",
      "[603]\ttrain-rmse:3.197980\tval-rmse:3.805099\n",
      "[604]\ttrain-rmse:3.197379\tval-rmse:3.805143\n",
      "Stopping. Best iteration:\n",
      "[584]\ttrain-rmse:3.208701\tval-rmse:3.804952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.01\n",
    "params[\"min_child_weight\"] = 5\n",
    "params[\"subsample\"] = 0.8\n",
    "params[\"colsample_bytree\"] = 0.8\n",
    "# params[\"max_delta_step\"] = 10\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 8 #7\n",
    "params[\"scale_pos_weight\"] = 1.0\n",
    "# params[\"gamma\"] = 0\n",
    "\n",
    "\n",
    "plst = list(params.items())\n",
    "\n",
    "max_rounds = 1000\n",
    "xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "#create a train and validation dmatrices \n",
    "xgtrain = xgb.DMatrix(X_train_k, label=y_train_k)\n",
    "xgval = xgb.DMatrix(X_valid_k, label=y_valid_k)\n",
    "\n",
    "#train using early stopping and predict\n",
    "watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "model = xgb.train(plst, xgtrain, max_rounds, watchlist, early_stopping_rounds=20)\n",
    "# preds1 = model.predict(xgtest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 15.,   3.,   2., ...,   4.,   2.,   2.],\n",
       "       [ 16.,  14.,   5., ...,   4.,   2.,   1.],\n",
       "       [ 10.,  10.,   5., ...,   4.,   6.,   1.],\n",
       "       ..., \n",
       "       [ 18.,   7.,   5., ...,   4.,   1.,   1.],\n",
       "       [ 18.,  17.,   5., ...,   2.,   2.,   6.],\n",
       "       [  5.,  15.,   3., ...,   4.,   5.,   4.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.DataFrame({\"Id\": test_ind, \"Hazard\": preds})\n",
    "preds = preds.set_index('Id')\n",
    "preds.to_csv('xgboost_benchmark.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
