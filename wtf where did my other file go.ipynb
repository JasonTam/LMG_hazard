{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/afs/ee.cooper.edu/user/t/a/tam8/documents/ml_misc/semi_supervised/')\n",
    "import coreg\n",
    "reload(coreg)\n",
    "import rasco\n",
    "reload(rasco)\n",
    "import trireg\n",
    "reload(trireg)\n",
    "sys.path.append('/afs/ee.cooper.edu/user/t/a/tam8/documents/ml_misc/ordinal/')\n",
    "import simple\n",
    "reload(simple)\n",
    "sys.path.append('/afs/ee.cooper.edu/user/t/a/tam8/documents/ml_misc/ensemble/')\n",
    "import stacking\n",
    "reload(stacking)\n",
    "\n",
    "sys.path.append('/afs/ee.cooper.edu/user/t/a/tam8/documents/ml_misc/neighbors/')\n",
    "import rpfnn\n",
    "reload(rpfnn)\n",
    "import ann\n",
    "reload(ann)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "\n",
    "import transformers as tforms\n",
    "reload(tforms)\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion, make_union\n",
    "\n",
    "import metrics\n",
    "reload(metrics)\n",
    "from sklearn.cross_validation import StratifiedKFold, train_test_split\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC, SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, ElasticNet, Ridge, Lasso, SGDRegressor, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier, DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import Counter\n",
    "import minirank as mr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "def wgmean(x, w):\n",
    "    return np.exp(np.sum(w*np.log(x), axis=1) / np.sum(w, axis=1))\n",
    "\n",
    "import logging \n",
    "fh = logging.FileHandler('/tmp/lmg.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_pd  = pd.read_pickle('saved/train_pd_enc.p')\n",
    "test_pd  = pd.read_pickle('saved/test_pd_enc.p')\n",
    "labels = pd.read_pickle('saved/labels.p')\n",
    "test_ind = pickle.load(open('saved/test_ind.p'))\n",
    "y_binned = np.load('saved/y_binned.npy')\n",
    "\n",
    "fi = np.load('saved/feature_importances.npy')\n",
    "y_binned[y_binned==6] = 5\n",
    "\n",
    "drop_cols = ['T1_V10', 'T1_V13', 'T2_V7', 'T2_V10']\n",
    "# drop_cols = train_pd.columns[fi < 0.01]\n",
    "\n",
    "\n",
    "for col in drop_cols:\n",
    "    train_pd.drop(col, axis=1, inplace=True)\n",
    "    test_pd.drop(col, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data le instead\n",
    "# train_pd  = pd.read_pickle('saved/train_pd_l_enc.p')\n",
    "# test_pd  = pd.read_pickle('saved/test_pd_l_enc.p')\n",
    "\n",
    "train_pd  = pd.read_pickle('saved/train_pd_le_and_oh_enc.p')\n",
    "test_pd  = pd.read_pickle('saved/test_pd_le_and_oh_enc.p')\n",
    "\n",
    "labels = pd.read_pickle('saved/labels.p')\n",
    "test_ind = pickle.load(open('saved/test_ind.p'))\n",
    "y_binned = np.load('saved/y_binned.npy')\n",
    "fi = np.load('saved/feature_importances.npy')\n",
    "\n",
    "y_binned[y_binned==6] = 5\n",
    "\n",
    "drop_cols = ['T1_V10', 'T1_V13', 'T2_V7', 'T2_V10']\n",
    "# drop_cols = []\n",
    "\n",
    "# drop_cols = train_pd.columns[fi < 0.01]\n",
    "\n",
    "\n",
    "for col in drop_cols:\n",
    "    train_pd.drop(col, axis=1, inplace=True)\n",
    "    test_pd.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Data binary instead\n",
    "train_pd  = pd.read_pickle('saved/train_pd_binary_enc.p')\n",
    "test_pd  = pd.read_pickle('saved/test_pd_binary_enc.p')\n",
    "labels = pd.read_pickle('saved/labels.p')\n",
    "test_ind = pickle.load(open('saved/test_ind.p'))\n",
    "y_binned = np.load('saved/y_binned.npy')\n",
    "\n",
    "y_binned[y_binned==6] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50999, 2)\n",
      "(51000, 2)\n",
      "(50999, 2)\n",
      "(51000, 2)\n"
     ]
    }
   ],
   "source": [
    "X_tsne2_26 = np.load('saved/X_tsne2_26important.npy')\n",
    "X_tsne2_26_train = X_tsne2_26[:len(train_pd), :]\n",
    "X_tsne2_26_test = X_tsne2_26[-len(test_pd):, :]\n",
    "\n",
    "X_tsne2 = np.load('saved/X_tsne2.npy')\n",
    "X_tsne2_train = X_tsne2[:len(train_pd), :]\n",
    "X_tsne2_test = X_tsne2[-len(test_pd):, :]\n",
    "\n",
    "print X_tsne2_train.shape\n",
    "print X_tsne2_test.shape\n",
    "print X_tsne2_26_train.shape\n",
    "print X_tsne2_26_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50999, 38) (51000, 38)\n"
     ]
    }
   ],
   "source": [
    "# X_fa10_train = np.load('saved/X_fa10_train.npy')\n",
    "# X_fa10_test = np.load('saved/X_fa10_test.npy')\n",
    "# print X_fa10_train.shape, X_fa10_test.shape\n",
    "\n",
    "X_fa40_train = np.load('saved/X_fa40_train.npy')\n",
    "X_fa40_test = np.load('saved/X_fa40_test.npy')\n",
    "print X_fa40_train.shape, X_fa40_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (50999,)\n",
      "X_train (50999, 125)\n",
      "X_test (51000, 125)\n",
      "X_hold 50\n",
      "5\n",
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "train = np.array(train_pd)\n",
    "test = np.array(test_pd)\n",
    "\n",
    "X_train = train.astype(float)\n",
    "X_test = test.astype(float)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "try:\n",
    "    X_train = np.c_[X_train, X_tsne2_26_train]\n",
    "    X_test = np.c_[X_test, X_tsne2_26_test]\n",
    "#     X_train = X_tsne2_26_train\n",
    "#     X_test = X_tsne2_26_test\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    X_train = np.c_[X_train, X_3000mean]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "holdout = False\n",
    "if holdout:\n",
    "    X_train, X_hold, \\\n",
    "    y_train, y_hold, \\\n",
    "    y_binned, y_binned_hold \\\n",
    "    = train_test_split(\n",
    "        X_train, y_train, y_binned, \n",
    "        test_size=0.2, random_state=0)\n",
    "\n",
    "# \"\"\"\n",
    "pipe_x = make_pipeline(\n",
    "    make_union(\n",
    "        tforms.IdentityTformer(),\n",
    "#         make_pipeline(AddTformer(1), BoxCoxTformer()),\n",
    "#         AnscombeTformer(),\n",
    "    ),\n",
    "#     StandardScaler(),\n",
    ")\n",
    "pipe_y = make_pipeline(\n",
    "    tforms.IdentityTformer(),\n",
    "#     tforms.BoxCoxTformer(),\n",
    "#     tforms.LogTformer(),\n",
    "#     tforms.AnscombeTformer(),\n",
    "#     tforms.FreemanTukeyTformer(),\n",
    "#     tforms.ArcsinhTformer(),\n",
    "#     StandardScaler(),\n",
    "    \n",
    ")\n",
    "pipe_x.fit(np.r_[X_train, X_test])\n",
    "pipe_y.fit(y_train)\n",
    "\n",
    "X_train = pipe_x.transform(X_train)\n",
    "X_test = pipe_x.transform(X_test)\n",
    "try:\n",
    "    X_hold = pipe_x.transform(X_hold)\n",
    "except:\n",
    "    pass\n",
    "# y_train = pipe_y.fit_transform(y_train)\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# small_n = 5000\n",
    "# X_train = X_train[:small_n,:]\n",
    "# y_train = y_train[:small_n]\n",
    "# y_binned = y_binned[:small_n]\n",
    "\n",
    "print 'y_train', y_train.shape\n",
    "print 'X_train', X_train.shape\n",
    "print 'X_test', X_test.shape\n",
    "try:\n",
    "    print 'X_hold', X_hold.shape\n",
    "except:\n",
    "    pass\n",
    "print len(np.unique(y_train))\n",
    "print len(np.unique(y_binned))\n",
    "print type(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.datasets import dump_svmlight_file, load_svmlight_file\n",
    "from svmlight_loader import dump_svmlight_file, load_svmlight_file\n",
    "mapped_train, _y = load_svmlight_file('saved/mapped2000_train.libsvm')\n",
    "\n",
    "X_2000mean = mapped_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50999, 2125)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nn = np.c_[X_2000mean, X_train]\n",
    "X_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, MaxoutDense, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from keras.optimizers import Adadelta, Adagrad, Adam, RMSprop\n",
    "from keras.layers.advanced_activations import ParametricSoftplus, PReLU\n",
    "\n",
    "n_feats = X_nn.shape[1]\n",
    "drop_prob = 0.6\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "hidden_size = 1024\n",
    "model.add(Dense(n_feats, hidden_size))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(ParametricSoftplus(hidden_size))\n",
    "model.add(BatchNormalization((hidden_size,)))\n",
    "model.add(Dropout(drop_prob))\n",
    "model.add(Dense(hidden_size, hidden_size))\n",
    "model.add(ParametricSoftplus(hidden_size))\n",
    "model.add(BatchNormalization((hidden_size,)))\n",
    "model.add(Dropout(drop_prob))\n",
    "model.add(Dense(hidden_size, hidden_size))\n",
    "model.add(ParametricSoftplus(hidden_size))\n",
    "model.add(BatchNormalization((hidden_size,)))\n",
    "model.add(Dropout(drop_prob))\n",
    "model.add(Dense(hidden_size, hidden_size))\n",
    "model.add(ParametricSoftplus(hidden_size))\n",
    "model.add(BatchNormalization((hidden_size,)))\n",
    "model.add(Dropout(drop_prob))\n",
    "model.add(Dense(hidden_size, 1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "loss_type = 'msle'\n",
    "\n",
    "opt = RMSprop(lr=0.0005, rho=0.75, epsilon=1e-6)\n",
    "\n",
    "# model.compile(loss=loss_type, optimizer=opt)\n",
    "# model.save_weights('saved/nn_weights', overwrite=True)\n",
    "\n",
    "clf_nn = KerasRegressor(model, optimizer=opt, loss=loss_type,\n",
    "                       train_batch_size=1024*4, test_batch_size=1024*16,\n",
    "                       nb_epoch=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GBM models\n",
    "\n",
    "gbm = xgb.XGBRegressor(\n",
    "    objective=\"reg:linear\",\n",
    "    n_estimators=900,\n",
    "    learning_rate=0.005,\n",
    "#     gamma=0.0,\n",
    "    max_depth=9,\n",
    "    min_child_weight=6,\n",
    "#     max_delta_step=10,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "#     scale_pos_weight=1.0,\n",
    "    base_score=0.5,\n",
    "    nthread=7,\n",
    "    seed=np.random.randint(0,100),\n",
    "    silent=True,\n",
    ")\n",
    "\n",
    "meta_gbm = xgb.XGBRegressor(\n",
    "    objective=\"reg:linear\",\n",
    "    n_estimators=750,\n",
    "    learning_rate=0.005,\n",
    "#     gamma=0.0,\n",
    "    max_depth=9,\n",
    "    min_child_weight=6,\n",
    "#     max_delta_step=10,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "#     scale_pos_weight=1.0,\n",
    "    base_score=0.5,\n",
    "    nthread=7,\n",
    "    seed=np.random.randint(0,100),\n",
    "    silent=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "gbm_bin = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "#     gamma=0.0,\n",
    "    max_depth=8,\n",
    "    min_child_weight=5,\n",
    "#     max_delta_step=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "#     scale_pos_weight=1.0,\n",
    "    base_score=0.5,\n",
    "    nthread=8,\n",
    "    seed=np.random.randint(0,100),\n",
    "    silent=True,\n",
    ")\n",
    "\n",
    "gbm_cat = xgb.XGBClassifier(\n",
    "    objective=\"binary:softmax\",\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "#     gamma=0.0,\n",
    "    max_depth=8,\n",
    "    min_child_weight=5,\n",
    "#     max_delta_step=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "#     scale_pos_weight=1.0,\n",
    "    base_score=0.5,\n",
    "    nthread=8,\n",
    "    seed=np.random.randint(0,100),\n",
    "    silent=True,\n",
    ")\n",
    "\n",
    "gbm_fast = xgb.XGBClassifier(\n",
    "    objective=\"binary:softmax\",\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.3,\n",
    "#     gamma=0.0,\n",
    "    max_depth=8,\n",
    "    min_child_weight=5,\n",
    "#     max_delta_step=10,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=1.0,\n",
    "#     scale_pos_weight=1.0,\n",
    "    base_score=0.5,\n",
    "    nthread=8,\n",
    "    seed=np.random.randint(0,100),\n",
    "    silent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasco:RASCO Init\n",
      "INFO:rasco:RASCO Init\n",
      "INFO:rasco:RASCO Init\n",
      "INFO:rasco:RASCO Init\n",
      "INFO:rasco:RASCO Init\n",
      "INFO:stacker:Stacker Init\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.901985\n",
      "DEBUG:rasco:Iter #0 time: 5.80886\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.908127\n",
      "DEBUG:rasco:Iter #1 time: 5.84686\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.894073\n",
      "DEBUG:rasco:Iter #2 time: 6.03353\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.893093\n",
      "DEBUG:rasco:Iter #3 time: 5.94141\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.901929\n",
      "DEBUG:rasco:Iter #4 time: 5.91349\n",
      "DEBUG:rasco:Total time: 29.5478\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.903516\n",
      "DEBUG:rasco:Iter #0 time: 5.80821\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.914373\n",
      "DEBUG:rasco:Iter #1 time: 5.91069\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.909786\n",
      "DEBUG:rasco:Iter #2 time: 5.9186\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.920266\n",
      "DEBUG:rasco:Iter #3 time: 5.92052\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.889757\n",
      "DEBUG:rasco:Iter #4 time: 5.91841\n",
      "DEBUG:rasco:Total time: 29.4801\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.935292\n",
      "DEBUG:rasco:Iter #0 time: 5.70421\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.941838\n",
      "DEBUG:rasco:Iter #1 time: 5.81137\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.939819\n",
      "DEBUG:rasco:Iter #2 time: 5.82137\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.938244\n",
      "DEBUG:rasco:Iter #3 time: 5.83485\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.932569\n",
      "DEBUG:rasco:Iter #4 time: 5.8079\n",
      "DEBUG:rasco:Total time: 28.9834\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.959768\n",
      "DEBUG:rasco:Iter #0 time: 5.82154\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.963889\n",
      "DEBUG:rasco:Iter #1 time: 5.9184\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.961023\n",
      "DEBUG:rasco:Iter #2 time: 5.92495\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.961213\n",
      "DEBUG:rasco:Iter #3 time: 5.92018\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.962497\n",
      "DEBUG:rasco:Iter #4 time: 5.93021\n",
      "DEBUG:rasco:Total time: 29.5189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "Fold 0 Train time: 117.654 s\tPred time: 33.352 s\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.914504\n",
      "DEBUG:rasco:Iter #0 time: 5.81148\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.903988\n",
      "DEBUG:rasco:Iter #1 time: 5.93031\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.902313\n",
      "DEBUG:rasco:Iter #2 time: 5.96014\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.910863\n",
      "DEBUG:rasco:Iter #3 time: 5.94718\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.90813\n",
      "DEBUG:rasco:Iter #4 time: 5.92928\n",
      "DEBUG:rasco:Total time: 29.582\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.908552\n",
      "DEBUG:rasco:Iter #0 time: 5.81869\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.904668\n",
      "DEBUG:rasco:Iter #1 time: 5.92255\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.910663\n",
      "DEBUG:rasco:Iter #2 time: 5.93496\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.905872\n",
      "DEBUG:rasco:Iter #3 time: 5.97166\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.898121\n",
      "DEBUG:rasco:Iter #4 time: 5.91031\n",
      "DEBUG:rasco:Total time: 29.5619\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.943556\n",
      "DEBUG:rasco:Iter #0 time: 5.81399\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.950666\n",
      "DEBUG:rasco:Iter #1 time: 5.83397\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.95037\n",
      "DEBUG:rasco:Iter #2 time: 5.9234\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.933103\n",
      "DEBUG:rasco:Iter #3 time: 5.81424\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.942533\n",
      "DEBUG:rasco:Iter #4 time: 5.81829\n",
      "DEBUG:rasco:Total time: 29.2075\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.974881\n",
      "DEBUG:rasco:Iter #0 time: 5.83509\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.973592\n",
      "DEBUG:rasco:Iter #1 time: 5.91863\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.980708\n",
      "DEBUG:rasco:Iter #2 time: 5.9237\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.969359\n",
      "DEBUG:rasco:Iter #3 time: 5.91185\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.9823\n",
      "DEBUG:rasco:Iter #4 time: 5.92807\n",
      "DEBUG:rasco:Total time: 29.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score [0.20677959061209183]\n",
      "Score avg ensemble 0.206779590612\n",
      "Fold 1 Train time: 117.999 s\tPred time: 33.515 s\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.920834\n",
      "DEBUG:rasco:Iter #0 time: 5.94445\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.904558\n",
      "DEBUG:rasco:Iter #1 time: 5.93389\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.908231\n",
      "DEBUG:rasco:Iter #2 time: 5.90467\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.904302\n",
      "DEBUG:rasco:Iter #3 time: 5.9072\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.926705\n",
      "DEBUG:rasco:Iter #4 time: 6.03077\n",
      "DEBUG:rasco:Total time: 29.7246\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.915491\n",
      "DEBUG:rasco:Iter #0 time: 5.81465\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.910574\n",
      "DEBUG:rasco:Iter #1 time: 5.93479\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.902904\n",
      "DEBUG:rasco:Iter #2 time: 5.95958\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.886849\n",
      "DEBUG:rasco:Iter #3 time: 5.91066\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.907669\n",
      "DEBUG:rasco:Iter #4 time: 5.95429\n",
      "DEBUG:rasco:Total time: 29.5776\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.946115\n",
      "DEBUG:rasco:Iter #0 time: 5.84252\n",
      "DEBUG:rasco:Best candidate: pred_class=1 | Prob: 0.937545\n",
      "DEBUG:rasco:Iter #1 time: 5.93953\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.935726\n",
      "DEBUG:rasco:Iter #2 time: 5.80888\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.938617\n",
      "DEBUG:rasco:Iter #3 time: 5.91905\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.94478\n",
      "DEBUG:rasco:Iter #4 time: 5.94076\n",
      "DEBUG:rasco:Total time: 29.4544\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.973174\n",
      "DEBUG:rasco:Iter #0 time: 5.83199\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.968924\n",
      "DEBUG:rasco:Iter #1 time: 5.80665\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.97118\n",
      "DEBUG:rasco:Iter #2 time: 5.93468\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.968114\n",
      "DEBUG:rasco:Iter #3 time: 5.80552\n",
      "DEBUG:rasco:Best candidate: pred_class=0 | Prob: 0.965776\n",
      "DEBUG:rasco:Iter #4 time: 5.81932\n",
      "DEBUG:rasco:Total time: 29.2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score [0.19520612253275124]\n",
      "Score avg ensemble 0.195206122533\n",
      "Fold 2 Train time: 118.100 s\tPred time: 33.402 s\tScore [0.20393425330556705]\n",
      "Score avg ensemble 0.203934253306\n",
      "done\n",
      "Score: [ 0.20197332]\n",
      "Base Score: 0.20197332215\n",
      "lol [-0.008757804121674033, -0.0022976210660010515, -0.01221072178961156] -0.00775538232576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "%pdb off\n",
    "\n",
    "rasco_nb = rasco.Rasco(base_estimator=GaussianNB(),\n",
    "                       n_estimators=32, max_iters=20,\n",
    "                       verbose=True,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "rasco_dt = rasco.Rasco(base_estimator=DecisionTreeClassifier(),\n",
    "                       n_estimators=128, max_iters=20,\n",
    "                       verbose=True,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "rasco_gbm = rasco.Rasco(base_estimator=gbm_cat,\n",
    "                       n_estimators=8, max_iters=20,\n",
    "                       verbose=True,\n",
    "                      n_jobs=1)\n",
    "rasco_logistic = rasco.Rasco(base_estimator=LogisticRegression(),\n",
    "                            n_estimators=8, max_iters=10,\n",
    "                            verbose=True,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "h = [GaussianNB() for _ in range(64)] + \\\n",
    "    [DecisionTreeClassifier(max_depth=6, min_samples_split=5, class_weight='auto') for _ in range(16)] + \\\n",
    "    [SGDClassifier(n_iter=20, loss='modified_huber', class_weight='auto', n_jobs=1) \n",
    "     for _ in range(8)] + \\\n",
    "    [ExtraTreeClassifier(max_depth=6, min_samples_split=6, class_weight='auto')\n",
    "     for _ in range(16)]\n",
    "\n",
    "\n",
    "rasco_mix = rasco.Rasco(h,\n",
    "                        feat_ratio=0.6,\n",
    "                       n_estimators=104, max_iters=5,\n",
    "                       verbose=True,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "ord_rasco = simple.SimpleOrdinalClassifier(rasco_mix, n_jobs=1)\n",
    "\n",
    "ord_gbm_bin = simple.SimpleOrdinalClassifier(gbm_bin, n_jobs=1)\n",
    "ord_gaussnb_bin = simple.SimpleOrdinalClassifier(GaussianNB(), n_jobs=-1)\n",
    "ord_logistic_bin = simple.SimpleOrdinalClassifier(LogisticRegression(), n_jobs=-1)\n",
    "ord_rf_bin = simple.SimpleOrdinalClassifier(RandomForestClassifier(n_estimators=200, n_jobs=-1), n_jobs=1)\n",
    "ord_ada_bin = simple.SimpleOrdinalClassifier(AdaBoostClassifier(n_estimators=200), n_jobs=-1)\n",
    "ord_dt = simple.SimpleOrdinalClassifier(DecisionTreeClassifier(), n_jobs=-1)\n",
    "ord_lda = simple.SimpleOrdinalClassifier(LDA(solver='lsqr'), n_jobs=-1)\n",
    "\n",
    "# clf0 = simple.SimpleOrdinalClassifier(base_estimator_type=GaussianNB, base_estimator_params={}, n_jobs=1)\n",
    "# clf0 = simple.SimpleOrdinalClassifier(SVC(probability=True), n_jobs=8)\n",
    "# clf0 = simple.SimpleOrdinalClassifier(clf_nn, n_jobs=1)\n",
    "# clf0 = simple.SimpleOrdinalClassifier(base_estimator_type=KerasClassifier,\n",
    "#                                       base_estimator_params=nn_params,\n",
    "#                                       label_transformer=label_bin_tform,\n",
    "#                                       n_jobs=1)\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=-1, **{'max_leaf_nodes': None, \n",
    "                                         'bootstrap': False, \n",
    "                                         'min_samples_leaf': 8, \n",
    "                                         'n_estimators': 150, \n",
    "                                         'min_samples_split': 8, \n",
    "                                         'min_weight_fraction_leaf': 0.25, \n",
    "                                         'max_features': 'sqrt', \n",
    "                                         'max_depth': 12} )\n",
    "\n",
    "et = ExtraTreesRegressor(n_jobs=-1, **{'max_leaf_nodes': None, \n",
    "                                         'bootstrap': False, \n",
    "                                         'min_samples_leaf': 8, \n",
    "                                         'n_estimators': 150, \n",
    "                                         'min_samples_split': 8, \n",
    "                                         'min_weight_fraction_leaf': 0.25, \n",
    "                                         'max_features': 'sqrt', \n",
    "                                         'max_depth': 12} )\n",
    "\n",
    "stack = stacking.Stacking([\n",
    "        ord_gaussnb_bin,\n",
    "        ord_lda,\n",
    "        rf,\n",
    "        clf_nn,\n",
    "#         ord_rf_bin,\n",
    "#         ord_ada_bin,\n",
    "#         ord_logistic_bin,\n",
    "#         ord_gbm_bin,\n",
    "#         ann.ann(no_trees=50, num_neighbors=100, weights='distance'),\n",
    "#         KNeighborsRegressor(n_neighbors=20),\n",
    "\n",
    "        LinearRegression(),\n",
    "        Ridge(), \n",
    "#         BaggingRegressor(n_estimators=400, max_features=0.8, n_jobs=-1),\n",
    "#         ExtraTreesRegressor(n_estimators=400, n_jobs=-1), \n",
    "        \n",
    "#         gbm,\n",
    "    ],\n",
    "                          meta_gbm,\n",
    "#                           LinearRegression(),\n",
    "#                           gbm,\n",
    "                          fit_params={\n",
    "        'base0_y': 'y_binned',\n",
    "        'base1_y': 'y_binned',\n",
    "        'base3_X': 'X_nn_train',\n",
    "#         'base3_fit_batch_size': 1024*16,\n",
    "#         'base3_predict_batch_size': 1024*16,\n",
    "#         'base3_fit_nb_epoch': 500,\n",
    "        \n",
    "#         'base2_y': 'y_binned',\n",
    "    },\n",
    "                          pred_params={\n",
    "        'base3_X': 'X_nn_val',\n",
    "#         'base3_predict_batch_size': 1024*16,\n",
    "        \n",
    "#         'base0_weighted':True,\n",
    "#         'base1_weighted':True,\n",
    "    },\n",
    "                          include_orig_feats=False,\n",
    "                          use_probs=True,\n",
    "                          cv=8,\n",
    "                          verbose=1,\n",
    "                          save_level0_out=True,\n",
    "                          log_handler=fh,\n",
    "                         )\n",
    "# clfs = [clf0, gbm] \n",
    "# clfs = [clone(gbm), stack]\n",
    "# clfs = [LinearRegression(), stack]\n",
    "# clfs = [stack]\n",
    "# clfs = [BaggingRegressor(n_estimators=200, max_features=0.8, n_jobs=-1)]\n",
    "\n",
    "# clfs = [stack]\n",
    "clfs = [ord_rasco]\n",
    "# clfs = [rasco_mix]\n",
    "# clfs = []\n",
    "# clfs = [LinearRegression()]\n",
    "# clfs = [rf]\n",
    "\n",
    "\n",
    "\n",
    "# clfs = [rpfnn.rpfnn(leaf_size=100, no_trees=10, num_neighbors=100)]\n",
    "# clfs = [ann.ann(no_trees=50, num_neighbors=100, weights='distance')]\n",
    "\n",
    "# clfs = [ord_gaussnb_bin]\n",
    "# clfs = [ord_lda]\n",
    "# clfs = [simple.SimpleOrdinalClassifier(LDA(solver='lsqr'), n_jobs=-1)]\n",
    "# clfs = [clf1, clf2, ]\n",
    "\n",
    "\n",
    "# h = [clone(clf1), clone(clf2)]\n",
    "# clf = coreg.CoReg(h=h, T=5, verbose=True, n_jobs=1)\n",
    "\n",
    "scores = []\n",
    "scores_base = []\n",
    "lols = []\n",
    "n_reps = 1\n",
    "k = 3\n",
    "for reps in range(n_reps):\n",
    "    skf = StratifiedKFold(y_binned, n_folds=k,\n",
    "                          shuffle=True,\n",
    "                          random_state=np.random.randint(0,100))\n",
    "    for ii, (train, valid) in enumerate(skf):\n",
    "        \n",
    "        \n",
    "#         history = LossHistory()   # for keras\n",
    "        print 'Fold %d' % ii,\n",
    "        X_train_k, X_valid_k = X_train[train], X_train[valid]\n",
    "#         X_train_k, X_valid_k = X_fa40_train[train], X_fa40_train[valid]\n",
    "        y_train_k, y_valid_k = y_train[train], y_train[valid]\n",
    "        y_train_binned_k, y_valid_binned_k = y_binned[train], y_binned[valid]\n",
    "        \n",
    "        X_nn_train_k, X_nn_valid_k = X_nn[train], X_nn[valid]\n",
    "        \n",
    "        \n",
    "        X_all = np.r_[X_train_k, X_valid_k]\n",
    "        y_all = np.r_[y_train_k, np.nan*np.ones(len(y_valid_k))]\n",
    "        y_binned_all = np.r_[y_train_binned_k, np.nan*np.ones(len(y_valid_binned_k))]\n",
    "        \n",
    "        tic = time()\n",
    "#         clf.fit(X_train_k, y_train_k)\n",
    "#         clf.fit(X_all, y_all)\n",
    "\n",
    "\n",
    "        stack.extra_data['y_binned'] = y_train_binned_k\n",
    "        stack.extra_data['X_nn_train'] = X_nn_train_k\n",
    "        stack.extra_data['X_nn_val'] = X_nn_valid_k\n",
    "        \n",
    "        rasco_mix.y_val = y_valid_binned_k - 1\n",
    "        for clf in clfs:\n",
    "            clf.fit(X_all, y_binned_all-1)\n",
    "#             clf.fit(X_train_k, pipe_y.transform(y_train_k))\n",
    "#             clf.fit(X_train_k, y_train_binned_k-1)\n",
    "#             clf.fit(X_train_k, y_train_binned_k,\n",
    "#                    nb_epoch=60, batch_size=1024*16, )\n",
    "#             clf.fit(X_train_k, y_train_k, \n",
    "#                     base0_y=y_train_binned_k,\n",
    "#                     base1_y=y_train_binned_k,\n",
    "# #                     base2_y=y_train_binned_k,\n",
    "#                    )\n",
    "    \n",
    "    \n",
    "        \n",
    "        # Minirank\n",
    "#         w, theta = mr.ordinal_logistic_fit(X_train_k, y_train_k, verbose=False,\n",
    "#                                 solver='TNC')\n",
    "\n",
    "        \n",
    "        toc = time() - tic\n",
    "        print 'Train time: %2.3f s\\t' % toc,\n",
    "        tic = time()\n",
    "\n",
    "        \n",
    "        \n",
    "#         valid_preds = [clf.predict_weighted(X_valid_k,) \n",
    "#                        if hasattr(clf, 'predict_weighted') \n",
    "#                        else clf.predict(X_valid_k)\n",
    "#                        for clf in clfs]\n",
    "        \n",
    "        valid_preds = [clf.predict(X_valid_k) for clf in clfs]\n",
    "        \n",
    "#         valid_preds = [clf.predict_weighted(X_valid_k, batch_size=1024*16) \n",
    "#                if hasattr(clf, 'predict_weighted') \n",
    "#                else clf.predict(X_valid_k)\n",
    "#                for clf in clfs]\n",
    "        \n",
    "        try:\n",
    "            lol = metrics.normalized_gini(y_valid_k, \n",
    "                                          clfs[0].predict_weighted(X_valid_k, geometric=True))\n",
    "            lols.append(lol)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Minirank\n",
    "#         valid_preds = mr.ordinal_logistic_predict(w, theta, X_valid_k)\n",
    "        \n",
    "        valid_base_preds = np.mean([clf.predict(X_valid_k) for clf in clfs\n",
    "                                   ], \n",
    "                                   axis=0)\n",
    "\n",
    "        \n",
    "        score = [metrics.normalized_gini(y_valid_k, v) for v in valid_preds]\n",
    "        score_base = metrics.normalized_gini(y_valid_k, valid_base_preds)\n",
    "        \n",
    "        toc_pred = time() - tic\n",
    "        print 'Pred time: %2.3f s\\t' % toc_pred, \n",
    "        \n",
    "        print 'Score', score\n",
    "        print 'Score avg ensemble', score_base\n",
    "        scores.append(score)\n",
    "        scores_base.append(score_base)\n",
    "        \n",
    "#         break\n",
    "        \n",
    "        \n",
    "print \"done\"\n",
    "print 'Score:', np.array(scores).mean(axis=0)\n",
    "print 'Base Score:', np.array(scores_base).mean()\n",
    "print 'lol', lols, np.mean(lols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = clfs[0]\n",
    "q = clf.predict_proba(X_valid_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 7, ..., 4, 3, 9])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "est = stack.base_estimators[3]\n",
    "est.config_['layers'][-1]['output_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_train_k.shape\n",
    "print y_train_binned_k.shape\n",
    "# gbm is ~ 0.381  @ 30 sec per fold?\n",
    "# gbm on binned labels ~ 0.378 @ 30 sec per fold... ~_~\n",
    "# ordinal nn binned is like 0.34 with stdscaling X 60 epochs\n",
    "\n",
    "# the stack is worse?????? 0.379\n",
    "# added nn\n",
    "# stack including features meta gbm 0.369\n",
    "# move gbm to base and dont includebase ests (use linreg for meta) -> 0.377\n",
    "# increase folds cv=8 -> 0.379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: [ 0.37916189]\n",
      "Base Score: 0.379161888136\n",
      "lol [] nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print 'Score:', np.array(scores).mean(axis=0)\n",
    "print 'Base Score:', np.array(scores_base).mean()\n",
    "print 'lol', lols, np.mean(lols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.normalized_gini(y_valid_k, clfs[0].predict_weighted(X_valid_k, geometric=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_pred_base_hold.shape\n",
    "print y_hold[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33998, 14)\n",
      "(33998,)\n"
     ]
    }
   ],
   "source": [
    "X_stack = stack.level0_out[0]\n",
    "y_stack = stack.level0_out[1]\n",
    "print X_stack.shape\n",
    "print y_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.02278476049\n",
      "2.35284428496\n",
      "2.35945290095\n"
     ]
    }
   ],
   "source": [
    "print y_train.mean()\n",
    "print y_stack.mean()\n",
    "print y_train_k.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until val error hasn't decreased in 120 rounds.\n",
      "[0]\ttrain-rmse:2.233049\tval-rmse:2.233330\n",
      "[1]\ttrain-rmse:2.224972\tval-rmse:2.225478\n",
      "[2]\ttrain-rmse:2.216940\tval-rmse:2.217663\n",
      "[3]\ttrain-rmse:2.208930\tval-rmse:2.209854\n",
      "[4]\ttrain-rmse:2.201055\tval-rmse:2.202188\n",
      "[5]\ttrain-rmse:2.193213\tval-rmse:2.194567\n",
      "[6]\ttrain-rmse:2.185442\tval-rmse:2.187056\n",
      "[7]\ttrain-rmse:2.177714\tval-rmse:2.179523\n",
      "[8]\ttrain-rmse:2.169972\tval-rmse:2.172019\n",
      "[9]\ttrain-rmse:2.162337\tval-rmse:2.164564\n",
      "[10]\ttrain-rmse:2.154759\tval-rmse:2.157186\n",
      "[11]\ttrain-rmse:2.147175\tval-rmse:2.149861\n",
      "[12]\ttrain-rmse:2.139671\tval-rmse:2.142588\n",
      "[13]\ttrain-rmse:2.132219\tval-rmse:2.135376\n",
      "[14]\ttrain-rmse:2.124771\tval-rmse:2.128183\n",
      "[15]\ttrain-rmse:2.117374\tval-rmse:2.121008\n",
      "[16]\ttrain-rmse:2.110065\tval-rmse:2.113907\n",
      "[17]\ttrain-rmse:2.102777\tval-rmse:2.106839\n",
      "[18]\ttrain-rmse:2.095571\tval-rmse:2.099890\n",
      "[19]\ttrain-rmse:2.088372\tval-rmse:2.092894\n",
      "[20]\ttrain-rmse:2.081231\tval-rmse:2.085951\n",
      "[21]\ttrain-rmse:2.074061\tval-rmse:2.079023\n",
      "[22]\ttrain-rmse:2.066958\tval-rmse:2.072139\n",
      "[23]\ttrain-rmse:2.059922\tval-rmse:2.065351\n",
      "[24]\ttrain-rmse:2.052948\tval-rmse:2.058593\n",
      "[25]\ttrain-rmse:2.046000\tval-rmse:2.051887\n",
      "[26]\ttrain-rmse:2.039125\tval-rmse:2.045192\n",
      "[27]\ttrain-rmse:2.032261\tval-rmse:2.038549\n",
      "[28]\ttrain-rmse:2.025515\tval-rmse:2.032025\n",
      "[29]\ttrain-rmse:2.018782\tval-rmse:2.025505\n",
      "[30]\ttrain-rmse:2.012036\tval-rmse:2.019048\n",
      "[31]\ttrain-rmse:2.005337\tval-rmse:2.012621\n",
      "[32]\ttrain-rmse:1.998740\tval-rmse:2.006221\n",
      "[33]\ttrain-rmse:1.992128\tval-rmse:1.999818\n",
      "[34]\ttrain-rmse:1.985605\tval-rmse:1.993545\n",
      "[35]\ttrain-rmse:1.979126\tval-rmse:1.987322\n",
      "[36]\ttrain-rmse:1.972642\tval-rmse:1.981073\n",
      "[37]\ttrain-rmse:1.966219\tval-rmse:1.974937\n",
      "[38]\ttrain-rmse:1.959824\tval-rmse:1.968790\n",
      "[39]\ttrain-rmse:1.953468\tval-rmse:1.962722\n",
      "[40]\ttrain-rmse:1.947179\tval-rmse:1.956670\n",
      "[41]\ttrain-rmse:1.940971\tval-rmse:1.950695\n",
      "[42]\ttrain-rmse:1.934765\tval-rmse:1.944752\n",
      "[43]\ttrain-rmse:1.928599\tval-rmse:1.938822\n",
      "[44]\ttrain-rmse:1.922475\tval-rmse:1.932956\n",
      "[45]\ttrain-rmse:1.916353\tval-rmse:1.927111\n",
      "[46]\ttrain-rmse:1.910286\tval-rmse:1.921278\n",
      "[47]\ttrain-rmse:1.904217\tval-rmse:1.915511\n",
      "[48]\ttrain-rmse:1.898194\tval-rmse:1.909757\n",
      "[49]\ttrain-rmse:1.892211\tval-rmse:1.904055\n",
      "[50]\ttrain-rmse:1.886346\tval-rmse:1.898459\n",
      "[51]\ttrain-rmse:1.880439\tval-rmse:1.892811\n",
      "[52]\ttrain-rmse:1.874576\tval-rmse:1.887172\n",
      "[53]\ttrain-rmse:1.868758\tval-rmse:1.881602\n",
      "[54]\ttrain-rmse:1.862957\tval-rmse:1.876059\n",
      "[55]\ttrain-rmse:1.857267\tval-rmse:1.870621\n",
      "[56]\ttrain-rmse:1.851536\tval-rmse:1.865200\n",
      "[57]\ttrain-rmse:1.845876\tval-rmse:1.859782\n",
      "[58]\ttrain-rmse:1.840278\tval-rmse:1.854449\n",
      "[59]\ttrain-rmse:1.834755\tval-rmse:1.849140\n",
      "[60]\ttrain-rmse:1.829211\tval-rmse:1.843852\n",
      "[61]\ttrain-rmse:1.823702\tval-rmse:1.838605\n",
      "[62]\ttrain-rmse:1.818242\tval-rmse:1.833433\n",
      "[63]\ttrain-rmse:1.812863\tval-rmse:1.828314\n",
      "[64]\ttrain-rmse:1.807478\tval-rmse:1.823200\n",
      "[65]\ttrain-rmse:1.802171\tval-rmse:1.818118\n",
      "[66]\ttrain-rmse:1.796861\tval-rmse:1.813035\n",
      "[67]\ttrain-rmse:1.791547\tval-rmse:1.808031\n",
      "[68]\ttrain-rmse:1.786327\tval-rmse:1.803082\n",
      "[69]\ttrain-rmse:1.781160\tval-rmse:1.798176\n",
      "[70]\ttrain-rmse:1.775995\tval-rmse:1.793265\n",
      "[71]\ttrain-rmse:1.770838\tval-rmse:1.788389\n",
      "[72]\ttrain-rmse:1.765732\tval-rmse:1.783497\n",
      "[73]\ttrain-rmse:1.760675\tval-rmse:1.778684\n",
      "[74]\ttrain-rmse:1.755662\tval-rmse:1.773950\n",
      "[75]\ttrain-rmse:1.750673\tval-rmse:1.769203\n",
      "[76]\ttrain-rmse:1.745729\tval-rmse:1.764562\n",
      "[77]\ttrain-rmse:1.740782\tval-rmse:1.759903\n",
      "[78]\ttrain-rmse:1.735878\tval-rmse:1.755268\n",
      "[79]\ttrain-rmse:1.731023\tval-rmse:1.750652\n",
      "[80]\ttrain-rmse:1.726188\tval-rmse:1.746070\n",
      "[81]\ttrain-rmse:1.721389\tval-rmse:1.741566\n",
      "[82]\ttrain-rmse:1.716646\tval-rmse:1.737084\n",
      "[83]\ttrain-rmse:1.711918\tval-rmse:1.732587\n",
      "[84]\ttrain-rmse:1.707255\tval-rmse:1.728195\n",
      "[85]\ttrain-rmse:1.702554\tval-rmse:1.723812\n",
      "[86]\ttrain-rmse:1.697884\tval-rmse:1.719465\n",
      "[87]\ttrain-rmse:1.693303\tval-rmse:1.715150\n",
      "[88]\ttrain-rmse:1.688712\tval-rmse:1.710850\n",
      "[89]\ttrain-rmse:1.684183\tval-rmse:1.706623\n",
      "[90]\ttrain-rmse:1.679686\tval-rmse:1.702386\n",
      "[91]\ttrain-rmse:1.675175\tval-rmse:1.698132\n",
      "[92]\ttrain-rmse:1.670770\tval-rmse:1.693976\n",
      "[93]\ttrain-rmse:1.666334\tval-rmse:1.689818\n",
      "[94]\ttrain-rmse:1.661943\tval-rmse:1.685700\n",
      "[95]\ttrain-rmse:1.657590\tval-rmse:1.681646\n",
      "[96]\ttrain-rmse:1.653232\tval-rmse:1.677592\n",
      "[97]\ttrain-rmse:1.648925\tval-rmse:1.673544\n",
      "[98]\ttrain-rmse:1.644706\tval-rmse:1.669594\n",
      "[99]\ttrain-rmse:1.640474\tval-rmse:1.665671\n",
      "[100]\ttrain-rmse:1.636225\tval-rmse:1.661667\n",
      "[101]\ttrain-rmse:1.632020\tval-rmse:1.657711\n",
      "[102]\ttrain-rmse:1.627872\tval-rmse:1.653823\n",
      "[103]\ttrain-rmse:1.623764\tval-rmse:1.649977\n",
      "[104]\ttrain-rmse:1.619663\tval-rmse:1.646201\n",
      "[105]\ttrain-rmse:1.615640\tval-rmse:1.642443\n",
      "[106]\ttrain-rmse:1.611582\tval-rmse:1.638683\n",
      "[107]\ttrain-rmse:1.607545\tval-rmse:1.634929\n",
      "[108]\ttrain-rmse:1.603536\tval-rmse:1.631194\n",
      "[109]\ttrain-rmse:1.599553\tval-rmse:1.627550\n",
      "[110]\ttrain-rmse:1.595638\tval-rmse:1.623909\n",
      "[111]\ttrain-rmse:1.591762\tval-rmse:1.620282\n",
      "[112]\ttrain-rmse:1.587900\tval-rmse:1.616681\n",
      "[113]\ttrain-rmse:1.584092\tval-rmse:1.613135\n",
      "[114]\ttrain-rmse:1.580274\tval-rmse:1.609612\n",
      "[115]\ttrain-rmse:1.576462\tval-rmse:1.606112\n",
      "[116]\ttrain-rmse:1.572774\tval-rmse:1.602653\n",
      "[117]\ttrain-rmse:1.569077\tval-rmse:1.599227\n",
      "[118]\ttrain-rmse:1.565419\tval-rmse:1.595862\n",
      "[119]\ttrain-rmse:1.561752\tval-rmse:1.592456\n",
      "[120]\ttrain-rmse:1.558128\tval-rmse:1.589114\n",
      "[121]\ttrain-rmse:1.554475\tval-rmse:1.585762\n",
      "[122]\ttrain-rmse:1.550865\tval-rmse:1.582465\n",
      "[123]\ttrain-rmse:1.547274\tval-rmse:1.579209\n",
      "[124]\ttrain-rmse:1.543745\tval-rmse:1.575969\n",
      "[125]\ttrain-rmse:1.540253\tval-rmse:1.572720\n",
      "[126]\ttrain-rmse:1.536800\tval-rmse:1.569494\n",
      "[127]\ttrain-rmse:1.533292\tval-rmse:1.566272\n",
      "[128]\ttrain-rmse:1.529855\tval-rmse:1.563090\n",
      "[129]\ttrain-rmse:1.526352\tval-rmse:1.559920\n",
      "[130]\ttrain-rmse:1.522895\tval-rmse:1.556775\n",
      "[131]\ttrain-rmse:1.519569\tval-rmse:1.553720\n",
      "[132]\ttrain-rmse:1.516235\tval-rmse:1.550626\n",
      "[133]\ttrain-rmse:1.512920\tval-rmse:1.547598\n",
      "[134]\ttrain-rmse:1.509607\tval-rmse:1.544552\n",
      "[135]\ttrain-rmse:1.506320\tval-rmse:1.541556\n",
      "[136]\ttrain-rmse:1.503111\tval-rmse:1.538576\n",
      "[137]\ttrain-rmse:1.499880\tval-rmse:1.535642\n",
      "[138]\ttrain-rmse:1.496670\tval-rmse:1.532700\n",
      "[139]\ttrain-rmse:1.493451\tval-rmse:1.529792\n",
      "[140]\ttrain-rmse:1.490291\tval-rmse:1.526947\n",
      "[141]\ttrain-rmse:1.487221\tval-rmse:1.524108\n",
      "[142]\ttrain-rmse:1.484124\tval-rmse:1.521276\n",
      "[143]\ttrain-rmse:1.481069\tval-rmse:1.518463\n",
      "[144]\ttrain-rmse:1.477977\tval-rmse:1.515684\n",
      "[145]\ttrain-rmse:1.474939\tval-rmse:1.512914\n",
      "[146]\ttrain-rmse:1.471930\tval-rmse:1.510180\n",
      "[147]\ttrain-rmse:1.468939\tval-rmse:1.507465\n",
      "[148]\ttrain-rmse:1.465964\tval-rmse:1.504774\n",
      "[149]\ttrain-rmse:1.463025\tval-rmse:1.502105\n",
      "[150]\ttrain-rmse:1.460118\tval-rmse:1.499449\n",
      "[151]\ttrain-rmse:1.457145\tval-rmse:1.496806\n",
      "[152]\ttrain-rmse:1.454225\tval-rmse:1.494209\n",
      "[153]\ttrain-rmse:1.451361\tval-rmse:1.491664\n",
      "[154]\ttrain-rmse:1.448489\tval-rmse:1.489081\n",
      "[155]\ttrain-rmse:1.445615\tval-rmse:1.486565\n",
      "[156]\ttrain-rmse:1.442804\tval-rmse:1.484031\n",
      "[157]\ttrain-rmse:1.440036\tval-rmse:1.481501\n",
      "[158]\ttrain-rmse:1.437272\tval-rmse:1.479002\n",
      "[159]\ttrain-rmse:1.434537\tval-rmse:1.476536\n",
      "[160]\ttrain-rmse:1.431830\tval-rmse:1.474049\n",
      "[161]\ttrain-rmse:1.429109\tval-rmse:1.471616\n",
      "[162]\ttrain-rmse:1.426418\tval-rmse:1.469250\n",
      "[163]\ttrain-rmse:1.423768\tval-rmse:1.466871\n",
      "[164]\ttrain-rmse:1.421127\tval-rmse:1.464579\n",
      "[165]\ttrain-rmse:1.418510\tval-rmse:1.462229\n",
      "[166]\ttrain-rmse:1.415913\tval-rmse:1.459863\n",
      "[167]\ttrain-rmse:1.413298\tval-rmse:1.457556\n",
      "[168]\ttrain-rmse:1.410658\tval-rmse:1.455291\n",
      "[169]\ttrain-rmse:1.408107\tval-rmse:1.453033\n",
      "[170]\ttrain-rmse:1.405526\tval-rmse:1.450769\n",
      "[171]\ttrain-rmse:1.402947\tval-rmse:1.448525\n",
      "[172]\ttrain-rmse:1.400463\tval-rmse:1.446317\n",
      "[173]\ttrain-rmse:1.397981\tval-rmse:1.444117\n",
      "[174]\ttrain-rmse:1.395496\tval-rmse:1.441922\n",
      "[175]\ttrain-rmse:1.393056\tval-rmse:1.439760\n",
      "[176]\ttrain-rmse:1.390635\tval-rmse:1.437642\n",
      "[177]\ttrain-rmse:1.388227\tval-rmse:1.435487\n",
      "[178]\ttrain-rmse:1.385787\tval-rmse:1.433340\n",
      "[179]\ttrain-rmse:1.383400\tval-rmse:1.431228\n",
      "[180]\ttrain-rmse:1.380991\tval-rmse:1.429179\n",
      "[181]\ttrain-rmse:1.378659\tval-rmse:1.427127\n",
      "[182]\ttrain-rmse:1.376363\tval-rmse:1.425116\n",
      "[183]\ttrain-rmse:1.374071\tval-rmse:1.423070\n",
      "[184]\ttrain-rmse:1.371851\tval-rmse:1.421062\n",
      "[185]\ttrain-rmse:1.369596\tval-rmse:1.419101\n",
      "[186]\ttrain-rmse:1.367284\tval-rmse:1.417145\n",
      "[187]\ttrain-rmse:1.365105\tval-rmse:1.415175\n",
      "[188]\ttrain-rmse:1.362895\tval-rmse:1.413239\n",
      "[189]\ttrain-rmse:1.360669\tval-rmse:1.411308\n",
      "[190]\ttrain-rmse:1.358454\tval-rmse:1.409399\n",
      "[191]\ttrain-rmse:1.356218\tval-rmse:1.407509\n",
      "[192]\ttrain-rmse:1.354076\tval-rmse:1.405636\n",
      "[193]\ttrain-rmse:1.352006\tval-rmse:1.403805\n",
      "[194]\ttrain-rmse:1.349857\tval-rmse:1.401961\n",
      "[195]\ttrain-rmse:1.347741\tval-rmse:1.400113\n",
      "[196]\ttrain-rmse:1.345706\tval-rmse:1.398288\n",
      "[197]\ttrain-rmse:1.343627\tval-rmse:1.396458\n",
      "[198]\ttrain-rmse:1.341559\tval-rmse:1.394658\n",
      "[199]\ttrain-rmse:1.339507\tval-rmse:1.392915\n",
      "[200]\ttrain-rmse:1.337481\tval-rmse:1.391125\n",
      "[201]\ttrain-rmse:1.335444\tval-rmse:1.389376\n",
      "[202]\ttrain-rmse:1.333533\tval-rmse:1.387668\n",
      "[203]\ttrain-rmse:1.331641\tval-rmse:1.385963\n",
      "[204]\ttrain-rmse:1.329701\tval-rmse:1.384322\n",
      "[205]\ttrain-rmse:1.327788\tval-rmse:1.382631\n",
      "[206]\ttrain-rmse:1.325911\tval-rmse:1.380992\n",
      "[207]\ttrain-rmse:1.323993\tval-rmse:1.379367\n",
      "[208]\ttrain-rmse:1.322092\tval-rmse:1.377749\n",
      "[209]\ttrain-rmse:1.320202\tval-rmse:1.376155\n",
      "[210]\ttrain-rmse:1.318387\tval-rmse:1.374555\n",
      "[211]\ttrain-rmse:1.316549\tval-rmse:1.372974\n",
      "[212]\ttrain-rmse:1.314739\tval-rmse:1.371401\n",
      "[213]\ttrain-rmse:1.312954\tval-rmse:1.369817\n",
      "[214]\ttrain-rmse:1.311111\tval-rmse:1.368282\n",
      "[215]\ttrain-rmse:1.309351\tval-rmse:1.366780\n",
      "[216]\ttrain-rmse:1.307535\tval-rmse:1.365245\n",
      "[217]\ttrain-rmse:1.305827\tval-rmse:1.363737\n",
      "[218]\ttrain-rmse:1.304081\tval-rmse:1.362235\n",
      "[219]\ttrain-rmse:1.302340\tval-rmse:1.360796\n",
      "[220]\ttrain-rmse:1.300631\tval-rmse:1.359325\n",
      "[221]\ttrain-rmse:1.298886\tval-rmse:1.357862\n",
      "[222]\ttrain-rmse:1.297169\tval-rmse:1.356430\n",
      "[223]\ttrain-rmse:1.295449\tval-rmse:1.354994\n",
      "[224]\ttrain-rmse:1.293755\tval-rmse:1.353587\n",
      "[225]\ttrain-rmse:1.292083\tval-rmse:1.352172\n",
      "[226]\ttrain-rmse:1.290396\tval-rmse:1.350760\n",
      "[227]\ttrain-rmse:1.288791\tval-rmse:1.349395\n",
      "[228]\ttrain-rmse:1.287173\tval-rmse:1.348032\n",
      "[229]\ttrain-rmse:1.285553\tval-rmse:1.346686\n",
      "[230]\ttrain-rmse:1.283955\tval-rmse:1.345320\n",
      "[231]\ttrain-rmse:1.282346\tval-rmse:1.343977\n",
      "[232]\ttrain-rmse:1.280760\tval-rmse:1.342648\n",
      "[233]\ttrain-rmse:1.279177\tval-rmse:1.341352\n",
      "[234]\ttrain-rmse:1.277667\tval-rmse:1.340057\n",
      "[235]\ttrain-rmse:1.276135\tval-rmse:1.338817\n",
      "[236]\ttrain-rmse:1.274602\tval-rmse:1.337503\n",
      "[237]\ttrain-rmse:1.273038\tval-rmse:1.336231\n",
      "[238]\ttrain-rmse:1.271584\tval-rmse:1.334972\n",
      "[239]\ttrain-rmse:1.270102\tval-rmse:1.333740\n",
      "[240]\ttrain-rmse:1.268560\tval-rmse:1.332514\n",
      "[241]\ttrain-rmse:1.267130\tval-rmse:1.331306\n",
      "[242]\ttrain-rmse:1.265665\tval-rmse:1.330115\n",
      "[243]\ttrain-rmse:1.264197\tval-rmse:1.328915\n",
      "[244]\ttrain-rmse:1.262764\tval-rmse:1.327740\n",
      "[245]\ttrain-rmse:1.261352\tval-rmse:1.326584\n",
      "[246]\ttrain-rmse:1.259920\tval-rmse:1.325414\n",
      "[247]\ttrain-rmse:1.258499\tval-rmse:1.324258\n",
      "[248]\ttrain-rmse:1.257135\tval-rmse:1.323135\n",
      "[249]\ttrain-rmse:1.255681\tval-rmse:1.322034\n",
      "[250]\ttrain-rmse:1.254343\tval-rmse:1.320920\n",
      "[251]\ttrain-rmse:1.252971\tval-rmse:1.319824\n",
      "[252]\ttrain-rmse:1.251607\tval-rmse:1.318726\n",
      "[253]\ttrain-rmse:1.250261\tval-rmse:1.317656\n",
      "[254]\ttrain-rmse:1.248949\tval-rmse:1.316611\n",
      "[255]\ttrain-rmse:1.247581\tval-rmse:1.315523\n",
      "[256]\ttrain-rmse:1.246248\tval-rmse:1.314448\n",
      "[257]\ttrain-rmse:1.244958\tval-rmse:1.313404\n",
      "[258]\ttrain-rmse:1.243589\tval-rmse:1.312334\n",
      "[259]\ttrain-rmse:1.242358\tval-rmse:1.311320\n",
      "[260]\ttrain-rmse:1.241107\tval-rmse:1.310283\n",
      "[261]\ttrain-rmse:1.239872\tval-rmse:1.309259\n",
      "[262]\ttrain-rmse:1.238638\tval-rmse:1.308245\n",
      "[263]\ttrain-rmse:1.237393\tval-rmse:1.307235\n",
      "[264]\ttrain-rmse:1.236166\tval-rmse:1.306249\n",
      "[265]\ttrain-rmse:1.234934\tval-rmse:1.305263\n",
      "[266]\ttrain-rmse:1.233744\tval-rmse:1.304301\n",
      "[267]\ttrain-rmse:1.232514\tval-rmse:1.303344\n",
      "[268]\ttrain-rmse:1.231345\tval-rmse:1.302405\n",
      "[269]\ttrain-rmse:1.230165\tval-rmse:1.301457\n",
      "[270]\ttrain-rmse:1.228950\tval-rmse:1.300514\n",
      "[271]\ttrain-rmse:1.227832\tval-rmse:1.299591\n",
      "[272]\ttrain-rmse:1.226707\tval-rmse:1.298676\n",
      "[273]\ttrain-rmse:1.225588\tval-rmse:1.297769\n",
      "[274]\ttrain-rmse:1.224490\tval-rmse:1.296879\n",
      "[275]\ttrain-rmse:1.223339\tval-rmse:1.295970\n",
      "[276]\ttrain-rmse:1.222218\tval-rmse:1.295116\n",
      "[277]\ttrain-rmse:1.221125\tval-rmse:1.294237\n",
      "[278]\ttrain-rmse:1.220102\tval-rmse:1.293375\n",
      "[279]\ttrain-rmse:1.219005\tval-rmse:1.292492\n",
      "[280]\ttrain-rmse:1.217935\tval-rmse:1.291630\n",
      "[281]\ttrain-rmse:1.216885\tval-rmse:1.290789\n",
      "[282]\ttrain-rmse:1.215872\tval-rmse:1.289951\n",
      "[283]\ttrain-rmse:1.214809\tval-rmse:1.289118\n",
      "[284]\ttrain-rmse:1.213734\tval-rmse:1.288309\n",
      "[285]\ttrain-rmse:1.212707\tval-rmse:1.287498\n",
      "[286]\ttrain-rmse:1.211666\tval-rmse:1.286689\n",
      "[287]\ttrain-rmse:1.210666\tval-rmse:1.285912\n",
      "[288]\ttrain-rmse:1.209581\tval-rmse:1.285124\n",
      "[289]\ttrain-rmse:1.208514\tval-rmse:1.284324\n",
      "[290]\ttrain-rmse:1.207499\tval-rmse:1.283555\n",
      "[291]\ttrain-rmse:1.206520\tval-rmse:1.282800\n",
      "[292]\ttrain-rmse:1.205510\tval-rmse:1.282056\n",
      "[293]\ttrain-rmse:1.204504\tval-rmse:1.281297\n",
      "[294]\ttrain-rmse:1.203526\tval-rmse:1.280563\n",
      "[295]\ttrain-rmse:1.202564\tval-rmse:1.279820\n",
      "[296]\ttrain-rmse:1.201562\tval-rmse:1.279090\n",
      "[297]\ttrain-rmse:1.200622\tval-rmse:1.278359\n",
      "[298]\ttrain-rmse:1.199687\tval-rmse:1.277617\n",
      "[299]\ttrain-rmse:1.198777\tval-rmse:1.276904\n",
      "[300]\ttrain-rmse:1.197849\tval-rmse:1.276196\n",
      "[301]\ttrain-rmse:1.196913\tval-rmse:1.275511\n",
      "[302]\ttrain-rmse:1.195991\tval-rmse:1.274799\n",
      "[303]\ttrain-rmse:1.195053\tval-rmse:1.274117\n",
      "[304]\ttrain-rmse:1.194123\tval-rmse:1.273434\n",
      "[305]\ttrain-rmse:1.193208\tval-rmse:1.272782\n",
      "[306]\ttrain-rmse:1.192319\tval-rmse:1.272129\n",
      "[307]\ttrain-rmse:1.191447\tval-rmse:1.271453\n",
      "[308]\ttrain-rmse:1.190541\tval-rmse:1.270820\n",
      "[309]\ttrain-rmse:1.189701\tval-rmse:1.270174\n",
      "[310]\ttrain-rmse:1.188822\tval-rmse:1.269519\n",
      "[311]\ttrain-rmse:1.187918\tval-rmse:1.268891\n",
      "[312]\ttrain-rmse:1.187092\tval-rmse:1.268279\n",
      "[313]\ttrain-rmse:1.186300\tval-rmse:1.267646\n",
      "[314]\ttrain-rmse:1.185424\tval-rmse:1.266994\n",
      "[315]\ttrain-rmse:1.184550\tval-rmse:1.266368\n",
      "[316]\ttrain-rmse:1.183675\tval-rmse:1.265764\n",
      "[317]\ttrain-rmse:1.182847\tval-rmse:1.265155\n",
      "[318]\ttrain-rmse:1.182008\tval-rmse:1.264545\n",
      "[319]\ttrain-rmse:1.181231\tval-rmse:1.263969\n",
      "[320]\ttrain-rmse:1.180366\tval-rmse:1.263414\n",
      "[321]\ttrain-rmse:1.179489\tval-rmse:1.262821\n",
      "[322]\ttrain-rmse:1.178714\tval-rmse:1.262234\n",
      "[323]\ttrain-rmse:1.177992\tval-rmse:1.261683\n",
      "[324]\ttrain-rmse:1.177229\tval-rmse:1.261110\n",
      "[325]\ttrain-rmse:1.176431\tval-rmse:1.260556\n",
      "[326]\ttrain-rmse:1.175624\tval-rmse:1.260013\n",
      "[327]\ttrain-rmse:1.174810\tval-rmse:1.259467\n",
      "[328]\ttrain-rmse:1.174024\tval-rmse:1.258906\n",
      "[329]\ttrain-rmse:1.173255\tval-rmse:1.258345\n",
      "[330]\ttrain-rmse:1.172510\tval-rmse:1.257796\n",
      "[331]\ttrain-rmse:1.171747\tval-rmse:1.257309\n",
      "[332]\ttrain-rmse:1.171021\tval-rmse:1.256795\n",
      "[333]\ttrain-rmse:1.170316\tval-rmse:1.256295\n",
      "[334]\ttrain-rmse:1.169552\tval-rmse:1.255787\n",
      "[335]\ttrain-rmse:1.168832\tval-rmse:1.255272\n",
      "[336]\ttrain-rmse:1.168174\tval-rmse:1.254774\n",
      "[337]\ttrain-rmse:1.167410\tval-rmse:1.254267\n",
      "[338]\ttrain-rmse:1.166715\tval-rmse:1.253776\n",
      "[339]\ttrain-rmse:1.166046\tval-rmse:1.253281\n",
      "[340]\ttrain-rmse:1.165382\tval-rmse:1.252806\n",
      "[341]\ttrain-rmse:1.164740\tval-rmse:1.252330\n",
      "[342]\ttrain-rmse:1.164064\tval-rmse:1.251861\n",
      "[343]\ttrain-rmse:1.163441\tval-rmse:1.251392\n",
      "[344]\ttrain-rmse:1.162749\tval-rmse:1.250951\n",
      "[345]\ttrain-rmse:1.162076\tval-rmse:1.250487\n",
      "[346]\ttrain-rmse:1.161358\tval-rmse:1.250006\n",
      "[347]\ttrain-rmse:1.160607\tval-rmse:1.249561\n",
      "[348]\ttrain-rmse:1.159957\tval-rmse:1.249112\n",
      "[349]\ttrain-rmse:1.159240\tval-rmse:1.248660\n",
      "[350]\ttrain-rmse:1.158580\tval-rmse:1.248232\n",
      "[351]\ttrain-rmse:1.157969\tval-rmse:1.247790\n",
      "[352]\ttrain-rmse:1.157276\tval-rmse:1.247353\n",
      "[353]\ttrain-rmse:1.156633\tval-rmse:1.246923\n",
      "[354]\ttrain-rmse:1.156019\tval-rmse:1.246505\n",
      "[355]\ttrain-rmse:1.155383\tval-rmse:1.246079\n",
      "[356]\ttrain-rmse:1.154745\tval-rmse:1.245666\n",
      "[357]\ttrain-rmse:1.154105\tval-rmse:1.245272\n",
      "[358]\ttrain-rmse:1.153542\tval-rmse:1.244855\n",
      "[359]\ttrain-rmse:1.153007\tval-rmse:1.244451\n",
      "[360]\ttrain-rmse:1.152410\tval-rmse:1.244027\n",
      "[361]\ttrain-rmse:1.151844\tval-rmse:1.243618\n",
      "[362]\ttrain-rmse:1.151223\tval-rmse:1.243225\n",
      "[363]\ttrain-rmse:1.150607\tval-rmse:1.242840\n",
      "[364]\ttrain-rmse:1.149958\tval-rmse:1.242456\n",
      "[365]\ttrain-rmse:1.149393\tval-rmse:1.242069\n",
      "[366]\ttrain-rmse:1.148812\tval-rmse:1.241687\n",
      "[367]\ttrain-rmse:1.148215\tval-rmse:1.241320\n",
      "[368]\ttrain-rmse:1.147645\tval-rmse:1.240953\n",
      "[369]\ttrain-rmse:1.147135\tval-rmse:1.240599\n",
      "[370]\ttrain-rmse:1.146540\tval-rmse:1.240257\n",
      "[371]\ttrain-rmse:1.145929\tval-rmse:1.239902\n",
      "[372]\ttrain-rmse:1.145338\tval-rmse:1.239543\n",
      "[373]\ttrain-rmse:1.144779\tval-rmse:1.239198\n",
      "[374]\ttrain-rmse:1.144277\tval-rmse:1.238853\n",
      "[375]\ttrain-rmse:1.143669\tval-rmse:1.238530\n",
      "[376]\ttrain-rmse:1.143135\tval-rmse:1.238187\n",
      "[377]\ttrain-rmse:1.142546\tval-rmse:1.237849\n",
      "[378]\ttrain-rmse:1.142013\tval-rmse:1.237523\n",
      "[379]\ttrain-rmse:1.141461\tval-rmse:1.237205\n",
      "[380]\ttrain-rmse:1.140918\tval-rmse:1.236884\n",
      "[381]\ttrain-rmse:1.140369\tval-rmse:1.236564\n",
      "[382]\ttrain-rmse:1.139857\tval-rmse:1.236230\n",
      "[383]\ttrain-rmse:1.139271\tval-rmse:1.235925\n",
      "[384]\ttrain-rmse:1.138764\tval-rmse:1.235612\n",
      "[385]\ttrain-rmse:1.138258\tval-rmse:1.235309\n",
      "[386]\ttrain-rmse:1.137780\tval-rmse:1.235031\n",
      "[387]\ttrain-rmse:1.137209\tval-rmse:1.234736\n",
      "[388]\ttrain-rmse:1.136649\tval-rmse:1.234446\n",
      "[389]\ttrain-rmse:1.136091\tval-rmse:1.234144\n",
      "[390]\ttrain-rmse:1.135617\tval-rmse:1.233849\n",
      "[391]\ttrain-rmse:1.135093\tval-rmse:1.233566\n",
      "[392]\ttrain-rmse:1.134644\tval-rmse:1.233269\n",
      "[393]\ttrain-rmse:1.134133\tval-rmse:1.232994\n",
      "[394]\ttrain-rmse:1.133672\tval-rmse:1.232704\n",
      "[395]\ttrain-rmse:1.133153\tval-rmse:1.232406\n",
      "[396]\ttrain-rmse:1.132713\tval-rmse:1.232124\n",
      "[397]\ttrain-rmse:1.132223\tval-rmse:1.231846\n",
      "[398]\ttrain-rmse:1.131723\tval-rmse:1.231588\n",
      "[399]\ttrain-rmse:1.131299\tval-rmse:1.231314\n",
      "[400]\ttrain-rmse:1.130899\tval-rmse:1.231027\n",
      "[401]\ttrain-rmse:1.130364\tval-rmse:1.230758\n",
      "[402]\ttrain-rmse:1.129911\tval-rmse:1.230516\n",
      "[403]\ttrain-rmse:1.129483\tval-rmse:1.230251\n",
      "[404]\ttrain-rmse:1.129067\tval-rmse:1.229984\n",
      "[405]\ttrain-rmse:1.128617\tval-rmse:1.229727\n",
      "[406]\ttrain-rmse:1.128202\tval-rmse:1.229473\n",
      "[407]\ttrain-rmse:1.127745\tval-rmse:1.229203\n",
      "[408]\ttrain-rmse:1.127317\tval-rmse:1.228961\n",
      "[409]\ttrain-rmse:1.126889\tval-rmse:1.228717\n",
      "[410]\ttrain-rmse:1.126484\tval-rmse:1.228465\n",
      "[411]\ttrain-rmse:1.126044\tval-rmse:1.228223\n",
      "[412]\ttrain-rmse:1.125559\tval-rmse:1.227995\n",
      "[413]\ttrain-rmse:1.125151\tval-rmse:1.227747\n",
      "[414]\ttrain-rmse:1.124770\tval-rmse:1.227525\n",
      "[415]\ttrain-rmse:1.124406\tval-rmse:1.227286\n",
      "[416]\ttrain-rmse:1.124022\tval-rmse:1.227065\n",
      "[417]\ttrain-rmse:1.123646\tval-rmse:1.226835\n",
      "[418]\ttrain-rmse:1.123166\tval-rmse:1.226609\n",
      "[419]\ttrain-rmse:1.122744\tval-rmse:1.226383\n",
      "[420]\ttrain-rmse:1.122384\tval-rmse:1.226156\n",
      "[421]\ttrain-rmse:1.122045\tval-rmse:1.225920\n",
      "[422]\ttrain-rmse:1.121525\tval-rmse:1.225725\n",
      "[423]\ttrain-rmse:1.121084\tval-rmse:1.225526\n",
      "[424]\ttrain-rmse:1.120697\tval-rmse:1.225334\n",
      "[425]\ttrain-rmse:1.120339\tval-rmse:1.225106\n",
      "[426]\ttrain-rmse:1.119953\tval-rmse:1.224928\n",
      "[427]\ttrain-rmse:1.119596\tval-rmse:1.224733\n",
      "[428]\ttrain-rmse:1.119252\tval-rmse:1.224528\n",
      "[429]\ttrain-rmse:1.118821\tval-rmse:1.224325\n",
      "[430]\ttrain-rmse:1.118450\tval-rmse:1.224121\n",
      "[431]\ttrain-rmse:1.118098\tval-rmse:1.223928\n",
      "[432]\ttrain-rmse:1.117741\tval-rmse:1.223722\n",
      "[433]\ttrain-rmse:1.117330\tval-rmse:1.223520\n",
      "[434]\ttrain-rmse:1.116919\tval-rmse:1.223339\n",
      "[435]\ttrain-rmse:1.116634\tval-rmse:1.223161\n",
      "[436]\ttrain-rmse:1.116281\tval-rmse:1.222970\n",
      "[437]\ttrain-rmse:1.115944\tval-rmse:1.222787\n",
      "[438]\ttrain-rmse:1.115584\tval-rmse:1.222591\n",
      "[439]\ttrain-rmse:1.115237\tval-rmse:1.222404\n",
      "[440]\ttrain-rmse:1.114823\tval-rmse:1.222234\n",
      "[441]\ttrain-rmse:1.114424\tval-rmse:1.222027\n",
      "[442]\ttrain-rmse:1.114127\tval-rmse:1.221849\n",
      "[443]\ttrain-rmse:1.113813\tval-rmse:1.221644\n",
      "[444]\ttrain-rmse:1.113505\tval-rmse:1.221480\n",
      "[445]\ttrain-rmse:1.113131\tval-rmse:1.221302\n",
      "[446]\ttrain-rmse:1.112777\tval-rmse:1.221134\n",
      "[447]\ttrain-rmse:1.112460\tval-rmse:1.220967\n",
      "[448]\ttrain-rmse:1.112100\tval-rmse:1.220797\n",
      "[449]\ttrain-rmse:1.111702\tval-rmse:1.220648\n",
      "[450]\ttrain-rmse:1.111377\tval-rmse:1.220484\n",
      "[451]\ttrain-rmse:1.111027\tval-rmse:1.220305\n",
      "[452]\ttrain-rmse:1.110707\tval-rmse:1.220133\n",
      "[453]\ttrain-rmse:1.110388\tval-rmse:1.219984\n",
      "[454]\ttrain-rmse:1.110091\tval-rmse:1.219820\n",
      "[455]\ttrain-rmse:1.109695\tval-rmse:1.219662\n",
      "[456]\ttrain-rmse:1.109371\tval-rmse:1.219508\n",
      "[457]\ttrain-rmse:1.109065\tval-rmse:1.219360\n",
      "[458]\ttrain-rmse:1.108725\tval-rmse:1.219193\n",
      "[459]\ttrain-rmse:1.108422\tval-rmse:1.219065\n",
      "[460]\ttrain-rmse:1.108102\tval-rmse:1.218932\n",
      "[461]\ttrain-rmse:1.107704\tval-rmse:1.218786\n",
      "[462]\ttrain-rmse:1.107411\tval-rmse:1.218639\n",
      "[463]\ttrain-rmse:1.107161\tval-rmse:1.218499\n",
      "[464]\ttrain-rmse:1.106820\tval-rmse:1.218356\n",
      "[465]\ttrain-rmse:1.106542\tval-rmse:1.218233\n",
      "[466]\ttrain-rmse:1.106252\tval-rmse:1.218098\n",
      "[467]\ttrain-rmse:1.105902\tval-rmse:1.217968\n",
      "[468]\ttrain-rmse:1.105620\tval-rmse:1.217834\n",
      "[469]\ttrain-rmse:1.105244\tval-rmse:1.217683\n",
      "[470]\ttrain-rmse:1.104919\tval-rmse:1.217543\n",
      "[471]\ttrain-rmse:1.104581\tval-rmse:1.217411\n",
      "[472]\ttrain-rmse:1.104312\tval-rmse:1.217284\n",
      "[473]\ttrain-rmse:1.103964\tval-rmse:1.217152\n",
      "[474]\ttrain-rmse:1.103657\tval-rmse:1.217023\n",
      "[475]\ttrain-rmse:1.103328\tval-rmse:1.216882\n",
      "[476]\ttrain-rmse:1.103034\tval-rmse:1.216768\n",
      "[477]\ttrain-rmse:1.102761\tval-rmse:1.216638\n",
      "[478]\ttrain-rmse:1.102481\tval-rmse:1.216509\n",
      "[479]\ttrain-rmse:1.102140\tval-rmse:1.216394\n",
      "[480]\ttrain-rmse:1.101819\tval-rmse:1.216264\n",
      "[481]\ttrain-rmse:1.101511\tval-rmse:1.216149\n",
      "[482]\ttrain-rmse:1.101203\tval-rmse:1.216012\n",
      "[483]\ttrain-rmse:1.100950\tval-rmse:1.215881\n",
      "[484]\ttrain-rmse:1.100695\tval-rmse:1.215765\n",
      "[485]\ttrain-rmse:1.100394\tval-rmse:1.215648\n",
      "[486]\ttrain-rmse:1.100105\tval-rmse:1.215542\n",
      "[487]\ttrain-rmse:1.099827\tval-rmse:1.215424\n",
      "[488]\ttrain-rmse:1.099518\tval-rmse:1.215321\n",
      "[489]\ttrain-rmse:1.099265\tval-rmse:1.215201\n",
      "[490]\ttrain-rmse:1.099005\tval-rmse:1.215091\n",
      "[491]\ttrain-rmse:1.098727\tval-rmse:1.214977\n",
      "[492]\ttrain-rmse:1.098510\tval-rmse:1.214875\n",
      "[493]\ttrain-rmse:1.098287\tval-rmse:1.214759\n",
      "[494]\ttrain-rmse:1.098046\tval-rmse:1.214659\n",
      "[495]\ttrain-rmse:1.097759\tval-rmse:1.214560\n",
      "[496]\ttrain-rmse:1.097533\tval-rmse:1.214445\n",
      "[497]\ttrain-rmse:1.097341\tval-rmse:1.214354\n",
      "[498]\ttrain-rmse:1.097070\tval-rmse:1.214256\n",
      "[499]\ttrain-rmse:1.096799\tval-rmse:1.214150\n",
      "[500]\ttrain-rmse:1.096573\tval-rmse:1.214056\n",
      "[501]\ttrain-rmse:1.096259\tval-rmse:1.213971\n",
      "[502]\ttrain-rmse:1.096047\tval-rmse:1.213860\n",
      "[503]\ttrain-rmse:1.095789\tval-rmse:1.213780\n",
      "[504]\ttrain-rmse:1.095558\tval-rmse:1.213675\n",
      "[505]\ttrain-rmse:1.095276\tval-rmse:1.213580\n",
      "[506]\ttrain-rmse:1.094976\tval-rmse:1.213482\n",
      "[507]\ttrain-rmse:1.094727\tval-rmse:1.213370\n",
      "[508]\ttrain-rmse:1.094512\tval-rmse:1.213283\n",
      "[509]\ttrain-rmse:1.094299\tval-rmse:1.213207\n",
      "[510]\ttrain-rmse:1.094107\tval-rmse:1.213139\n",
      "[511]\ttrain-rmse:1.093894\tval-rmse:1.213050\n",
      "[512]\ttrain-rmse:1.093663\tval-rmse:1.212935\n",
      "[513]\ttrain-rmse:1.093384\tval-rmse:1.212853\n",
      "[514]\ttrain-rmse:1.093135\tval-rmse:1.212783\n",
      "[515]\ttrain-rmse:1.092910\tval-rmse:1.212697\n",
      "[516]\ttrain-rmse:1.092628\tval-rmse:1.212616\n",
      "[517]\ttrain-rmse:1.092461\tval-rmse:1.212537\n",
      "[518]\ttrain-rmse:1.092271\tval-rmse:1.212471\n",
      "[519]\ttrain-rmse:1.091961\tval-rmse:1.212375\n",
      "[520]\ttrain-rmse:1.091667\tval-rmse:1.212305\n",
      "[521]\ttrain-rmse:1.091431\tval-rmse:1.212242\n",
      "[522]\ttrain-rmse:1.091125\tval-rmse:1.212150\n",
      "[523]\ttrain-rmse:1.090913\tval-rmse:1.212075\n",
      "[524]\ttrain-rmse:1.090654\tval-rmse:1.212003\n",
      "[525]\ttrain-rmse:1.090405\tval-rmse:1.211929\n",
      "[526]\ttrain-rmse:1.090192\tval-rmse:1.211846\n",
      "[527]\ttrain-rmse:1.089942\tval-rmse:1.211778\n",
      "[528]\ttrain-rmse:1.089745\tval-rmse:1.211700\n",
      "[529]\ttrain-rmse:1.089537\tval-rmse:1.211616\n",
      "[530]\ttrain-rmse:1.089302\tval-rmse:1.211541\n",
      "[531]\ttrain-rmse:1.089132\tval-rmse:1.211465\n",
      "[532]\ttrain-rmse:1.088843\tval-rmse:1.211417\n",
      "[533]\ttrain-rmse:1.088638\tval-rmse:1.211335\n",
      "[534]\ttrain-rmse:1.088467\tval-rmse:1.211267\n",
      "[535]\ttrain-rmse:1.088227\tval-rmse:1.211194\n",
      "[536]\ttrain-rmse:1.088023\tval-rmse:1.211135\n",
      "[537]\ttrain-rmse:1.087837\tval-rmse:1.211053\n",
      "[538]\ttrain-rmse:1.087644\tval-rmse:1.210989\n",
      "[539]\ttrain-rmse:1.087437\tval-rmse:1.210926\n",
      "[540]\ttrain-rmse:1.087226\tval-rmse:1.210843\n",
      "[541]\ttrain-rmse:1.086949\tval-rmse:1.210777\n",
      "[542]\ttrain-rmse:1.086734\tval-rmse:1.210700\n",
      "[543]\ttrain-rmse:1.086498\tval-rmse:1.210651\n",
      "[544]\ttrain-rmse:1.086297\tval-rmse:1.210584\n",
      "[545]\ttrain-rmse:1.086107\tval-rmse:1.210523\n",
      "[546]\ttrain-rmse:1.085918\tval-rmse:1.210464\n",
      "[547]\ttrain-rmse:1.085683\tval-rmse:1.210413\n",
      "[548]\ttrain-rmse:1.085467\tval-rmse:1.210351\n",
      "[549]\ttrain-rmse:1.085272\tval-rmse:1.210289\n",
      "[550]\ttrain-rmse:1.085069\tval-rmse:1.210220\n",
      "[551]\ttrain-rmse:1.084836\tval-rmse:1.210172\n",
      "[552]\ttrain-rmse:1.084663\tval-rmse:1.210108\n",
      "[553]\ttrain-rmse:1.084506\tval-rmse:1.210041\n",
      "[554]\ttrain-rmse:1.084237\tval-rmse:1.209993\n",
      "[555]\ttrain-rmse:1.084075\tval-rmse:1.209947\n",
      "[556]\ttrain-rmse:1.083884\tval-rmse:1.209898\n",
      "[557]\ttrain-rmse:1.083663\tval-rmse:1.209859\n",
      "[558]\ttrain-rmse:1.083457\tval-rmse:1.209805\n",
      "[559]\ttrain-rmse:1.083231\tval-rmse:1.209751\n",
      "[560]\ttrain-rmse:1.083047\tval-rmse:1.209679\n",
      "[561]\ttrain-rmse:1.082854\tval-rmse:1.209628\n",
      "[562]\ttrain-rmse:1.082678\tval-rmse:1.209562\n",
      "[563]\ttrain-rmse:1.082497\tval-rmse:1.209511\n",
      "[564]\ttrain-rmse:1.082303\tval-rmse:1.209445\n",
      "[565]\ttrain-rmse:1.082187\tval-rmse:1.209403\n",
      "[566]\ttrain-rmse:1.082009\tval-rmse:1.209351\n",
      "[567]\ttrain-rmse:1.081842\tval-rmse:1.209312\n",
      "[568]\ttrain-rmse:1.081634\tval-rmse:1.209260\n",
      "[569]\ttrain-rmse:1.081410\tval-rmse:1.209218\n",
      "[570]\ttrain-rmse:1.081269\tval-rmse:1.209172\n",
      "[571]\ttrain-rmse:1.081099\tval-rmse:1.209112\n",
      "[572]\ttrain-rmse:1.080848\tval-rmse:1.209060\n",
      "[573]\ttrain-rmse:1.080594\tval-rmse:1.209033\n",
      "[574]\ttrain-rmse:1.080431\tval-rmse:1.208981\n",
      "[575]\ttrain-rmse:1.080210\tval-rmse:1.208940\n",
      "[576]\ttrain-rmse:1.080026\tval-rmse:1.208898\n",
      "[577]\ttrain-rmse:1.079820\tval-rmse:1.208846\n",
      "[578]\ttrain-rmse:1.079677\tval-rmse:1.208803\n",
      "[579]\ttrain-rmse:1.079549\tval-rmse:1.208757\n",
      "[580]\ttrain-rmse:1.079294\tval-rmse:1.208712\n",
      "[581]\ttrain-rmse:1.079160\tval-rmse:1.208666\n",
      "[582]\ttrain-rmse:1.078891\tval-rmse:1.208633\n",
      "[583]\ttrain-rmse:1.078756\tval-rmse:1.208593\n",
      "[584]\ttrain-rmse:1.078599\tval-rmse:1.208546\n",
      "[585]\ttrain-rmse:1.078384\tval-rmse:1.208495\n",
      "[586]\ttrain-rmse:1.078194\tval-rmse:1.208460\n",
      "[587]\ttrain-rmse:1.078012\tval-rmse:1.208426\n",
      "[588]\ttrain-rmse:1.077790\tval-rmse:1.208387\n",
      "[589]\ttrain-rmse:1.077533\tval-rmse:1.208375\n",
      "[590]\ttrain-rmse:1.077390\tval-rmse:1.208346\n",
      "[591]\ttrain-rmse:1.077231\tval-rmse:1.208300\n",
      "[592]\ttrain-rmse:1.076985\tval-rmse:1.208262\n",
      "[593]\ttrain-rmse:1.076833\tval-rmse:1.208218\n",
      "[594]\ttrain-rmse:1.076636\tval-rmse:1.208192\n",
      "[595]\ttrain-rmse:1.076512\tval-rmse:1.208154\n",
      "[596]\ttrain-rmse:1.076277\tval-rmse:1.208120\n",
      "[597]\ttrain-rmse:1.076095\tval-rmse:1.208077\n",
      "[598]\ttrain-rmse:1.075968\tval-rmse:1.208032\n",
      "[599]\ttrain-rmse:1.075782\tval-rmse:1.207994\n",
      "[600]\ttrain-rmse:1.075633\tval-rmse:1.207949\n",
      "[601]\ttrain-rmse:1.075449\tval-rmse:1.207927\n",
      "[602]\ttrain-rmse:1.075348\tval-rmse:1.207893\n",
      "[603]\ttrain-rmse:1.075184\tval-rmse:1.207872\n",
      "[604]\ttrain-rmse:1.074864\tval-rmse:1.207834\n",
      "[605]\ttrain-rmse:1.074747\tval-rmse:1.207799\n",
      "[606]\ttrain-rmse:1.074516\tval-rmse:1.207766\n",
      "[607]\ttrain-rmse:1.074310\tval-rmse:1.207747\n",
      "[608]\ttrain-rmse:1.074124\tval-rmse:1.207735\n",
      "[609]\ttrain-rmse:1.073969\tval-rmse:1.207703\n",
      "[610]\ttrain-rmse:1.073762\tval-rmse:1.207660\n",
      "[611]\ttrain-rmse:1.073547\tval-rmse:1.207638\n",
      "[612]\ttrain-rmse:1.073340\tval-rmse:1.207607\n",
      "[613]\ttrain-rmse:1.073196\tval-rmse:1.207576\n",
      "[614]\ttrain-rmse:1.073012\tval-rmse:1.207539\n",
      "[615]\ttrain-rmse:1.072812\tval-rmse:1.207509\n",
      "[616]\ttrain-rmse:1.072693\tval-rmse:1.207486\n",
      "[617]\ttrain-rmse:1.072502\tval-rmse:1.207458\n",
      "[618]\ttrain-rmse:1.072275\tval-rmse:1.207440\n",
      "[619]\ttrain-rmse:1.072168\tval-rmse:1.207420\n",
      "[620]\ttrain-rmse:1.072010\tval-rmse:1.207397\n",
      "[621]\ttrain-rmse:1.071903\tval-rmse:1.207367\n",
      "[622]\ttrain-rmse:1.071646\tval-rmse:1.207334\n",
      "[623]\ttrain-rmse:1.071430\tval-rmse:1.207297\n",
      "[624]\ttrain-rmse:1.071307\tval-rmse:1.207258\n",
      "[625]\ttrain-rmse:1.071149\tval-rmse:1.207237\n",
      "[626]\ttrain-rmse:1.070988\tval-rmse:1.207209\n",
      "[627]\ttrain-rmse:1.070811\tval-rmse:1.207197\n",
      "[628]\ttrain-rmse:1.070701\tval-rmse:1.207177\n",
      "[629]\ttrain-rmse:1.070554\tval-rmse:1.207148\n",
      "[630]\ttrain-rmse:1.070403\tval-rmse:1.207128\n",
      "[631]\ttrain-rmse:1.070241\tval-rmse:1.207105\n",
      "[632]\ttrain-rmse:1.070107\tval-rmse:1.207087\n",
      "[633]\ttrain-rmse:1.069956\tval-rmse:1.207063\n",
      "[634]\ttrain-rmse:1.069806\tval-rmse:1.207041\n",
      "[635]\ttrain-rmse:1.069707\tval-rmse:1.207009\n",
      "[636]\ttrain-rmse:1.069594\tval-rmse:1.206977\n",
      "[637]\ttrain-rmse:1.069436\tval-rmse:1.206946\n",
      "[638]\ttrain-rmse:1.069230\tval-rmse:1.206948\n",
      "[639]\ttrain-rmse:1.069121\tval-rmse:1.206930\n",
      "[640]\ttrain-rmse:1.068997\tval-rmse:1.206904\n",
      "[641]\ttrain-rmse:1.068856\tval-rmse:1.206875\n",
      "[642]\ttrain-rmse:1.068741\tval-rmse:1.206844\n",
      "[643]\ttrain-rmse:1.068572\tval-rmse:1.206826\n",
      "[644]\ttrain-rmse:1.068483\tval-rmse:1.206809\n",
      "[645]\ttrain-rmse:1.068354\tval-rmse:1.206791\n",
      "[646]\ttrain-rmse:1.068117\tval-rmse:1.206752\n",
      "[647]\ttrain-rmse:1.067944\tval-rmse:1.206747\n",
      "[648]\ttrain-rmse:1.067839\tval-rmse:1.206712\n",
      "[649]\ttrain-rmse:1.067649\tval-rmse:1.206662\n",
      "[650]\ttrain-rmse:1.067530\tval-rmse:1.206666\n",
      "[651]\ttrain-rmse:1.067381\tval-rmse:1.206646\n",
      "[652]\ttrain-rmse:1.067156\tval-rmse:1.206617\n",
      "[653]\ttrain-rmse:1.066975\tval-rmse:1.206612\n",
      "[654]\ttrain-rmse:1.066787\tval-rmse:1.206611\n",
      "[655]\ttrain-rmse:1.066665\tval-rmse:1.206584\n",
      "[656]\ttrain-rmse:1.066566\tval-rmse:1.206564\n",
      "[657]\ttrain-rmse:1.066357\tval-rmse:1.206571\n",
      "[658]\ttrain-rmse:1.066098\tval-rmse:1.206561\n",
      "[659]\ttrain-rmse:1.065975\tval-rmse:1.206539\n",
      "[660]\ttrain-rmse:1.065756\tval-rmse:1.206512\n",
      "[661]\ttrain-rmse:1.065658\tval-rmse:1.206496\n",
      "[662]\ttrain-rmse:1.065551\tval-rmse:1.206472\n",
      "[663]\ttrain-rmse:1.065382\tval-rmse:1.206461\n",
      "[664]\ttrain-rmse:1.065211\tval-rmse:1.206454\n",
      "[665]\ttrain-rmse:1.065072\tval-rmse:1.206457\n",
      "[666]\ttrain-rmse:1.064940\tval-rmse:1.206447\n",
      "[667]\ttrain-rmse:1.064793\tval-rmse:1.206423\n",
      "[668]\ttrain-rmse:1.064635\tval-rmse:1.206410\n",
      "[669]\ttrain-rmse:1.064454\tval-rmse:1.206403\n",
      "[670]\ttrain-rmse:1.064313\tval-rmse:1.206393\n",
      "[671]\ttrain-rmse:1.064202\tval-rmse:1.206376\n",
      "[672]\ttrain-rmse:1.064051\tval-rmse:1.206356\n",
      "[673]\ttrain-rmse:1.063933\tval-rmse:1.206339\n",
      "[674]\ttrain-rmse:1.063768\tval-rmse:1.206330\n",
      "[675]\ttrain-rmse:1.063663\tval-rmse:1.206307\n",
      "[676]\ttrain-rmse:1.063536\tval-rmse:1.206314\n",
      "[677]\ttrain-rmse:1.063353\tval-rmse:1.206314\n",
      "[678]\ttrain-rmse:1.063168\tval-rmse:1.206283\n",
      "[679]\ttrain-rmse:1.062933\tval-rmse:1.206253\n",
      "[680]\ttrain-rmse:1.062837\tval-rmse:1.206243\n",
      "[681]\ttrain-rmse:1.062757\tval-rmse:1.206235\n",
      "[682]\ttrain-rmse:1.062536\tval-rmse:1.206232\n",
      "[683]\ttrain-rmse:1.062409\tval-rmse:1.206214\n",
      "[684]\ttrain-rmse:1.062300\tval-rmse:1.206204\n",
      "[685]\ttrain-rmse:1.062119\tval-rmse:1.206159\n",
      "[686]\ttrain-rmse:1.061994\tval-rmse:1.206158\n",
      "[687]\ttrain-rmse:1.061918\tval-rmse:1.206137\n",
      "[688]\ttrain-rmse:1.061746\tval-rmse:1.206131\n",
      "[689]\ttrain-rmse:1.061556\tval-rmse:1.206127\n",
      "[690]\ttrain-rmse:1.061443\tval-rmse:1.206113\n",
      "[691]\ttrain-rmse:1.061265\tval-rmse:1.206116\n",
      "[692]\ttrain-rmse:1.061174\tval-rmse:1.206103\n",
      "[693]\ttrain-rmse:1.061080\tval-rmse:1.206092\n",
      "[694]\ttrain-rmse:1.060944\tval-rmse:1.206075\n",
      "[695]\ttrain-rmse:1.060875\tval-rmse:1.206063\n",
      "[696]\ttrain-rmse:1.060681\tval-rmse:1.206042\n",
      "[697]\ttrain-rmse:1.060569\tval-rmse:1.206023\n",
      "[698]\ttrain-rmse:1.060366\tval-rmse:1.206026\n",
      "[699]\ttrain-rmse:1.060301\tval-rmse:1.206006\n",
      "[700]\ttrain-rmse:1.060068\tval-rmse:1.206023\n",
      "[701]\ttrain-rmse:1.059944\tval-rmse:1.206018\n",
      "[702]\ttrain-rmse:1.059757\tval-rmse:1.206016\n",
      "[703]\ttrain-rmse:1.059551\tval-rmse:1.206009\n",
      "[704]\ttrain-rmse:1.059508\tval-rmse:1.205991\n",
      "[705]\ttrain-rmse:1.059373\tval-rmse:1.205996\n",
      "[706]\ttrain-rmse:1.059249\tval-rmse:1.205981\n",
      "[707]\ttrain-rmse:1.059040\tval-rmse:1.205971\n",
      "[708]\ttrain-rmse:1.058971\tval-rmse:1.205952\n",
      "[709]\ttrain-rmse:1.058853\tval-rmse:1.205950\n",
      "[710]\ttrain-rmse:1.058645\tval-rmse:1.205947\n",
      "[711]\ttrain-rmse:1.058533\tval-rmse:1.205938\n",
      "[712]\ttrain-rmse:1.058452\tval-rmse:1.205922\n",
      "[713]\ttrain-rmse:1.058323\tval-rmse:1.205904\n",
      "[714]\ttrain-rmse:1.058168\tval-rmse:1.205902\n",
      "[715]\ttrain-rmse:1.058046\tval-rmse:1.205900\n",
      "[716]\ttrain-rmse:1.057941\tval-rmse:1.205891\n",
      "[717]\ttrain-rmse:1.057748\tval-rmse:1.205896\n",
      "[718]\ttrain-rmse:1.057585\tval-rmse:1.205900\n",
      "[719]\ttrain-rmse:1.057440\tval-rmse:1.205870\n",
      "[720]\ttrain-rmse:1.057371\tval-rmse:1.205854\n",
      "[721]\ttrain-rmse:1.057286\tval-rmse:1.205841\n",
      "[722]\ttrain-rmse:1.057132\tval-rmse:1.205817\n",
      "[723]\ttrain-rmse:1.056919\tval-rmse:1.205821\n",
      "[724]\ttrain-rmse:1.056821\tval-rmse:1.205821\n",
      "[725]\ttrain-rmse:1.056707\tval-rmse:1.205801\n",
      "[726]\ttrain-rmse:1.056555\tval-rmse:1.205808\n",
      "[727]\ttrain-rmse:1.056378\tval-rmse:1.205823\n",
      "[728]\ttrain-rmse:1.056293\tval-rmse:1.205806\n",
      "[729]\ttrain-rmse:1.056196\tval-rmse:1.205791\n",
      "[730]\ttrain-rmse:1.056106\tval-rmse:1.205794\n",
      "[731]\ttrain-rmse:1.056005\tval-rmse:1.205810\n",
      "[732]\ttrain-rmse:1.055884\tval-rmse:1.205822\n",
      "[733]\ttrain-rmse:1.055783\tval-rmse:1.205812\n",
      "[734]\ttrain-rmse:1.055729\tval-rmse:1.205804\n",
      "[735]\ttrain-rmse:1.055587\tval-rmse:1.205791\n",
      "[736]\ttrain-rmse:1.055515\tval-rmse:1.205777\n",
      "[737]\ttrain-rmse:1.055352\tval-rmse:1.205765\n",
      "[738]\ttrain-rmse:1.055240\tval-rmse:1.205760\n",
      "[739]\ttrain-rmse:1.055081\tval-rmse:1.205757\n",
      "[740]\ttrain-rmse:1.054968\tval-rmse:1.205764\n",
      "[741]\ttrain-rmse:1.054813\tval-rmse:1.205761\n",
      "[742]\ttrain-rmse:1.054640\tval-rmse:1.205768\n",
      "[743]\ttrain-rmse:1.054432\tval-rmse:1.205770\n",
      "[744]\ttrain-rmse:1.054220\tval-rmse:1.205772\n",
      "[745]\ttrain-rmse:1.054128\tval-rmse:1.205757\n",
      "[746]\ttrain-rmse:1.053946\tval-rmse:1.205740\n",
      "[747]\ttrain-rmse:1.053843\tval-rmse:1.205733\n",
      "[748]\ttrain-rmse:1.053689\tval-rmse:1.205725\n",
      "[749]\ttrain-rmse:1.053625\tval-rmse:1.205718\n",
      "[750]\ttrain-rmse:1.053452\tval-rmse:1.205718\n",
      "[751]\ttrain-rmse:1.053352\tval-rmse:1.205706\n",
      "[752]\ttrain-rmse:1.053280\tval-rmse:1.205687\n",
      "[753]\ttrain-rmse:1.053142\tval-rmse:1.205682\n",
      "[754]\ttrain-rmse:1.053035\tval-rmse:1.205694\n",
      "[755]\ttrain-rmse:1.052961\tval-rmse:1.205677\n",
      "[756]\ttrain-rmse:1.052829\tval-rmse:1.205689\n",
      "[757]\ttrain-rmse:1.052672\tval-rmse:1.205701\n",
      "[758]\ttrain-rmse:1.052638\tval-rmse:1.205694\n",
      "[759]\ttrain-rmse:1.052525\tval-rmse:1.205698\n",
      "[760]\ttrain-rmse:1.052395\tval-rmse:1.205700\n",
      "[761]\ttrain-rmse:1.052331\tval-rmse:1.205684\n",
      "[762]\ttrain-rmse:1.052149\tval-rmse:1.205694\n",
      "[763]\ttrain-rmse:1.052079\tval-rmse:1.205694\n",
      "[764]\ttrain-rmse:1.052000\tval-rmse:1.205691\n",
      "[765]\ttrain-rmse:1.051933\tval-rmse:1.205689\n",
      "[766]\ttrain-rmse:1.051854\tval-rmse:1.205688\n",
      "[767]\ttrain-rmse:1.051754\tval-rmse:1.205696\n",
      "[768]\ttrain-rmse:1.051707\tval-rmse:1.205693\n",
      "[769]\ttrain-rmse:1.051628\tval-rmse:1.205675\n",
      "[770]\ttrain-rmse:1.051418\tval-rmse:1.205652\n",
      "[771]\ttrain-rmse:1.051298\tval-rmse:1.205668\n",
      "[772]\ttrain-rmse:1.051243\tval-rmse:1.205671\n",
      "[773]\ttrain-rmse:1.051021\tval-rmse:1.205665\n",
      "[774]\ttrain-rmse:1.050844\tval-rmse:1.205662\n",
      "[775]\ttrain-rmse:1.050721\tval-rmse:1.205674\n",
      "[776]\ttrain-rmse:1.050574\tval-rmse:1.205678\n",
      "[777]\ttrain-rmse:1.050331\tval-rmse:1.205667\n",
      "[778]\ttrain-rmse:1.050235\tval-rmse:1.205666\n",
      "[779]\ttrain-rmse:1.050125\tval-rmse:1.205669\n",
      "[780]\ttrain-rmse:1.050007\tval-rmse:1.205676\n",
      "[781]\ttrain-rmse:1.049959\tval-rmse:1.205675\n",
      "[782]\ttrain-rmse:1.049844\tval-rmse:1.205687\n",
      "[783]\ttrain-rmse:1.049639\tval-rmse:1.205678\n",
      "[784]\ttrain-rmse:1.049408\tval-rmse:1.205673\n",
      "[785]\ttrain-rmse:1.049201\tval-rmse:1.205676\n",
      "[786]\ttrain-rmse:1.049128\tval-rmse:1.205678\n",
      "[787]\ttrain-rmse:1.049003\tval-rmse:1.205692\n",
      "[788]\ttrain-rmse:1.048920\tval-rmse:1.205686\n",
      "[789]\ttrain-rmse:1.048746\tval-rmse:1.205676\n",
      "[790]\ttrain-rmse:1.048662\tval-rmse:1.205676\n",
      "[791]\ttrain-rmse:1.048569\tval-rmse:1.205680\n",
      "[792]\ttrain-rmse:1.048473\tval-rmse:1.205682\n",
      "[793]\ttrain-rmse:1.048437\tval-rmse:1.205676\n",
      "[794]\ttrain-rmse:1.048263\tval-rmse:1.205691\n",
      "[795]\ttrain-rmse:1.048100\tval-rmse:1.205685\n",
      "[796]\ttrain-rmse:1.047890\tval-rmse:1.205685\n",
      "[797]\ttrain-rmse:1.047663\tval-rmse:1.205677\n",
      "[798]\ttrain-rmse:1.047516\tval-rmse:1.205682\n",
      "[799]\ttrain-rmse:1.047394\tval-rmse:1.205696\n",
      "[800]\ttrain-rmse:1.047286\tval-rmse:1.205692\n",
      "[801]\ttrain-rmse:1.047106\tval-rmse:1.205703\n",
      "[802]\ttrain-rmse:1.047040\tval-rmse:1.205703\n",
      "[803]\ttrain-rmse:1.046931\tval-rmse:1.205723\n",
      "[804]\ttrain-rmse:1.046825\tval-rmse:1.205739\n",
      "[805]\ttrain-rmse:1.046735\tval-rmse:1.205717\n",
      "[806]\ttrain-rmse:1.046636\tval-rmse:1.205709\n",
      "[807]\ttrain-rmse:1.046483\tval-rmse:1.205713\n",
      "[808]\ttrain-rmse:1.046413\tval-rmse:1.205714\n",
      "[809]\ttrain-rmse:1.046318\tval-rmse:1.205715\n",
      "[810]\ttrain-rmse:1.046130\tval-rmse:1.205719\n",
      "[811]\ttrain-rmse:1.046049\tval-rmse:1.205723\n",
      "[812]\ttrain-rmse:1.045863\tval-rmse:1.205723\n",
      "[813]\ttrain-rmse:1.045703\tval-rmse:1.205712\n",
      "[814]\ttrain-rmse:1.045547\tval-rmse:1.205700\n",
      "[815]\ttrain-rmse:1.045373\tval-rmse:1.205710\n",
      "[816]\ttrain-rmse:1.045202\tval-rmse:1.205712\n",
      "[817]\ttrain-rmse:1.045115\tval-rmse:1.205721\n",
      "[818]\ttrain-rmse:1.045038\tval-rmse:1.205724\n",
      "[819]\ttrain-rmse:1.044925\tval-rmse:1.205719\n",
      "[820]\ttrain-rmse:1.044762\tval-rmse:1.205731\n",
      "[821]\ttrain-rmse:1.044616\tval-rmse:1.205732\n",
      "[822]\ttrain-rmse:1.044436\tval-rmse:1.205746\n",
      "[823]\ttrain-rmse:1.044337\tval-rmse:1.205746\n",
      "[824]\ttrain-rmse:1.044234\tval-rmse:1.205741\n",
      "[825]\ttrain-rmse:1.044101\tval-rmse:1.205753\n",
      "[826]\ttrain-rmse:1.043907\tval-rmse:1.205747\n",
      "[827]\ttrain-rmse:1.043821\tval-rmse:1.205746\n",
      "[828]\ttrain-rmse:1.043695\tval-rmse:1.205750\n",
      "[829]\ttrain-rmse:1.043595\tval-rmse:1.205745\n",
      "[830]\ttrain-rmse:1.043574\tval-rmse:1.205736\n",
      "[831]\ttrain-rmse:1.043423\tval-rmse:1.205740\n",
      "[832]\ttrain-rmse:1.043328\tval-rmse:1.205741\n",
      "[833]\ttrain-rmse:1.043200\tval-rmse:1.205747\n",
      "[834]\ttrain-rmse:1.043035\tval-rmse:1.205767\n",
      "[835]\ttrain-rmse:1.042963\tval-rmse:1.205774\n",
      "[836]\ttrain-rmse:1.042798\tval-rmse:1.205764\n",
      "[837]\ttrain-rmse:1.042653\tval-rmse:1.205757\n",
      "[838]\ttrain-rmse:1.042540\tval-rmse:1.205747\n",
      "[839]\ttrain-rmse:1.042409\tval-rmse:1.205736\n",
      "[840]\ttrain-rmse:1.042220\tval-rmse:1.205739\n",
      "[841]\ttrain-rmse:1.042048\tval-rmse:1.205738\n",
      "[842]\ttrain-rmse:1.041990\tval-rmse:1.205732\n",
      "[843]\ttrain-rmse:1.041860\tval-rmse:1.205750\n",
      "[844]\ttrain-rmse:1.041691\tval-rmse:1.205772\n",
      "[845]\ttrain-rmse:1.041626\tval-rmse:1.205771\n",
      "[846]\ttrain-rmse:1.041479\tval-rmse:1.205790\n",
      "[847]\ttrain-rmse:1.041411\tval-rmse:1.205800\n",
      "[848]\ttrain-rmse:1.041301\tval-rmse:1.205808\n",
      "[849]\ttrain-rmse:1.041170\tval-rmse:1.205803\n",
      "[850]\ttrain-rmse:1.041033\tval-rmse:1.205821\n",
      "[851]\ttrain-rmse:1.040885\tval-rmse:1.205834\n",
      "[852]\ttrain-rmse:1.040782\tval-rmse:1.205829\n",
      "[853]\ttrain-rmse:1.040705\tval-rmse:1.205830\n",
      "[854]\ttrain-rmse:1.040661\tval-rmse:1.205823\n",
      "[855]\ttrain-rmse:1.040594\tval-rmse:1.205811\n",
      "[856]\ttrain-rmse:1.040472\tval-rmse:1.205813\n",
      "[857]\ttrain-rmse:1.040378\tval-rmse:1.205821\n",
      "[858]\ttrain-rmse:1.040317\tval-rmse:1.205822\n",
      "[859]\ttrain-rmse:1.040174\tval-rmse:1.205821\n",
      "[860]\ttrain-rmse:1.040106\tval-rmse:1.205822\n",
      "[861]\ttrain-rmse:1.040047\tval-rmse:1.205815\n",
      "[862]\ttrain-rmse:1.039976\tval-rmse:1.205811\n",
      "[863]\ttrain-rmse:1.039845\tval-rmse:1.205805\n",
      "[864]\ttrain-rmse:1.039711\tval-rmse:1.205804\n",
      "[865]\ttrain-rmse:1.039659\tval-rmse:1.205800\n",
      "[866]\ttrain-rmse:1.039558\tval-rmse:1.205801\n",
      "[867]\ttrain-rmse:1.039407\tval-rmse:1.205807\n",
      "[868]\ttrain-rmse:1.039290\tval-rmse:1.205817\n",
      "[869]\ttrain-rmse:1.039068\tval-rmse:1.205824\n",
      "[870]\ttrain-rmse:1.038976\tval-rmse:1.205838\n",
      "[871]\ttrain-rmse:1.038810\tval-rmse:1.205855\n",
      "[872]\ttrain-rmse:1.038738\tval-rmse:1.205840\n",
      "[873]\ttrain-rmse:1.038584\tval-rmse:1.205829\n",
      "[874]\ttrain-rmse:1.038449\tval-rmse:1.205838\n",
      "[875]\ttrain-rmse:1.038328\tval-rmse:1.205828\n",
      "[876]\ttrain-rmse:1.038208\tval-rmse:1.205823\n",
      "[877]\ttrain-rmse:1.038106\tval-rmse:1.205828\n",
      "[878]\ttrain-rmse:1.037970\tval-rmse:1.205840\n",
      "[879]\ttrain-rmse:1.037897\tval-rmse:1.205840\n",
      "[880]\ttrain-rmse:1.037770\tval-rmse:1.205832\n",
      "[881]\ttrain-rmse:1.037567\tval-rmse:1.205861\n",
      "[882]\ttrain-rmse:1.037490\tval-rmse:1.205855\n",
      "[883]\ttrain-rmse:1.037423\tval-rmse:1.205859\n",
      "[884]\ttrain-rmse:1.037337\tval-rmse:1.205865\n",
      "[885]\ttrain-rmse:1.037169\tval-rmse:1.205855\n",
      "[886]\ttrain-rmse:1.037063\tval-rmse:1.205862\n",
      "[887]\ttrain-rmse:1.037007\tval-rmse:1.205860\n",
      "[888]\ttrain-rmse:1.036971\tval-rmse:1.205858\n",
      "[889]\ttrain-rmse:1.036769\tval-rmse:1.205862\n",
      "[890]\ttrain-rmse:1.036636\tval-rmse:1.205882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.301873235152\n",
      "0.318391809956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[770]\ttrain-rmse:1.051418\tval-rmse:1.205652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.005\n",
    "params[\"min_child_weight\"] = 6\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "# params[\"max_delta_step\"] = 10\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 9 #7\n",
    "# params[\"gamma\"] = 0\n",
    "\n",
    "\n",
    "plst = list(params.items())\n",
    "\n",
    "max_rounds = 2000\n",
    "# xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(y_stack, n_folds=3,\n",
    "                      shuffle=True,\n",
    "                      random_state=np.random.randint(0,100))\n",
    "train, valid= iter(skf).next()\n",
    "X_train_k = X_stack[train]\n",
    "X_valid_k = X_stack[valid]\n",
    "\n",
    "y_train_k = y_stack[train]\n",
    "y_valid_k = y_stack[valid]\n",
    "\n",
    "\n",
    "#create a train and validation dmatrices \n",
    "xgtrain = xgb.DMatrix(X_train_k, label=y_train_k)\n",
    "xgval = xgb.DMatrix(X_valid_k, label=y_valid_k)\n",
    "\n",
    "#train using early stopping and predict\n",
    "watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "model = xgb.train(plst, xgtrain, max_rounds, watchlist, early_stopping_rounds=120)\n",
    "\n",
    "preds_val = model.predict(xgval)\n",
    "\n",
    "s = metrics.normalized_gini(y_valid_k, preds_val)\n",
    "\n",
    "print s\n",
    "\n",
    "\n",
    "print metrics.normalized_gini(\n",
    "    y_valid_k, \n",
    "    LinearRegression().fit(X_train_k, y_train_k).predict(X_valid_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until val error hasn't decreased in 120 rounds.\n",
      "[0]\ttrain-rmse:5.317329\tval-rmse:5.362140\n",
      "[1]\ttrain-rmse:5.303665\tval-rmse:5.349388\n",
      "[2]\ttrain-rmse:5.289955\tval-rmse:5.336975\n",
      "[3]\ttrain-rmse:5.276534\tval-rmse:5.324588\n",
      "[4]\ttrain-rmse:5.262992\tval-rmse:5.312044\n",
      "[5]\ttrain-rmse:5.249659\tval-rmse:5.299715\n",
      "[6]\ttrain-rmse:5.236305\tval-rmse:5.287350\n",
      "[7]\ttrain-rmse:5.223094\tval-rmse:5.275422\n",
      "[8]\ttrain-rmse:5.210062\tval-rmse:5.263691\n",
      "[9]\ttrain-rmse:5.196976\tval-rmse:5.251692\n",
      "[10]\ttrain-rmse:5.184126\tval-rmse:5.239738\n",
      "[11]\ttrain-rmse:5.171191\tval-rmse:5.227896\n",
      "[12]\ttrain-rmse:5.158447\tval-rmse:5.216073\n",
      "[13]\ttrain-rmse:5.145739\tval-rmse:5.204370\n",
      "[14]\ttrain-rmse:5.133117\tval-rmse:5.192982\n",
      "[15]\ttrain-rmse:5.120632\tval-rmse:5.181509\n",
      "[16]\ttrain-rmse:5.108198\tval-rmse:5.170189\n",
      "[17]\ttrain-rmse:5.095583\tval-rmse:5.158813\n",
      "[18]\ttrain-rmse:5.083429\tval-rmse:5.147689\n",
      "[19]\ttrain-rmse:5.071270\tval-rmse:5.136600\n",
      "[20]\ttrain-rmse:5.059189\tval-rmse:5.125554\n",
      "[21]\ttrain-rmse:5.047148\tval-rmse:5.114747\n",
      "[22]\ttrain-rmse:5.035156\tval-rmse:5.104002\n",
      "[23]\ttrain-rmse:5.023225\tval-rmse:5.093394\n",
      "[24]\ttrain-rmse:5.011335\tval-rmse:5.082791\n",
      "[25]\ttrain-rmse:4.999636\tval-rmse:5.072303\n",
      "[26]\ttrain-rmse:4.988064\tval-rmse:5.061784\n",
      "[27]\ttrain-rmse:4.976587\tval-rmse:5.051442\n",
      "[28]\ttrain-rmse:4.964846\tval-rmse:5.040935\n",
      "[29]\ttrain-rmse:4.953426\tval-rmse:5.030469\n",
      "[30]\ttrain-rmse:4.942129\tval-rmse:5.020384\n",
      "[31]\ttrain-rmse:4.930887\tval-rmse:5.010408\n",
      "[32]\ttrain-rmse:4.919833\tval-rmse:5.000432\n",
      "[33]\ttrain-rmse:4.908564\tval-rmse:4.990530\n",
      "[34]\ttrain-rmse:4.897518\tval-rmse:4.980635\n",
      "[35]\ttrain-rmse:4.886410\tval-rmse:4.970726\n",
      "[36]\ttrain-rmse:4.875651\tval-rmse:4.961075\n",
      "[37]\ttrain-rmse:4.865101\tval-rmse:4.951534\n",
      "[38]\ttrain-rmse:4.854400\tval-rmse:4.942029\n",
      "[39]\ttrain-rmse:4.843782\tval-rmse:4.932655\n",
      "[40]\ttrain-rmse:4.833087\tval-rmse:4.923251\n",
      "[41]\ttrain-rmse:4.822546\tval-rmse:4.913787\n",
      "[42]\ttrain-rmse:4.812131\tval-rmse:4.904465\n",
      "[43]\ttrain-rmse:4.801408\tval-rmse:4.895278\n",
      "[44]\ttrain-rmse:4.791036\tval-rmse:4.886026\n",
      "[45]\ttrain-rmse:4.781069\tval-rmse:4.877297\n",
      "[46]\ttrain-rmse:4.770916\tval-rmse:4.868333\n",
      "[47]\ttrain-rmse:4.760911\tval-rmse:4.859249\n",
      "[48]\ttrain-rmse:4.750652\tval-rmse:4.850362\n",
      "[49]\ttrain-rmse:4.740548\tval-rmse:4.841267\n",
      "[50]\ttrain-rmse:4.730755\tval-rmse:4.832618\n",
      "[51]\ttrain-rmse:4.721072\tval-rmse:4.823991\n",
      "[52]\ttrain-rmse:4.711204\tval-rmse:4.815480\n",
      "[53]\ttrain-rmse:4.701779\tval-rmse:4.807205\n",
      "[54]\ttrain-rmse:4.692129\tval-rmse:4.798724\n",
      "[55]\ttrain-rmse:4.682605\tval-rmse:4.790294\n",
      "[56]\ttrain-rmse:4.673148\tval-rmse:4.781865\n",
      "[57]\ttrain-rmse:4.663727\tval-rmse:4.773672\n",
      "[58]\ttrain-rmse:4.654384\tval-rmse:4.765357\n",
      "[59]\ttrain-rmse:4.645144\tval-rmse:4.757274\n",
      "[60]\ttrain-rmse:4.636009\tval-rmse:4.749265\n",
      "[61]\ttrain-rmse:4.627010\tval-rmse:4.741294\n",
      "[62]\ttrain-rmse:4.618227\tval-rmse:4.733316\n",
      "[63]\ttrain-rmse:4.609083\tval-rmse:4.725380\n",
      "[64]\ttrain-rmse:4.600104\tval-rmse:4.717454\n",
      "[65]\ttrain-rmse:4.591099\tval-rmse:4.709581\n",
      "[66]\ttrain-rmse:4.582182\tval-rmse:4.701712\n",
      "[67]\ttrain-rmse:4.573260\tval-rmse:4.694212\n",
      "[68]\ttrain-rmse:4.564420\tval-rmse:4.686734\n",
      "[69]\ttrain-rmse:4.555683\tval-rmse:4.679104\n",
      "[70]\ttrain-rmse:4.547225\tval-rmse:4.671666\n",
      "[71]\ttrain-rmse:4.538640\tval-rmse:4.664329\n",
      "[72]\ttrain-rmse:4.530188\tval-rmse:4.657194\n",
      "[73]\ttrain-rmse:4.521654\tval-rmse:4.649894\n",
      "[74]\ttrain-rmse:4.513519\tval-rmse:4.642758\n",
      "[75]\ttrain-rmse:4.505299\tval-rmse:4.635763\n",
      "[76]\ttrain-rmse:4.496882\tval-rmse:4.628460\n",
      "[77]\ttrain-rmse:4.488437\tval-rmse:4.621348\n",
      "[78]\ttrain-rmse:4.480303\tval-rmse:4.614189\n",
      "[79]\ttrain-rmse:4.472121\tval-rmse:4.607227\n",
      "[80]\ttrain-rmse:4.464087\tval-rmse:4.600332\n",
      "[81]\ttrain-rmse:4.455976\tval-rmse:4.593670\n",
      "[82]\ttrain-rmse:4.448198\tval-rmse:4.586980\n",
      "[83]\ttrain-rmse:4.440296\tval-rmse:4.580387\n",
      "[84]\ttrain-rmse:4.432248\tval-rmse:4.573910\n",
      "[85]\ttrain-rmse:4.424588\tval-rmse:4.567241\n",
      "[86]\ttrain-rmse:4.416801\tval-rmse:4.560709\n",
      "[87]\ttrain-rmse:4.409188\tval-rmse:4.554360\n",
      "[88]\ttrain-rmse:4.401700\tval-rmse:4.548122\n",
      "[89]\ttrain-rmse:4.394271\tval-rmse:4.541784\n",
      "[90]\ttrain-rmse:4.386622\tval-rmse:4.535429\n",
      "[91]\ttrain-rmse:4.379037\tval-rmse:4.529155\n",
      "[92]\ttrain-rmse:4.371615\tval-rmse:4.522962\n",
      "[93]\ttrain-rmse:4.364332\tval-rmse:4.516790\n",
      "[94]\ttrain-rmse:4.356800\tval-rmse:4.510573\n",
      "[95]\ttrain-rmse:4.349433\tval-rmse:4.504600\n",
      "[96]\ttrain-rmse:4.342274\tval-rmse:4.498536\n",
      "[97]\ttrain-rmse:4.334778\tval-rmse:4.492481\n",
      "[98]\ttrain-rmse:4.327713\tval-rmse:4.486571\n",
      "[99]\ttrain-rmse:4.320630\tval-rmse:4.480711\n",
      "[100]\ttrain-rmse:4.313466\tval-rmse:4.474889\n",
      "[101]\ttrain-rmse:4.306653\tval-rmse:4.469231\n",
      "[102]\ttrain-rmse:4.299776\tval-rmse:4.463569\n",
      "[103]\ttrain-rmse:4.292939\tval-rmse:4.458002\n",
      "[104]\ttrain-rmse:4.286227\tval-rmse:4.452383\n",
      "[105]\ttrain-rmse:4.279385\tval-rmse:4.446946\n",
      "[106]\ttrain-rmse:4.272540\tval-rmse:4.441191\n",
      "[107]\ttrain-rmse:4.265760\tval-rmse:4.435664\n",
      "[108]\ttrain-rmse:4.259197\tval-rmse:4.430285\n",
      "[109]\ttrain-rmse:4.252453\tval-rmse:4.424767\n",
      "[110]\ttrain-rmse:4.245902\tval-rmse:4.419438\n",
      "[111]\ttrain-rmse:4.239407\tval-rmse:4.414170\n",
      "[112]\ttrain-rmse:4.232867\tval-rmse:4.408892\n",
      "[113]\ttrain-rmse:4.226596\tval-rmse:4.403718\n",
      "[114]\ttrain-rmse:4.220265\tval-rmse:4.398557\n",
      "[115]\ttrain-rmse:4.213981\tval-rmse:4.393501\n",
      "[116]\ttrain-rmse:4.207653\tval-rmse:4.388423\n",
      "[117]\ttrain-rmse:4.201451\tval-rmse:4.383458\n",
      "[118]\ttrain-rmse:4.195421\tval-rmse:4.378440\n",
      "[119]\ttrain-rmse:4.189374\tval-rmse:4.373496\n",
      "[120]\ttrain-rmse:4.183230\tval-rmse:4.368700\n",
      "[121]\ttrain-rmse:4.177284\tval-rmse:4.363869\n",
      "[122]\ttrain-rmse:4.171463\tval-rmse:4.359032\n",
      "[123]\ttrain-rmse:4.165400\tval-rmse:4.354298\n",
      "[124]\ttrain-rmse:4.159397\tval-rmse:4.349600\n",
      "[125]\ttrain-rmse:4.153474\tval-rmse:4.344949\n",
      "[126]\ttrain-rmse:4.147521\tval-rmse:4.340209\n",
      "[127]\ttrain-rmse:4.141695\tval-rmse:4.335579\n",
      "[128]\ttrain-rmse:4.136089\tval-rmse:4.331177\n",
      "[129]\ttrain-rmse:4.130387\tval-rmse:4.326675\n",
      "[130]\ttrain-rmse:4.124716\tval-rmse:4.322204\n",
      "[131]\ttrain-rmse:4.118928\tval-rmse:4.317580\n",
      "[132]\ttrain-rmse:4.113356\tval-rmse:4.313045\n",
      "[133]\ttrain-rmse:4.107608\tval-rmse:4.308702\n",
      "[134]\ttrain-rmse:4.102286\tval-rmse:4.304382\n",
      "[135]\ttrain-rmse:4.096787\tval-rmse:4.300061\n",
      "[136]\ttrain-rmse:4.091342\tval-rmse:4.295716\n",
      "[137]\ttrain-rmse:4.085996\tval-rmse:4.291540\n",
      "[138]\ttrain-rmse:4.080585\tval-rmse:4.287334\n",
      "[139]\ttrain-rmse:4.075145\tval-rmse:4.283132\n",
      "[140]\ttrain-rmse:4.069706\tval-rmse:4.278947\n",
      "[141]\ttrain-rmse:4.064198\tval-rmse:4.274883\n",
      "[142]\ttrain-rmse:4.058951\tval-rmse:4.270802\n",
      "[143]\ttrain-rmse:4.053566\tval-rmse:4.266948\n",
      "[144]\ttrain-rmse:4.048240\tval-rmse:4.263032\n",
      "[145]\ttrain-rmse:4.043257\tval-rmse:4.259011\n",
      "[146]\ttrain-rmse:4.037879\tval-rmse:4.255089\n",
      "[147]\ttrain-rmse:4.032935\tval-rmse:4.251260\n",
      "[148]\ttrain-rmse:4.027750\tval-rmse:4.247466\n",
      "[149]\ttrain-rmse:4.022805\tval-rmse:4.243475\n",
      "[150]\ttrain-rmse:4.017740\tval-rmse:4.239882\n",
      "[151]\ttrain-rmse:4.012719\tval-rmse:4.236081\n",
      "[152]\ttrain-rmse:4.007663\tval-rmse:4.232418\n",
      "[153]\ttrain-rmse:4.002743\tval-rmse:4.228885\n",
      "[154]\ttrain-rmse:3.997906\tval-rmse:4.225154\n",
      "[155]\ttrain-rmse:3.993006\tval-rmse:4.221515\n",
      "[156]\ttrain-rmse:3.988274\tval-rmse:4.217811\n",
      "[157]\ttrain-rmse:3.983468\tval-rmse:4.214181\n",
      "[158]\ttrain-rmse:3.978826\tval-rmse:4.210823\n",
      "[159]\ttrain-rmse:3.974102\tval-rmse:4.207268\n",
      "[160]\ttrain-rmse:3.969710\tval-rmse:4.203835\n",
      "[161]\ttrain-rmse:3.965135\tval-rmse:4.200551\n",
      "[162]\ttrain-rmse:3.960542\tval-rmse:4.197181\n",
      "[163]\ttrain-rmse:3.956110\tval-rmse:4.193766\n",
      "[164]\ttrain-rmse:3.951520\tval-rmse:4.190257\n",
      "[165]\ttrain-rmse:3.947123\tval-rmse:4.186976\n",
      "[166]\ttrain-rmse:3.942743\tval-rmse:4.183860\n",
      "[167]\ttrain-rmse:3.938308\tval-rmse:4.180545\n",
      "[168]\ttrain-rmse:3.934249\tval-rmse:4.177363\n",
      "[169]\ttrain-rmse:3.929717\tval-rmse:4.174099\n",
      "[170]\ttrain-rmse:3.925261\tval-rmse:4.170746\n",
      "[171]\ttrain-rmse:3.921073\tval-rmse:4.167662\n",
      "[172]\ttrain-rmse:3.916925\tval-rmse:4.164518\n",
      "[173]\ttrain-rmse:3.912587\tval-rmse:4.161574\n",
      "[174]\ttrain-rmse:3.908313\tval-rmse:4.158442\n",
      "[175]\ttrain-rmse:3.903958\tval-rmse:4.155510\n",
      "[176]\ttrain-rmse:3.899922\tval-rmse:4.152617\n",
      "[177]\ttrain-rmse:3.895940\tval-rmse:4.149650\n",
      "[178]\ttrain-rmse:3.891539\tval-rmse:4.146697\n",
      "[179]\ttrain-rmse:3.887639\tval-rmse:4.143768\n",
      "[180]\ttrain-rmse:3.883370\tval-rmse:4.140839\n",
      "[181]\ttrain-rmse:3.879497\tval-rmse:4.137982\n",
      "[182]\ttrain-rmse:3.875420\tval-rmse:4.135098\n",
      "[183]\ttrain-rmse:3.871419\tval-rmse:4.132378\n",
      "[184]\ttrain-rmse:3.867447\tval-rmse:4.129488\n",
      "[185]\ttrain-rmse:3.863471\tval-rmse:4.126739\n",
      "[186]\ttrain-rmse:3.859469\tval-rmse:4.124101\n",
      "[187]\ttrain-rmse:3.855394\tval-rmse:4.121219\n",
      "[188]\ttrain-rmse:3.851542\tval-rmse:4.118556\n",
      "[189]\ttrain-rmse:3.847883\tval-rmse:4.115895\n",
      "[190]\ttrain-rmse:3.844139\tval-rmse:4.113220\n",
      "[191]\ttrain-rmse:3.840386\tval-rmse:4.110598\n",
      "[192]\ttrain-rmse:3.836640\tval-rmse:4.107896\n",
      "[193]\ttrain-rmse:3.832865\tval-rmse:4.105253\n",
      "[194]\ttrain-rmse:3.829170\tval-rmse:4.102692\n",
      "[195]\ttrain-rmse:3.825516\tval-rmse:4.100168\n",
      "[196]\ttrain-rmse:3.821556\tval-rmse:4.097546\n",
      "[197]\ttrain-rmse:3.817952\tval-rmse:4.094974\n",
      "[198]\ttrain-rmse:3.814430\tval-rmse:4.092504\n",
      "[199]\ttrain-rmse:3.810928\tval-rmse:4.089981\n",
      "[200]\ttrain-rmse:3.807420\tval-rmse:4.087561\n",
      "[201]\ttrain-rmse:3.803912\tval-rmse:4.085177\n",
      "[202]\ttrain-rmse:3.800364\tval-rmse:4.082828\n",
      "[203]\ttrain-rmse:3.796743\tval-rmse:4.080353\n",
      "[204]\ttrain-rmse:3.793055\tval-rmse:4.077872\n",
      "[205]\ttrain-rmse:3.789598\tval-rmse:4.075577\n",
      "[206]\ttrain-rmse:3.786226\tval-rmse:4.073242\n",
      "[207]\ttrain-rmse:3.782849\tval-rmse:4.070911\n",
      "[208]\ttrain-rmse:3.779315\tval-rmse:4.068689\n",
      "[209]\ttrain-rmse:3.775873\tval-rmse:4.066412\n",
      "[210]\ttrain-rmse:3.772508\tval-rmse:4.064154\n",
      "[211]\ttrain-rmse:3.768979\tval-rmse:4.061904\n",
      "[212]\ttrain-rmse:3.765634\tval-rmse:4.059706\n",
      "[213]\ttrain-rmse:3.762629\tval-rmse:4.057523\n",
      "[214]\ttrain-rmse:3.759328\tval-rmse:4.055300\n",
      "[215]\ttrain-rmse:3.756088\tval-rmse:4.053212\n",
      "[216]\ttrain-rmse:3.752842\tval-rmse:4.051117\n",
      "[217]\ttrain-rmse:3.749639\tval-rmse:4.048880\n",
      "[218]\ttrain-rmse:3.746616\tval-rmse:4.046891\n",
      "[219]\ttrain-rmse:3.743530\tval-rmse:4.044825\n",
      "[220]\ttrain-rmse:3.740473\tval-rmse:4.042791\n",
      "[221]\ttrain-rmse:3.737327\tval-rmse:4.040750\n",
      "[222]\ttrain-rmse:3.734294\tval-rmse:4.038801\n",
      "[223]\ttrain-rmse:3.731390\tval-rmse:4.036809\n",
      "[224]\ttrain-rmse:3.728370\tval-rmse:4.034862\n",
      "[225]\ttrain-rmse:3.725469\tval-rmse:4.032951\n",
      "[226]\ttrain-rmse:3.722489\tval-rmse:4.031024\n",
      "[227]\ttrain-rmse:3.719434\tval-rmse:4.029078\n",
      "[228]\ttrain-rmse:3.716568\tval-rmse:4.027254\n",
      "[229]\ttrain-rmse:3.713548\tval-rmse:4.025380\n",
      "[230]\ttrain-rmse:3.710739\tval-rmse:4.023519\n",
      "[231]\ttrain-rmse:3.707723\tval-rmse:4.021684\n",
      "[232]\ttrain-rmse:3.705141\tval-rmse:4.019998\n",
      "[233]\ttrain-rmse:3.702082\tval-rmse:4.018047\n",
      "[234]\ttrain-rmse:3.698991\tval-rmse:4.016233\n",
      "[235]\ttrain-rmse:3.696241\tval-rmse:4.014477\n",
      "[236]\ttrain-rmse:3.693317\tval-rmse:4.012717\n",
      "[237]\ttrain-rmse:3.690445\tval-rmse:4.010903\n",
      "[238]\ttrain-rmse:3.687680\tval-rmse:4.009218\n",
      "[239]\ttrain-rmse:3.684807\tval-rmse:4.007555\n",
      "[240]\ttrain-rmse:3.681975\tval-rmse:4.005725\n",
      "[241]\ttrain-rmse:3.679217\tval-rmse:4.004082\n",
      "[242]\ttrain-rmse:3.676611\tval-rmse:4.002352\n",
      "[243]\ttrain-rmse:3.673707\tval-rmse:4.000753\n",
      "[244]\ttrain-rmse:3.671192\tval-rmse:3.999014\n",
      "[245]\ttrain-rmse:3.668644\tval-rmse:3.997432\n",
      "[246]\ttrain-rmse:3.666043\tval-rmse:3.995878\n",
      "[247]\ttrain-rmse:3.663574\tval-rmse:3.994307\n",
      "[248]\ttrain-rmse:3.660801\tval-rmse:3.992718\n",
      "[249]\ttrain-rmse:3.658364\tval-rmse:3.991211\n",
      "[250]\ttrain-rmse:3.655670\tval-rmse:3.989656\n",
      "[251]\ttrain-rmse:3.653111\tval-rmse:3.988090\n",
      "[252]\ttrain-rmse:3.650728\tval-rmse:3.986610\n",
      "[253]\ttrain-rmse:3.648168\tval-rmse:3.985207\n",
      "[254]\ttrain-rmse:3.645646\tval-rmse:3.983727\n",
      "[255]\ttrain-rmse:3.643086\tval-rmse:3.982270\n",
      "[256]\ttrain-rmse:3.640458\tval-rmse:3.980672\n",
      "[257]\ttrain-rmse:3.637947\tval-rmse:3.979307\n",
      "[258]\ttrain-rmse:3.635452\tval-rmse:3.977833\n",
      "[259]\ttrain-rmse:3.632991\tval-rmse:3.976366\n",
      "[260]\ttrain-rmse:3.630591\tval-rmse:3.974973\n",
      "[261]\ttrain-rmse:3.628132\tval-rmse:3.973547\n",
      "[262]\ttrain-rmse:3.625927\tval-rmse:3.972182\n",
      "[263]\ttrain-rmse:3.623632\tval-rmse:3.970907\n",
      "[264]\ttrain-rmse:3.621242\tval-rmse:3.969502\n",
      "[265]\ttrain-rmse:3.619017\tval-rmse:3.968181\n",
      "[266]\ttrain-rmse:3.616635\tval-rmse:3.966820\n",
      "[267]\ttrain-rmse:3.614352\tval-rmse:3.965485\n",
      "[268]\ttrain-rmse:3.612139\tval-rmse:3.964162\n",
      "[269]\ttrain-rmse:3.609867\tval-rmse:3.962906\n",
      "[270]\ttrain-rmse:3.607599\tval-rmse:3.961541\n",
      "[271]\ttrain-rmse:3.605444\tval-rmse:3.960218\n",
      "[272]\ttrain-rmse:3.603152\tval-rmse:3.958841\n",
      "[273]\ttrain-rmse:3.600667\tval-rmse:3.957447\n",
      "[274]\ttrain-rmse:3.598624\tval-rmse:3.956239\n",
      "[275]\ttrain-rmse:3.596450\tval-rmse:3.954897\n",
      "[276]\ttrain-rmse:3.594466\tval-rmse:3.953685\n",
      "[277]\ttrain-rmse:3.592263\tval-rmse:3.952605\n",
      "[278]\ttrain-rmse:3.589923\tval-rmse:3.951359\n",
      "[279]\ttrain-rmse:3.587877\tval-rmse:3.950166\n",
      "[280]\ttrain-rmse:3.585705\tval-rmse:3.949012\n",
      "[281]\ttrain-rmse:3.583585\tval-rmse:3.947909\n",
      "[282]\ttrain-rmse:3.581557\tval-rmse:3.946707\n",
      "[283]\ttrain-rmse:3.579419\tval-rmse:3.945535\n",
      "[284]\ttrain-rmse:3.577239\tval-rmse:3.944386\n",
      "[285]\ttrain-rmse:3.575183\tval-rmse:3.943276\n",
      "[286]\ttrain-rmse:3.573153\tval-rmse:3.942007\n",
      "[287]\ttrain-rmse:3.570990\tval-rmse:3.940866\n",
      "[288]\ttrain-rmse:3.568910\tval-rmse:3.939739\n",
      "[289]\ttrain-rmse:3.566834\tval-rmse:3.938735\n",
      "[290]\ttrain-rmse:3.565082\tval-rmse:3.937705\n",
      "[291]\ttrain-rmse:3.562921\tval-rmse:3.936669\n",
      "[292]\ttrain-rmse:3.560914\tval-rmse:3.935646\n",
      "[293]\ttrain-rmse:3.558900\tval-rmse:3.934569\n",
      "[294]\ttrain-rmse:3.556875\tval-rmse:3.933579\n",
      "[295]\ttrain-rmse:3.554871\tval-rmse:3.932588\n",
      "[296]\ttrain-rmse:3.553010\tval-rmse:3.931587\n",
      "[297]\ttrain-rmse:3.551125\tval-rmse:3.930647\n",
      "[298]\ttrain-rmse:3.549148\tval-rmse:3.929717\n",
      "[299]\ttrain-rmse:3.547177\tval-rmse:3.928812\n",
      "[300]\ttrain-rmse:3.545155\tval-rmse:3.927789\n",
      "[301]\ttrain-rmse:3.543027\tval-rmse:3.926702\n",
      "[302]\ttrain-rmse:3.541025\tval-rmse:3.925841\n",
      "[303]\ttrain-rmse:3.539077\tval-rmse:3.924962\n",
      "[304]\ttrain-rmse:3.537214\tval-rmse:3.924086\n",
      "[305]\ttrain-rmse:3.535295\tval-rmse:3.923157\n",
      "[306]\ttrain-rmse:3.533234\tval-rmse:3.922194\n",
      "[307]\ttrain-rmse:3.531185\tval-rmse:3.921282\n",
      "[308]\ttrain-rmse:3.529344\tval-rmse:3.920391\n",
      "[309]\ttrain-rmse:3.527350\tval-rmse:3.919454\n",
      "[310]\ttrain-rmse:3.525505\tval-rmse:3.918485\n",
      "[311]\ttrain-rmse:3.523529\tval-rmse:3.917560\n",
      "[312]\ttrain-rmse:3.521547\tval-rmse:3.916627\n",
      "[313]\ttrain-rmse:3.519823\tval-rmse:3.915700\n",
      "[314]\ttrain-rmse:3.517904\tval-rmse:3.914840\n",
      "[315]\ttrain-rmse:3.516037\tval-rmse:3.913971\n",
      "[316]\ttrain-rmse:3.514090\tval-rmse:3.913164\n",
      "[317]\ttrain-rmse:3.512339\tval-rmse:3.912334\n",
      "[318]\ttrain-rmse:3.510498\tval-rmse:3.911461\n",
      "[319]\ttrain-rmse:3.508701\tval-rmse:3.910733\n",
      "[320]\ttrain-rmse:3.506818\tval-rmse:3.909822\n",
      "[321]\ttrain-rmse:3.505190\tval-rmse:3.908980\n",
      "[322]\ttrain-rmse:3.503347\tval-rmse:3.908000\n",
      "[323]\ttrain-rmse:3.501700\tval-rmse:3.907116\n",
      "[324]\ttrain-rmse:3.499740\tval-rmse:3.906278\n",
      "[325]\ttrain-rmse:3.498000\tval-rmse:3.905365\n",
      "[326]\ttrain-rmse:3.496421\tval-rmse:3.904601\n",
      "[327]\ttrain-rmse:3.494962\tval-rmse:3.903840\n",
      "[328]\ttrain-rmse:3.493219\tval-rmse:3.903071\n",
      "[329]\ttrain-rmse:3.491353\tval-rmse:3.902358\n",
      "[330]\ttrain-rmse:3.489573\tval-rmse:3.901665\n",
      "[331]\ttrain-rmse:3.488107\tval-rmse:3.900935\n",
      "[332]\ttrain-rmse:3.486385\tval-rmse:3.900209\n",
      "[333]\ttrain-rmse:3.484743\tval-rmse:3.899500\n",
      "[334]\ttrain-rmse:3.483059\tval-rmse:3.898831\n",
      "[335]\ttrain-rmse:3.481240\tval-rmse:3.898194\n",
      "[336]\ttrain-rmse:3.479557\tval-rmse:3.897530\n",
      "[337]\ttrain-rmse:3.477870\tval-rmse:3.896801\n",
      "[338]\ttrain-rmse:3.476274\tval-rmse:3.896102\n",
      "[339]\ttrain-rmse:3.474578\tval-rmse:3.895439\n",
      "[340]\ttrain-rmse:3.473326\tval-rmse:3.894774\n",
      "[341]\ttrain-rmse:3.471732\tval-rmse:3.894110\n",
      "[342]\ttrain-rmse:3.470297\tval-rmse:3.893423\n",
      "[343]\ttrain-rmse:3.468860\tval-rmse:3.892700\n",
      "[344]\ttrain-rmse:3.467213\tval-rmse:3.892028\n",
      "[345]\ttrain-rmse:3.465880\tval-rmse:3.891272\n",
      "[346]\ttrain-rmse:3.464210\tval-rmse:3.890503\n",
      "[347]\ttrain-rmse:3.462568\tval-rmse:3.889842\n",
      "[348]\ttrain-rmse:3.460900\tval-rmse:3.889076\n",
      "[349]\ttrain-rmse:3.459098\tval-rmse:3.888340\n",
      "[350]\ttrain-rmse:3.457379\tval-rmse:3.887625\n",
      "[351]\ttrain-rmse:3.455882\tval-rmse:3.886905\n",
      "[352]\ttrain-rmse:3.454365\tval-rmse:3.886311\n",
      "[353]\ttrain-rmse:3.453010\tval-rmse:3.885629\n",
      "[354]\ttrain-rmse:3.451391\tval-rmse:3.884928\n",
      "[355]\ttrain-rmse:3.449916\tval-rmse:3.884247\n",
      "[356]\ttrain-rmse:3.448391\tval-rmse:3.883634\n",
      "[357]\ttrain-rmse:3.446759\tval-rmse:3.883018\n",
      "[358]\ttrain-rmse:3.444993\tval-rmse:3.882464\n",
      "[359]\ttrain-rmse:3.443337\tval-rmse:3.881858\n",
      "[360]\ttrain-rmse:3.441608\tval-rmse:3.881277\n",
      "[361]\ttrain-rmse:3.440212\tval-rmse:3.880754\n",
      "[362]\ttrain-rmse:3.438792\tval-rmse:3.880086\n",
      "[363]\ttrain-rmse:3.437510\tval-rmse:3.879529\n",
      "[364]\ttrain-rmse:3.436054\tval-rmse:3.878960\n",
      "[365]\ttrain-rmse:3.434438\tval-rmse:3.878345\n",
      "[366]\ttrain-rmse:3.433176\tval-rmse:3.877704\n",
      "[367]\ttrain-rmse:3.431677\tval-rmse:3.877204\n",
      "[368]\ttrain-rmse:3.430026\tval-rmse:3.876592\n",
      "[369]\ttrain-rmse:3.428891\tval-rmse:3.876097\n",
      "[370]\ttrain-rmse:3.427412\tval-rmse:3.875558\n",
      "[371]\ttrain-rmse:3.426102\tval-rmse:3.874980\n",
      "[372]\ttrain-rmse:3.424601\tval-rmse:3.874424\n",
      "[373]\ttrain-rmse:3.423257\tval-rmse:3.873949\n",
      "[374]\ttrain-rmse:3.421797\tval-rmse:3.873507\n",
      "[375]\ttrain-rmse:3.420304\tval-rmse:3.872915\n",
      "[376]\ttrain-rmse:3.418871\tval-rmse:3.872441\n",
      "[377]\ttrain-rmse:3.417481\tval-rmse:3.871942\n",
      "[378]\ttrain-rmse:3.416084\tval-rmse:3.871474\n",
      "[379]\ttrain-rmse:3.414707\tval-rmse:3.870981\n",
      "[380]\ttrain-rmse:3.413202\tval-rmse:3.870413\n",
      "[381]\ttrain-rmse:3.411916\tval-rmse:3.869893\n",
      "[382]\ttrain-rmse:3.410511\tval-rmse:3.869320\n",
      "[383]\ttrain-rmse:3.409179\tval-rmse:3.868856\n",
      "[384]\ttrain-rmse:3.407707\tval-rmse:3.868245\n",
      "[385]\ttrain-rmse:3.406223\tval-rmse:3.867867\n",
      "[386]\ttrain-rmse:3.404771\tval-rmse:3.867432\n",
      "[387]\ttrain-rmse:3.403444\tval-rmse:3.866923\n",
      "[388]\ttrain-rmse:3.402186\tval-rmse:3.866472\n",
      "[389]\ttrain-rmse:3.400941\tval-rmse:3.865963\n",
      "[390]\ttrain-rmse:3.399529\tval-rmse:3.865485\n",
      "[391]\ttrain-rmse:3.398447\tval-rmse:3.865124\n",
      "[392]\ttrain-rmse:3.396724\tval-rmse:3.864742\n",
      "[393]\ttrain-rmse:3.395427\tval-rmse:3.864313\n",
      "[394]\ttrain-rmse:3.394208\tval-rmse:3.863899\n",
      "[395]\ttrain-rmse:3.393001\tval-rmse:3.863489\n",
      "[396]\ttrain-rmse:3.391702\tval-rmse:3.863046\n",
      "[397]\ttrain-rmse:3.390196\tval-rmse:3.862688\n",
      "[398]\ttrain-rmse:3.388980\tval-rmse:3.862244\n",
      "[399]\ttrain-rmse:3.387811\tval-rmse:3.861830\n",
      "[400]\ttrain-rmse:3.386585\tval-rmse:3.861431\n",
      "[401]\ttrain-rmse:3.385458\tval-rmse:3.861054\n",
      "[402]\ttrain-rmse:3.384051\tval-rmse:3.860602\n",
      "[403]\ttrain-rmse:3.382946\tval-rmse:3.860267\n",
      "[404]\ttrain-rmse:3.381909\tval-rmse:3.859821\n",
      "[405]\ttrain-rmse:3.380631\tval-rmse:3.859517\n",
      "[406]\ttrain-rmse:3.379451\tval-rmse:3.859129\n",
      "[407]\ttrain-rmse:3.378217\tval-rmse:3.858667\n",
      "[408]\ttrain-rmse:3.376703\tval-rmse:3.858180\n",
      "[409]\ttrain-rmse:3.375478\tval-rmse:3.857808\n",
      "[410]\ttrain-rmse:3.373831\tval-rmse:3.857398\n",
      "[411]\ttrain-rmse:3.372622\tval-rmse:3.857023\n",
      "[412]\ttrain-rmse:3.371353\tval-rmse:3.856678\n",
      "[413]\ttrain-rmse:3.369937\tval-rmse:3.856255\n",
      "[414]\ttrain-rmse:3.368782\tval-rmse:3.855888\n",
      "[415]\ttrain-rmse:3.367661\tval-rmse:3.855583\n",
      "[416]\ttrain-rmse:3.366646\tval-rmse:3.855214\n",
      "[417]\ttrain-rmse:3.365553\tval-rmse:3.854820\n",
      "[418]\ttrain-rmse:3.364222\tval-rmse:3.854426\n",
      "[419]\ttrain-rmse:3.362889\tval-rmse:3.854056\n",
      "[420]\ttrain-rmse:3.361862\tval-rmse:3.853702\n",
      "[421]\ttrain-rmse:3.360679\tval-rmse:3.853367\n",
      "[422]\ttrain-rmse:3.359837\tval-rmse:3.853020\n",
      "[423]\ttrain-rmse:3.358467\tval-rmse:3.852621\n",
      "[424]\ttrain-rmse:3.357358\tval-rmse:3.852350\n",
      "[425]\ttrain-rmse:3.356192\tval-rmse:3.852020\n",
      "[426]\ttrain-rmse:3.354965\tval-rmse:3.851791\n",
      "[427]\ttrain-rmse:3.353971\tval-rmse:3.851449\n",
      "[428]\ttrain-rmse:3.352662\tval-rmse:3.851037\n",
      "[429]\ttrain-rmse:3.351268\tval-rmse:3.850631\n",
      "[430]\ttrain-rmse:3.350130\tval-rmse:3.850330\n",
      "[431]\ttrain-rmse:3.348850\tval-rmse:3.849979\n",
      "[432]\ttrain-rmse:3.347774\tval-rmse:3.849536\n",
      "[433]\ttrain-rmse:3.346872\tval-rmse:3.849269\n",
      "[434]\ttrain-rmse:3.345677\tval-rmse:3.848988\n",
      "[435]\ttrain-rmse:3.344362\tval-rmse:3.848668\n",
      "[436]\ttrain-rmse:3.343275\tval-rmse:3.848364\n",
      "[437]\ttrain-rmse:3.342235\tval-rmse:3.848006\n",
      "[438]\ttrain-rmse:3.341237\tval-rmse:3.847679\n",
      "[439]\ttrain-rmse:3.339874\tval-rmse:3.847438\n",
      "[440]\ttrain-rmse:3.338787\tval-rmse:3.847168\n",
      "[441]\ttrain-rmse:3.337610\tval-rmse:3.846790\n",
      "[442]\ttrain-rmse:3.336678\tval-rmse:3.846411\n",
      "[443]\ttrain-rmse:3.335438\tval-rmse:3.846139\n",
      "[444]\ttrain-rmse:3.334675\tval-rmse:3.845834\n",
      "[445]\ttrain-rmse:3.333530\tval-rmse:3.845492\n",
      "[446]\ttrain-rmse:3.332551\tval-rmse:3.845219\n",
      "[447]\ttrain-rmse:3.331358\tval-rmse:3.844974\n",
      "[448]\ttrain-rmse:3.330176\tval-rmse:3.844620\n",
      "[449]\ttrain-rmse:3.329228\tval-rmse:3.844403\n",
      "[450]\ttrain-rmse:3.328244\tval-rmse:3.844097\n",
      "[451]\ttrain-rmse:3.327268\tval-rmse:3.843971\n",
      "[452]\ttrain-rmse:3.326213\tval-rmse:3.843739\n",
      "[453]\ttrain-rmse:3.324780\tval-rmse:3.843399\n",
      "[454]\ttrain-rmse:3.323578\tval-rmse:3.843155\n",
      "[455]\ttrain-rmse:3.322334\tval-rmse:3.842806\n",
      "[456]\ttrain-rmse:3.321315\tval-rmse:3.842576\n",
      "[457]\ttrain-rmse:3.320131\tval-rmse:3.842266\n",
      "[458]\ttrain-rmse:3.319069\tval-rmse:3.841827\n",
      "[459]\ttrain-rmse:3.317562\tval-rmse:3.841579\n",
      "[460]\ttrain-rmse:3.316591\tval-rmse:3.841364\n",
      "[461]\ttrain-rmse:3.315799\tval-rmse:3.841112\n",
      "[462]\ttrain-rmse:3.315008\tval-rmse:3.840813\n",
      "[463]\ttrain-rmse:3.314195\tval-rmse:3.840557\n",
      "[464]\ttrain-rmse:3.312917\tval-rmse:3.840285\n",
      "[465]\ttrain-rmse:3.311898\tval-rmse:3.839947\n",
      "[466]\ttrain-rmse:3.310607\tval-rmse:3.839678\n",
      "[467]\ttrain-rmse:3.309601\tval-rmse:3.839483\n",
      "[468]\ttrain-rmse:3.308424\tval-rmse:3.839188\n",
      "[469]\ttrain-rmse:3.307504\tval-rmse:3.838891\n",
      "[470]\ttrain-rmse:3.306461\tval-rmse:3.838654\n",
      "[471]\ttrain-rmse:3.305274\tval-rmse:3.838470\n",
      "[472]\ttrain-rmse:3.304082\tval-rmse:3.838184\n",
      "[473]\ttrain-rmse:3.303129\tval-rmse:3.838013\n",
      "[474]\ttrain-rmse:3.302287\tval-rmse:3.837847\n",
      "[475]\ttrain-rmse:3.301279\tval-rmse:3.837736\n",
      "[476]\ttrain-rmse:3.300208\tval-rmse:3.837555\n",
      "[477]\ttrain-rmse:3.299373\tval-rmse:3.837458\n",
      "[478]\ttrain-rmse:3.298402\tval-rmse:3.837289\n",
      "[479]\ttrain-rmse:3.297476\tval-rmse:3.837045\n",
      "[480]\ttrain-rmse:3.296465\tval-rmse:3.836828\n",
      "[481]\ttrain-rmse:3.295668\tval-rmse:3.836573\n",
      "[482]\ttrain-rmse:3.294742\tval-rmse:3.836333\n",
      "[483]\ttrain-rmse:3.293814\tval-rmse:3.836178\n",
      "[484]\ttrain-rmse:3.292972\tval-rmse:3.835983\n",
      "[485]\ttrain-rmse:3.292040\tval-rmse:3.835788\n",
      "[486]\ttrain-rmse:3.291113\tval-rmse:3.835588\n",
      "[487]\ttrain-rmse:3.289935\tval-rmse:3.835304\n",
      "[488]\ttrain-rmse:3.289218\tval-rmse:3.835124\n",
      "[489]\ttrain-rmse:3.288188\tval-rmse:3.834945\n",
      "[490]\ttrain-rmse:3.287100\tval-rmse:3.834772\n",
      "[491]\ttrain-rmse:3.286327\tval-rmse:3.834536\n",
      "[492]\ttrain-rmse:3.285441\tval-rmse:3.834357\n",
      "[493]\ttrain-rmse:3.284441\tval-rmse:3.834203\n",
      "[494]\ttrain-rmse:3.283393\tval-rmse:3.834029\n",
      "[495]\ttrain-rmse:3.282318\tval-rmse:3.833844\n",
      "[496]\ttrain-rmse:3.281542\tval-rmse:3.833579\n",
      "[497]\ttrain-rmse:3.280519\tval-rmse:3.833369\n",
      "[498]\ttrain-rmse:3.279486\tval-rmse:3.833155\n",
      "[499]\ttrain-rmse:3.278634\tval-rmse:3.832911\n",
      "[500]\ttrain-rmse:3.278006\tval-rmse:3.832749\n",
      "[501]\ttrain-rmse:3.277136\tval-rmse:3.832475\n",
      "[502]\ttrain-rmse:3.276230\tval-rmse:3.832390\n",
      "[503]\ttrain-rmse:3.275488\tval-rmse:3.832186\n",
      "[504]\ttrain-rmse:3.274604\tval-rmse:3.832075\n",
      "[505]\ttrain-rmse:3.273738\tval-rmse:3.831922\n",
      "[506]\ttrain-rmse:3.272624\tval-rmse:3.831754\n",
      "[507]\ttrain-rmse:3.271610\tval-rmse:3.831592\n",
      "[508]\ttrain-rmse:3.270709\tval-rmse:3.831381\n",
      "[509]\ttrain-rmse:3.269659\tval-rmse:3.831194\n",
      "[510]\ttrain-rmse:3.268994\tval-rmse:3.830989\n",
      "[511]\ttrain-rmse:3.268101\tval-rmse:3.830769\n",
      "[512]\ttrain-rmse:3.267213\tval-rmse:3.830698\n",
      "[513]\ttrain-rmse:3.266113\tval-rmse:3.830543\n",
      "[514]\ttrain-rmse:3.265360\tval-rmse:3.830382\n",
      "[515]\ttrain-rmse:3.264168\tval-rmse:3.830215\n",
      "[516]\ttrain-rmse:3.262998\tval-rmse:3.830155\n",
      "[517]\ttrain-rmse:3.262034\tval-rmse:3.830033\n",
      "[518]\ttrain-rmse:3.261181\tval-rmse:3.829858\n",
      "[519]\ttrain-rmse:3.260325\tval-rmse:3.829646\n",
      "[520]\ttrain-rmse:3.259483\tval-rmse:3.829541\n",
      "[521]\ttrain-rmse:3.258569\tval-rmse:3.829489\n",
      "[522]\ttrain-rmse:3.257728\tval-rmse:3.829313\n",
      "[523]\ttrain-rmse:3.257170\tval-rmse:3.829170\n",
      "[524]\ttrain-rmse:3.256156\tval-rmse:3.828980\n",
      "[525]\ttrain-rmse:3.255324\tval-rmse:3.828740\n",
      "[526]\ttrain-rmse:3.254581\tval-rmse:3.828635\n",
      "[527]\ttrain-rmse:3.253612\tval-rmse:3.828534\n",
      "[528]\ttrain-rmse:3.252817\tval-rmse:3.828373\n",
      "[529]\ttrain-rmse:3.252044\tval-rmse:3.828151\n",
      "[530]\ttrain-rmse:3.250886\tval-rmse:3.828036\n",
      "[531]\ttrain-rmse:3.250131\tval-rmse:3.827836\n",
      "[532]\ttrain-rmse:3.249094\tval-rmse:3.827638\n",
      "[533]\ttrain-rmse:3.248245\tval-rmse:3.827486\n",
      "[534]\ttrain-rmse:3.247525\tval-rmse:3.827393\n",
      "[535]\ttrain-rmse:3.246852\tval-rmse:3.827278\n",
      "[536]\ttrain-rmse:3.245984\tval-rmse:3.827110\n",
      "[537]\ttrain-rmse:3.245318\tval-rmse:3.827023\n",
      "[538]\ttrain-rmse:3.244402\tval-rmse:3.826791\n",
      "[539]\ttrain-rmse:3.243644\tval-rmse:3.826640\n",
      "[540]\ttrain-rmse:3.242465\tval-rmse:3.826536\n",
      "[541]\ttrain-rmse:3.241698\tval-rmse:3.826456\n",
      "[542]\ttrain-rmse:3.240988\tval-rmse:3.826331\n",
      "[543]\ttrain-rmse:3.240447\tval-rmse:3.826179\n",
      "[544]\ttrain-rmse:3.239436\tval-rmse:3.825985\n",
      "[545]\ttrain-rmse:3.238423\tval-rmse:3.825799\n",
      "[546]\ttrain-rmse:3.237944\tval-rmse:3.825663\n",
      "[547]\ttrain-rmse:3.236950\tval-rmse:3.825582\n",
      "[548]\ttrain-rmse:3.235889\tval-rmse:3.825464\n",
      "[549]\ttrain-rmse:3.235100\tval-rmse:3.825337\n",
      "[550]\ttrain-rmse:3.233979\tval-rmse:3.825238\n",
      "[551]\ttrain-rmse:3.233273\tval-rmse:3.825174\n",
      "[552]\ttrain-rmse:3.232525\tval-rmse:3.825047\n",
      "[553]\ttrain-rmse:3.231796\tval-rmse:3.824982\n",
      "[554]\ttrain-rmse:3.231081\tval-rmse:3.824769\n",
      "[555]\ttrain-rmse:3.230416\tval-rmse:3.824643\n",
      "[556]\ttrain-rmse:3.229510\tval-rmse:3.824535\n",
      "[557]\ttrain-rmse:3.228782\tval-rmse:3.824349\n",
      "[558]\ttrain-rmse:3.228076\tval-rmse:3.824195\n",
      "[559]\ttrain-rmse:3.227080\tval-rmse:3.824065\n",
      "[560]\ttrain-rmse:3.226173\tval-rmse:3.823897\n",
      "[561]\ttrain-rmse:3.225413\tval-rmse:3.823754\n",
      "[562]\ttrain-rmse:3.224483\tval-rmse:3.823611\n",
      "[563]\ttrain-rmse:3.223515\tval-rmse:3.823476\n",
      "[564]\ttrain-rmse:3.222919\tval-rmse:3.823404\n",
      "[565]\ttrain-rmse:3.221997\tval-rmse:3.823210\n",
      "[566]\ttrain-rmse:3.221359\tval-rmse:3.823019\n",
      "[567]\ttrain-rmse:3.220508\tval-rmse:3.822919\n",
      "[568]\ttrain-rmse:3.219919\tval-rmse:3.822841\n",
      "[569]\ttrain-rmse:3.219288\tval-rmse:3.822692\n",
      "[570]\ttrain-rmse:3.218755\tval-rmse:3.822598\n",
      "[571]\ttrain-rmse:3.217985\tval-rmse:3.822525\n",
      "[572]\ttrain-rmse:3.217295\tval-rmse:3.822437\n",
      "[573]\ttrain-rmse:3.216756\tval-rmse:3.822330\n",
      "[574]\ttrain-rmse:3.215889\tval-rmse:3.822227\n",
      "[575]\ttrain-rmse:3.214854\tval-rmse:3.822114\n",
      "[576]\ttrain-rmse:3.214012\tval-rmse:3.822071\n",
      "[577]\ttrain-rmse:3.213171\tval-rmse:3.822043\n",
      "[578]\ttrain-rmse:3.212198\tval-rmse:3.821954\n",
      "[579]\ttrain-rmse:3.211532\tval-rmse:3.821910\n",
      "[580]\ttrain-rmse:3.210729\tval-rmse:3.821769\n",
      "[581]\ttrain-rmse:3.209860\tval-rmse:3.821640\n",
      "[582]\ttrain-rmse:3.209008\tval-rmse:3.821588\n",
      "[583]\ttrain-rmse:3.208462\tval-rmse:3.821394\n",
      "[584]\ttrain-rmse:3.207776\tval-rmse:3.821296\n",
      "[585]\ttrain-rmse:3.207187\tval-rmse:3.821253\n",
      "[586]\ttrain-rmse:3.206159\tval-rmse:3.821179\n",
      "[587]\ttrain-rmse:3.205407\tval-rmse:3.821151\n",
      "[588]\ttrain-rmse:3.204507\tval-rmse:3.820973\n",
      "[589]\ttrain-rmse:3.203828\tval-rmse:3.820850\n",
      "[590]\ttrain-rmse:3.203191\tval-rmse:3.820742\n",
      "[591]\ttrain-rmse:3.202411\tval-rmse:3.820577\n",
      "[592]\ttrain-rmse:3.201780\tval-rmse:3.820424\n",
      "[593]\ttrain-rmse:3.201127\tval-rmse:3.820375\n",
      "[594]\ttrain-rmse:3.200570\tval-rmse:3.820269\n",
      "[595]\ttrain-rmse:3.199806\tval-rmse:3.820296\n",
      "[596]\ttrain-rmse:3.199209\tval-rmse:3.820207\n",
      "[597]\ttrain-rmse:3.198488\tval-rmse:3.820036\n",
      "[598]\ttrain-rmse:3.197599\tval-rmse:3.819895\n",
      "[599]\ttrain-rmse:3.196950\tval-rmse:3.819779\n",
      "[600]\ttrain-rmse:3.195994\tval-rmse:3.819663\n",
      "[601]\ttrain-rmse:3.195347\tval-rmse:3.819546\n",
      "[602]\ttrain-rmse:3.194545\tval-rmse:3.819522\n",
      "[603]\ttrain-rmse:3.193980\tval-rmse:3.819433\n",
      "[604]\ttrain-rmse:3.193391\tval-rmse:3.819392\n",
      "[605]\ttrain-rmse:3.192488\tval-rmse:3.819365\n",
      "[606]\ttrain-rmse:3.192005\tval-rmse:3.819331\n",
      "[607]\ttrain-rmse:3.191486\tval-rmse:3.819202\n",
      "[608]\ttrain-rmse:3.190752\tval-rmse:3.819102\n",
      "[609]\ttrain-rmse:3.190127\tval-rmse:3.819017\n",
      "[610]\ttrain-rmse:3.189526\tval-rmse:3.818924\n",
      "[611]\ttrain-rmse:3.188941\tval-rmse:3.818855\n",
      "[612]\ttrain-rmse:3.188308\tval-rmse:3.818766\n",
      "[613]\ttrain-rmse:3.187372\tval-rmse:3.818640\n",
      "[614]\ttrain-rmse:3.186600\tval-rmse:3.818517\n",
      "[615]\ttrain-rmse:3.186151\tval-rmse:3.818457\n",
      "[616]\ttrain-rmse:3.185504\tval-rmse:3.818367\n",
      "[617]\ttrain-rmse:3.184850\tval-rmse:3.818315\n",
      "[618]\ttrain-rmse:3.184047\tval-rmse:3.818316\n",
      "[619]\ttrain-rmse:3.183222\tval-rmse:3.818199\n",
      "[620]\ttrain-rmse:3.182528\tval-rmse:3.818051\n",
      "[621]\ttrain-rmse:3.181930\tval-rmse:3.817972\n",
      "[622]\ttrain-rmse:3.181372\tval-rmse:3.817887\n",
      "[623]\ttrain-rmse:3.180833\tval-rmse:3.817807\n",
      "[624]\ttrain-rmse:3.179949\tval-rmse:3.817688\n",
      "[625]\ttrain-rmse:3.179256\tval-rmse:3.817673\n",
      "[626]\ttrain-rmse:3.178714\tval-rmse:3.817593\n",
      "[627]\ttrain-rmse:3.177977\tval-rmse:3.817481\n",
      "[628]\ttrain-rmse:3.177339\tval-rmse:3.817497\n",
      "[629]\ttrain-rmse:3.176508\tval-rmse:3.817420\n",
      "[630]\ttrain-rmse:3.175832\tval-rmse:3.817289\n",
      "[631]\ttrain-rmse:3.175400\tval-rmse:3.817165\n",
      "[632]\ttrain-rmse:3.174610\tval-rmse:3.817073\n",
      "[633]\ttrain-rmse:3.173968\tval-rmse:3.817050\n",
      "[634]\ttrain-rmse:3.173162\tval-rmse:3.816967\n",
      "[635]\ttrain-rmse:3.172509\tval-rmse:3.816950\n",
      "[636]\ttrain-rmse:3.171860\tval-rmse:3.816884\n",
      "[637]\ttrain-rmse:3.171393\tval-rmse:3.816834\n",
      "[638]\ttrain-rmse:3.170787\tval-rmse:3.816751\n",
      "[639]\ttrain-rmse:3.170159\tval-rmse:3.816734\n",
      "[640]\ttrain-rmse:3.169509\tval-rmse:3.816681\n",
      "[641]\ttrain-rmse:3.168947\tval-rmse:3.816595\n",
      "[642]\ttrain-rmse:3.168071\tval-rmse:3.816524\n",
      "[643]\ttrain-rmse:3.167267\tval-rmse:3.816451\n",
      "[644]\ttrain-rmse:3.166538\tval-rmse:3.816440\n",
      "[645]\ttrain-rmse:3.165513\tval-rmse:3.816341\n",
      "[646]\ttrain-rmse:3.165089\tval-rmse:3.816273\n",
      "[647]\ttrain-rmse:3.164530\tval-rmse:3.816265\n",
      "[648]\ttrain-rmse:3.164142\tval-rmse:3.816234\n",
      "[649]\ttrain-rmse:3.163517\tval-rmse:3.816185\n",
      "[650]\ttrain-rmse:3.162705\tval-rmse:3.816135\n",
      "[651]\ttrain-rmse:3.162071\tval-rmse:3.816048\n",
      "[652]\ttrain-rmse:3.161504\tval-rmse:3.816052\n",
      "[653]\ttrain-rmse:3.160681\tval-rmse:3.815983\n",
      "[654]\ttrain-rmse:3.160261\tval-rmse:3.815945\n",
      "[655]\ttrain-rmse:3.159595\tval-rmse:3.815827\n",
      "[656]\ttrain-rmse:3.158699\tval-rmse:3.815626\n",
      "[657]\ttrain-rmse:3.157969\tval-rmse:3.815574\n",
      "[658]\ttrain-rmse:3.157202\tval-rmse:3.815534\n",
      "[659]\ttrain-rmse:3.156433\tval-rmse:3.815511\n",
      "[660]\ttrain-rmse:3.156027\tval-rmse:3.815490\n",
      "[661]\ttrain-rmse:3.155277\tval-rmse:3.815415\n",
      "[662]\ttrain-rmse:3.154598\tval-rmse:3.815351\n",
      "[663]\ttrain-rmse:3.154042\tval-rmse:3.815367\n",
      "[664]\ttrain-rmse:3.153557\tval-rmse:3.815310\n",
      "[665]\ttrain-rmse:3.153005\tval-rmse:3.815185\n",
      "[666]\ttrain-rmse:3.152195\tval-rmse:3.815128\n",
      "[667]\ttrain-rmse:3.151411\tval-rmse:3.815071\n",
      "[668]\ttrain-rmse:3.150689\tval-rmse:3.814984\n",
      "[669]\ttrain-rmse:3.150069\tval-rmse:3.814915\n",
      "[670]\ttrain-rmse:3.149425\tval-rmse:3.814836\n",
      "[671]\ttrain-rmse:3.148701\tval-rmse:3.814729\n",
      "[672]\ttrain-rmse:3.148042\tval-rmse:3.814710\n",
      "[673]\ttrain-rmse:3.147676\tval-rmse:3.814653\n",
      "[674]\ttrain-rmse:3.147104\tval-rmse:3.814642\n",
      "[675]\ttrain-rmse:3.146245\tval-rmse:3.814602\n",
      "[676]\ttrain-rmse:3.145880\tval-rmse:3.814501\n",
      "[677]\ttrain-rmse:3.145326\tval-rmse:3.814434\n",
      "[678]\ttrain-rmse:3.144727\tval-rmse:3.814436\n",
      "[679]\ttrain-rmse:3.144238\tval-rmse:3.814414\n",
      "[680]\ttrain-rmse:3.143458\tval-rmse:3.814304\n",
      "[681]\ttrain-rmse:3.143041\tval-rmse:3.814280\n",
      "[682]\ttrain-rmse:3.142031\tval-rmse:3.814250\n",
      "[683]\ttrain-rmse:3.141245\tval-rmse:3.814121\n",
      "[684]\ttrain-rmse:3.140852\tval-rmse:3.814080\n",
      "[685]\ttrain-rmse:3.140379\tval-rmse:3.814064\n",
      "[686]\ttrain-rmse:3.139766\tval-rmse:3.814042\n",
      "[687]\ttrain-rmse:3.139234\tval-rmse:3.813972\n",
      "[688]\ttrain-rmse:3.138674\tval-rmse:3.813912\n",
      "[689]\ttrain-rmse:3.138238\tval-rmse:3.813896\n",
      "[690]\ttrain-rmse:3.137882\tval-rmse:3.813864\n",
      "[691]\ttrain-rmse:3.137429\tval-rmse:3.813872\n",
      "[692]\ttrain-rmse:3.136502\tval-rmse:3.813733\n",
      "[693]\ttrain-rmse:3.135936\tval-rmse:3.813660\n",
      "[694]\ttrain-rmse:3.135307\tval-rmse:3.813658\n",
      "[695]\ttrain-rmse:3.134793\tval-rmse:3.813647\n",
      "[696]\ttrain-rmse:3.134308\tval-rmse:3.813560\n",
      "[697]\ttrain-rmse:3.133903\tval-rmse:3.813549\n",
      "[698]\ttrain-rmse:3.133286\tval-rmse:3.813540\n",
      "[699]\ttrain-rmse:3.132430\tval-rmse:3.813513\n",
      "[700]\ttrain-rmse:3.131897\tval-rmse:3.813556\n",
      "[701]\ttrain-rmse:3.131610\tval-rmse:3.813489\n",
      "[702]\ttrain-rmse:3.131118\tval-rmse:3.813440\n",
      "[703]\ttrain-rmse:3.130654\tval-rmse:3.813424\n",
      "[704]\ttrain-rmse:3.129871\tval-rmse:3.813372\n",
      "[705]\ttrain-rmse:3.129316\tval-rmse:3.813318\n",
      "[706]\ttrain-rmse:3.128887\tval-rmse:3.813281\n",
      "[707]\ttrain-rmse:3.128279\tval-rmse:3.813307\n",
      "[708]\ttrain-rmse:3.127883\tval-rmse:3.813300\n",
      "[709]\ttrain-rmse:3.127006\tval-rmse:3.813311\n",
      "[710]\ttrain-rmse:3.126464\tval-rmse:3.813309\n",
      "[711]\ttrain-rmse:3.125794\tval-rmse:3.813323\n",
      "[712]\ttrain-rmse:3.125197\tval-rmse:3.813292\n",
      "[713]\ttrain-rmse:3.124676\tval-rmse:3.813220\n",
      "[714]\ttrain-rmse:3.124246\tval-rmse:3.813165\n",
      "[715]\ttrain-rmse:3.123463\tval-rmse:3.813124\n",
      "[716]\ttrain-rmse:3.122904\tval-rmse:3.813174\n",
      "[717]\ttrain-rmse:3.122508\tval-rmse:3.813148\n",
      "[718]\ttrain-rmse:3.122161\tval-rmse:3.813135\n",
      "[719]\ttrain-rmse:3.121487\tval-rmse:3.813096\n",
      "[720]\ttrain-rmse:3.120791\tval-rmse:3.813088\n",
      "[721]\ttrain-rmse:3.120303\tval-rmse:3.813095\n",
      "[722]\ttrain-rmse:3.119790\tval-rmse:3.813080\n",
      "[723]\ttrain-rmse:3.118829\tval-rmse:3.812999\n",
      "[724]\ttrain-rmse:3.118203\tval-rmse:3.812938\n",
      "[725]\ttrain-rmse:3.117248\tval-rmse:3.812826\n",
      "[726]\ttrain-rmse:3.116610\tval-rmse:3.812780\n",
      "[727]\ttrain-rmse:3.115994\tval-rmse:3.812677\n",
      "[728]\ttrain-rmse:3.115508\tval-rmse:3.812640\n",
      "[729]\ttrain-rmse:3.115124\tval-rmse:3.812582\n",
      "[730]\ttrain-rmse:3.114370\tval-rmse:3.812562\n",
      "[731]\ttrain-rmse:3.114108\tval-rmse:3.812557\n",
      "[732]\ttrain-rmse:3.113244\tval-rmse:3.812578\n",
      "[733]\ttrain-rmse:3.112715\tval-rmse:3.812591\n",
      "[734]\ttrain-rmse:3.111898\tval-rmse:3.812548\n",
      "[735]\ttrain-rmse:3.110901\tval-rmse:3.812490\n",
      "[736]\ttrain-rmse:3.110524\tval-rmse:3.812467\n",
      "[737]\ttrain-rmse:3.110152\tval-rmse:3.812442\n",
      "[738]\ttrain-rmse:3.109857\tval-rmse:3.812418\n",
      "[739]\ttrain-rmse:3.109599\tval-rmse:3.812338\n",
      "[740]\ttrain-rmse:3.109127\tval-rmse:3.812306\n",
      "[741]\ttrain-rmse:3.108739\tval-rmse:3.812318\n",
      "[742]\ttrain-rmse:3.108264\tval-rmse:3.812294\n",
      "[743]\ttrain-rmse:3.107762\tval-rmse:3.812262\n",
      "[744]\ttrain-rmse:3.107287\tval-rmse:3.812183\n",
      "[745]\ttrain-rmse:3.106736\tval-rmse:3.812134\n",
      "[746]\ttrain-rmse:3.106242\tval-rmse:3.812056\n",
      "[747]\ttrain-rmse:3.105917\tval-rmse:3.812025\n",
      "[748]\ttrain-rmse:3.105373\tval-rmse:3.812010\n",
      "[749]\ttrain-rmse:3.104959\tval-rmse:3.811991\n",
      "[750]\ttrain-rmse:3.104613\tval-rmse:3.812016\n",
      "[751]\ttrain-rmse:3.104012\tval-rmse:3.811959\n",
      "[752]\ttrain-rmse:3.103434\tval-rmse:3.811872\n",
      "[753]\ttrain-rmse:3.102791\tval-rmse:3.811763\n",
      "[754]\ttrain-rmse:3.102180\tval-rmse:3.811739\n",
      "[755]\ttrain-rmse:3.101793\tval-rmse:3.811688\n",
      "[756]\ttrain-rmse:3.100966\tval-rmse:3.811589\n",
      "[757]\ttrain-rmse:3.100473\tval-rmse:3.811540\n",
      "[758]\ttrain-rmse:3.100107\tval-rmse:3.811532\n",
      "[759]\ttrain-rmse:3.099735\tval-rmse:3.811462\n",
      "[760]\ttrain-rmse:3.099267\tval-rmse:3.811450\n",
      "[761]\ttrain-rmse:3.098867\tval-rmse:3.811424\n",
      "[762]\ttrain-rmse:3.098466\tval-rmse:3.811418\n",
      "[763]\ttrain-rmse:3.097996\tval-rmse:3.811452\n",
      "[764]\ttrain-rmse:3.097469\tval-rmse:3.811440\n",
      "[765]\ttrain-rmse:3.096679\tval-rmse:3.811378\n",
      "[766]\ttrain-rmse:3.096432\tval-rmse:3.811378\n",
      "[767]\ttrain-rmse:3.095859\tval-rmse:3.811325\n",
      "[768]\ttrain-rmse:3.094917\tval-rmse:3.811283\n",
      "[769]\ttrain-rmse:3.094329\tval-rmse:3.811310\n",
      "[770]\ttrain-rmse:3.093886\tval-rmse:3.811318\n",
      "[771]\ttrain-rmse:3.093304\tval-rmse:3.811303\n",
      "[772]\ttrain-rmse:3.093123\tval-rmse:3.811275\n",
      "[773]\ttrain-rmse:3.092381\tval-rmse:3.811252\n",
      "[774]\ttrain-rmse:3.091428\tval-rmse:3.811214\n",
      "[775]\ttrain-rmse:3.090635\tval-rmse:3.811173\n",
      "[776]\ttrain-rmse:3.090310\tval-rmse:3.811180\n",
      "[777]\ttrain-rmse:3.089898\tval-rmse:3.811177\n",
      "[778]\ttrain-rmse:3.089555\tval-rmse:3.811151\n",
      "[779]\ttrain-rmse:3.089317\tval-rmse:3.811150\n",
      "[780]\ttrain-rmse:3.088823\tval-rmse:3.811097\n",
      "[781]\ttrain-rmse:3.088369\tval-rmse:3.811082\n",
      "[782]\ttrain-rmse:3.088090\tval-rmse:3.811090\n",
      "[783]\ttrain-rmse:3.087654\tval-rmse:3.811056\n",
      "[784]\ttrain-rmse:3.087092\tval-rmse:3.810983\n",
      "[785]\ttrain-rmse:3.086669\tval-rmse:3.810938\n",
      "[786]\ttrain-rmse:3.086216\tval-rmse:3.810900\n",
      "[787]\ttrain-rmse:3.085727\tval-rmse:3.810916\n",
      "[788]\ttrain-rmse:3.085121\tval-rmse:3.810893\n",
      "[789]\ttrain-rmse:3.084661\tval-rmse:3.810832\n",
      "[790]\ttrain-rmse:3.084231\tval-rmse:3.810835\n",
      "[791]\ttrain-rmse:3.083786\tval-rmse:3.810836\n",
      "[792]\ttrain-rmse:3.083377\tval-rmse:3.810859\n",
      "[793]\ttrain-rmse:3.082834\tval-rmse:3.810861\n",
      "[794]\ttrain-rmse:3.082366\tval-rmse:3.810812\n",
      "[795]\ttrain-rmse:3.082146\tval-rmse:3.810783\n",
      "[796]\ttrain-rmse:3.081739\tval-rmse:3.810762\n",
      "[797]\ttrain-rmse:3.081058\tval-rmse:3.810737\n",
      "[798]\ttrain-rmse:3.080800\tval-rmse:3.810735\n",
      "[799]\ttrain-rmse:3.080440\tval-rmse:3.810723\n",
      "[800]\ttrain-rmse:3.079911\tval-rmse:3.810710\n",
      "[801]\ttrain-rmse:3.079304\tval-rmse:3.810701\n",
      "[802]\ttrain-rmse:3.078876\tval-rmse:3.810702\n",
      "[803]\ttrain-rmse:3.078555\tval-rmse:3.810661\n",
      "[804]\ttrain-rmse:3.077915\tval-rmse:3.810675\n",
      "[805]\ttrain-rmse:3.077599\tval-rmse:3.810649\n",
      "[806]\ttrain-rmse:3.076867\tval-rmse:3.810630\n",
      "[807]\ttrain-rmse:3.076236\tval-rmse:3.810667\n",
      "[808]\ttrain-rmse:3.075723\tval-rmse:3.810614\n",
      "[809]\ttrain-rmse:3.074907\tval-rmse:3.810562\n",
      "[810]\ttrain-rmse:3.073985\tval-rmse:3.810451\n",
      "[811]\ttrain-rmse:3.073671\tval-rmse:3.810406\n",
      "[812]\ttrain-rmse:3.073232\tval-rmse:3.810386\n",
      "[813]\ttrain-rmse:3.072811\tval-rmse:3.810392\n",
      "[814]\ttrain-rmse:3.072510\tval-rmse:3.810380\n",
      "[815]\ttrain-rmse:3.072148\tval-rmse:3.810393\n",
      "[816]\ttrain-rmse:3.071631\tval-rmse:3.810374\n",
      "[817]\ttrain-rmse:3.071225\tval-rmse:3.810338\n",
      "[818]\ttrain-rmse:3.070624\tval-rmse:3.810336\n",
      "[819]\ttrain-rmse:3.070084\tval-rmse:3.810346\n",
      "[820]\ttrain-rmse:3.069634\tval-rmse:3.810299\n",
      "[821]\ttrain-rmse:3.069132\tval-rmse:3.810298\n",
      "[822]\ttrain-rmse:3.068549\tval-rmse:3.810319\n",
      "[823]\ttrain-rmse:3.067799\tval-rmse:3.810266\n",
      "[824]\ttrain-rmse:3.067621\tval-rmse:3.810292\n",
      "[825]\ttrain-rmse:3.067149\tval-rmse:3.810282\n",
      "[826]\ttrain-rmse:3.066565\tval-rmse:3.810282\n",
      "[827]\ttrain-rmse:3.065659\tval-rmse:3.810253\n",
      "[828]\ttrain-rmse:3.065206\tval-rmse:3.810258\n",
      "[829]\ttrain-rmse:3.064806\tval-rmse:3.810255\n",
      "[830]\ttrain-rmse:3.064095\tval-rmse:3.810257\n",
      "[831]\ttrain-rmse:3.063743\tval-rmse:3.810270\n",
      "[832]\ttrain-rmse:3.063493\tval-rmse:3.810274\n",
      "[833]\ttrain-rmse:3.062795\tval-rmse:3.810187\n",
      "[834]\ttrain-rmse:3.062169\tval-rmse:3.810201\n",
      "[835]\ttrain-rmse:3.061798\tval-rmse:3.810211\n",
      "[836]\ttrain-rmse:3.061460\tval-rmse:3.810182\n",
      "[837]\ttrain-rmse:3.061235\tval-rmse:3.810150\n",
      "[838]\ttrain-rmse:3.060713\tval-rmse:3.810091\n",
      "[839]\ttrain-rmse:3.060087\tval-rmse:3.810069\n",
      "[840]\ttrain-rmse:3.059837\tval-rmse:3.810100\n",
      "[841]\ttrain-rmse:3.059592\tval-rmse:3.810072\n",
      "[842]\ttrain-rmse:3.059258\tval-rmse:3.810067\n",
      "[843]\ttrain-rmse:3.058610\tval-rmse:3.810059\n",
      "[844]\ttrain-rmse:3.058270\tval-rmse:3.810058\n",
      "[845]\ttrain-rmse:3.057961\tval-rmse:3.810105\n",
      "[846]\ttrain-rmse:3.057214\tval-rmse:3.810082\n",
      "[847]\ttrain-rmse:3.056711\tval-rmse:3.810081\n",
      "[848]\ttrain-rmse:3.056230\tval-rmse:3.810130\n",
      "[849]\ttrain-rmse:3.055938\tval-rmse:3.810127\n",
      "[850]\ttrain-rmse:3.055481\tval-rmse:3.810106\n",
      "[851]\ttrain-rmse:3.055251\tval-rmse:3.810114\n",
      "[852]\ttrain-rmse:3.054554\tval-rmse:3.810046\n",
      "[853]\ttrain-rmse:3.053895\tval-rmse:3.810025\n",
      "[854]\ttrain-rmse:3.053371\tval-rmse:3.810010\n",
      "[855]\ttrain-rmse:3.052714\tval-rmse:3.809959\n",
      "[856]\ttrain-rmse:3.052418\tval-rmse:3.809938\n",
      "[857]\ttrain-rmse:3.051799\tval-rmse:3.809929\n",
      "[858]\ttrain-rmse:3.051127\tval-rmse:3.809958\n",
      "[859]\ttrain-rmse:3.050786\tval-rmse:3.809938\n",
      "[860]\ttrain-rmse:3.049902\tval-rmse:3.809948\n",
      "[861]\ttrain-rmse:3.049448\tval-rmse:3.809969\n",
      "[862]\ttrain-rmse:3.048921\tval-rmse:3.809965\n",
      "[863]\ttrain-rmse:3.048481\tval-rmse:3.809938\n",
      "[864]\ttrain-rmse:3.048009\tval-rmse:3.809957\n",
      "[865]\ttrain-rmse:3.047184\tval-rmse:3.809852\n",
      "[866]\ttrain-rmse:3.046389\tval-rmse:3.809851\n",
      "[867]\ttrain-rmse:3.045969\tval-rmse:3.809865\n",
      "[868]\ttrain-rmse:3.045810\tval-rmse:3.809850\n",
      "[869]\ttrain-rmse:3.045173\tval-rmse:3.809847\n",
      "[870]\ttrain-rmse:3.044846\tval-rmse:3.809833\n",
      "[871]\ttrain-rmse:3.044530\tval-rmse:3.809859\n",
      "[872]\ttrain-rmse:3.044233\tval-rmse:3.809880\n",
      "[873]\ttrain-rmse:3.043780\tval-rmse:3.809837\n",
      "[874]\ttrain-rmse:3.043216\tval-rmse:3.809839\n",
      "[875]\ttrain-rmse:3.042741\tval-rmse:3.809850\n",
      "[876]\ttrain-rmse:3.042454\tval-rmse:3.809846\n",
      "[877]\ttrain-rmse:3.042073\tval-rmse:3.809812\n",
      "[878]\ttrain-rmse:3.041706\tval-rmse:3.809788\n",
      "[879]\ttrain-rmse:3.041106\tval-rmse:3.809729\n",
      "[880]\ttrain-rmse:3.040617\tval-rmse:3.809768\n",
      "[881]\ttrain-rmse:3.040157\tval-rmse:3.809729\n",
      "[882]\ttrain-rmse:3.039770\tval-rmse:3.809707\n",
      "[883]\ttrain-rmse:3.039689\tval-rmse:3.809700\n",
      "[884]\ttrain-rmse:3.039359\tval-rmse:3.809703\n",
      "[885]\ttrain-rmse:3.039142\tval-rmse:3.809710\n",
      "[886]\ttrain-rmse:3.038535\tval-rmse:3.809719\n",
      "[887]\ttrain-rmse:3.038035\tval-rmse:3.809738\n",
      "[888]\ttrain-rmse:3.037626\tval-rmse:3.809744\n",
      "[889]\ttrain-rmse:3.037190\tval-rmse:3.809737\n",
      "[890]\ttrain-rmse:3.036801\tval-rmse:3.809726\n",
      "[891]\ttrain-rmse:3.036584\tval-rmse:3.809725\n",
      "[892]\ttrain-rmse:3.036052\tval-rmse:3.809717\n",
      "[893]\ttrain-rmse:3.035789\tval-rmse:3.809736\n",
      "[894]\ttrain-rmse:3.035375\tval-rmse:3.809790\n",
      "[895]\ttrain-rmse:3.034913\tval-rmse:3.809793\n",
      "[896]\ttrain-rmse:3.034330\tval-rmse:3.809782\n",
      "[897]\ttrain-rmse:3.033691\tval-rmse:3.809744\n",
      "[898]\ttrain-rmse:3.032969\tval-rmse:3.809716\n",
      "[899]\ttrain-rmse:3.032596\tval-rmse:3.809760\n",
      "[900]\ttrain-rmse:3.032280\tval-rmse:3.809765\n",
      "[901]\ttrain-rmse:3.032157\tval-rmse:3.809750\n",
      "[902]\ttrain-rmse:3.031656\tval-rmse:3.809706\n",
      "[903]\ttrain-rmse:3.030966\tval-rmse:3.809690\n",
      "[904]\ttrain-rmse:3.030617\tval-rmse:3.809654\n",
      "[905]\ttrain-rmse:3.030249\tval-rmse:3.809635\n",
      "[906]\ttrain-rmse:3.029769\tval-rmse:3.809646\n",
      "[907]\ttrain-rmse:3.029299\tval-rmse:3.809555\n",
      "[908]\ttrain-rmse:3.028907\tval-rmse:3.809515\n",
      "[909]\ttrain-rmse:3.028241\tval-rmse:3.809526\n",
      "[910]\ttrain-rmse:3.027443\tval-rmse:3.809471\n",
      "[911]\ttrain-rmse:3.026942\tval-rmse:3.809474\n",
      "[912]\ttrain-rmse:3.026558\tval-rmse:3.809462\n",
      "[913]\ttrain-rmse:3.026148\tval-rmse:3.809417\n",
      "[914]\ttrain-rmse:3.025528\tval-rmse:3.809403\n",
      "[915]\ttrain-rmse:3.025214\tval-rmse:3.809411\n",
      "[916]\ttrain-rmse:3.025026\tval-rmse:3.809391\n",
      "[917]\ttrain-rmse:3.024784\tval-rmse:3.809396\n",
      "[918]\ttrain-rmse:3.024298\tval-rmse:3.809357\n",
      "[919]\ttrain-rmse:3.023546\tval-rmse:3.809339\n",
      "[920]\ttrain-rmse:3.022667\tval-rmse:3.809313\n",
      "[921]\ttrain-rmse:3.022391\tval-rmse:3.809318\n",
      "[922]\ttrain-rmse:3.021869\tval-rmse:3.809255\n",
      "[923]\ttrain-rmse:3.021211\tval-rmse:3.809236\n",
      "[924]\ttrain-rmse:3.020895\tval-rmse:3.809231\n",
      "[925]\ttrain-rmse:3.020425\tval-rmse:3.809201\n",
      "[926]\ttrain-rmse:3.019942\tval-rmse:3.809156\n",
      "[927]\ttrain-rmse:3.019395\tval-rmse:3.809126\n",
      "[928]\ttrain-rmse:3.018947\tval-rmse:3.809083\n",
      "[929]\ttrain-rmse:3.018086\tval-rmse:3.809025\n",
      "[930]\ttrain-rmse:3.017829\tval-rmse:3.808997\n",
      "[931]\ttrain-rmse:3.017489\tval-rmse:3.809007\n",
      "[932]\ttrain-rmse:3.017100\tval-rmse:3.808965\n",
      "[933]\ttrain-rmse:3.016748\tval-rmse:3.808964\n",
      "[934]\ttrain-rmse:3.016597\tval-rmse:3.808949\n",
      "[935]\ttrain-rmse:3.016301\tval-rmse:3.808942\n",
      "[936]\ttrain-rmse:3.015589\tval-rmse:3.808942\n",
      "[937]\ttrain-rmse:3.015261\tval-rmse:3.808912\n",
      "[938]\ttrain-rmse:3.014999\tval-rmse:3.808977\n",
      "[939]\ttrain-rmse:3.014548\tval-rmse:3.808949\n",
      "[940]\ttrain-rmse:3.014144\tval-rmse:3.808973\n",
      "[941]\ttrain-rmse:3.013606\tval-rmse:3.808859\n",
      "[942]\ttrain-rmse:3.012758\tval-rmse:3.808814\n",
      "[943]\ttrain-rmse:3.012164\tval-rmse:3.808764\n",
      "[944]\ttrain-rmse:3.011527\tval-rmse:3.808674\n",
      "[945]\ttrain-rmse:3.011209\tval-rmse:3.808706\n",
      "[946]\ttrain-rmse:3.010860\tval-rmse:3.808720\n",
      "[947]\ttrain-rmse:3.010470\tval-rmse:3.808735\n",
      "[948]\ttrain-rmse:3.010171\tval-rmse:3.808744\n",
      "[949]\ttrain-rmse:3.009940\tval-rmse:3.808767\n",
      "[950]\ttrain-rmse:3.009551\tval-rmse:3.808815\n",
      "[951]\ttrain-rmse:3.009156\tval-rmse:3.808808\n",
      "[952]\ttrain-rmse:3.008960\tval-rmse:3.808776\n",
      "[953]\ttrain-rmse:3.008441\tval-rmse:3.808748\n",
      "[954]\ttrain-rmse:3.008177\tval-rmse:3.808729\n",
      "[955]\ttrain-rmse:3.008056\tval-rmse:3.808736\n",
      "[956]\ttrain-rmse:3.007636\tval-rmse:3.808752\n",
      "[957]\ttrain-rmse:3.007267\tval-rmse:3.808710\n",
      "[958]\ttrain-rmse:3.006891\tval-rmse:3.808712\n",
      "[959]\ttrain-rmse:3.006436\tval-rmse:3.808709\n",
      "[960]\ttrain-rmse:3.006101\tval-rmse:3.808694\n",
      "[961]\ttrain-rmse:3.005786\tval-rmse:3.808689\n",
      "[962]\ttrain-rmse:3.005319\tval-rmse:3.808698\n",
      "[963]\ttrain-rmse:3.005003\tval-rmse:3.808689\n",
      "[964]\ttrain-rmse:3.004579\tval-rmse:3.808673\n",
      "[965]\ttrain-rmse:3.004173\tval-rmse:3.808644\n",
      "[966]\ttrain-rmse:3.003901\tval-rmse:3.808599\n",
      "[967]\ttrain-rmse:3.003572\tval-rmse:3.808608\n",
      "[968]\ttrain-rmse:3.003419\tval-rmse:3.808575\n",
      "[969]\ttrain-rmse:3.003037\tval-rmse:3.808550\n",
      "[970]\ttrain-rmse:3.002434\tval-rmse:3.808550\n",
      "[971]\ttrain-rmse:3.002043\tval-rmse:3.808573\n",
      "[972]\ttrain-rmse:3.001284\tval-rmse:3.808574\n",
      "[973]\ttrain-rmse:3.001142\tval-rmse:3.808577\n",
      "[974]\ttrain-rmse:3.000646\tval-rmse:3.808609\n",
      "[975]\ttrain-rmse:3.000197\tval-rmse:3.808598\n",
      "[976]\ttrain-rmse:2.999773\tval-rmse:3.808622\n",
      "[977]\ttrain-rmse:2.999428\tval-rmse:3.808647\n",
      "[978]\ttrain-rmse:2.999014\tval-rmse:3.808612\n",
      "[979]\ttrain-rmse:2.998638\tval-rmse:3.808611\n",
      "[980]\ttrain-rmse:2.998049\tval-rmse:3.808660\n",
      "[981]\ttrain-rmse:2.997674\tval-rmse:3.808638\n",
      "[982]\ttrain-rmse:2.997344\tval-rmse:3.808654\n",
      "[983]\ttrain-rmse:2.996928\tval-rmse:3.808577\n",
      "[984]\ttrain-rmse:2.996463\tval-rmse:3.808563\n",
      "[985]\ttrain-rmse:2.995972\tval-rmse:3.808572\n",
      "[986]\ttrain-rmse:2.995490\tval-rmse:3.808524\n",
      "[987]\ttrain-rmse:2.995036\tval-rmse:3.808522\n",
      "[988]\ttrain-rmse:2.994802\tval-rmse:3.808486\n",
      "[989]\ttrain-rmse:2.994236\tval-rmse:3.808443\n",
      "[990]\ttrain-rmse:2.993547\tval-rmse:3.808428\n",
      "[991]\ttrain-rmse:2.993060\tval-rmse:3.808443\n",
      "[992]\ttrain-rmse:2.992546\tval-rmse:3.808366\n",
      "[993]\ttrain-rmse:2.992320\tval-rmse:3.808363\n",
      "[994]\ttrain-rmse:2.991950\tval-rmse:3.808368\n",
      "[995]\ttrain-rmse:2.991695\tval-rmse:3.808334\n",
      "[996]\ttrain-rmse:2.991254\tval-rmse:3.808329\n",
      "[997]\ttrain-rmse:2.990795\tval-rmse:3.808315\n",
      "[998]\ttrain-rmse:2.990457\tval-rmse:3.808302\n",
      "[999]\ttrain-rmse:2.990028\tval-rmse:3.808332\n",
      "[1000]\ttrain-rmse:2.989916\tval-rmse:3.808331\n",
      "[1001]\ttrain-rmse:2.989542\tval-rmse:3.808287\n",
      "[1002]\ttrain-rmse:2.989332\tval-rmse:3.808256\n",
      "[1003]\ttrain-rmse:2.989156\tval-rmse:3.808250\n",
      "[1004]\ttrain-rmse:2.988852\tval-rmse:3.808254\n",
      "[1005]\ttrain-rmse:2.988541\tval-rmse:3.808245\n",
      "[1006]\ttrain-rmse:2.988027\tval-rmse:3.808264\n",
      "[1007]\ttrain-rmse:2.987817\tval-rmse:3.808240\n",
      "[1008]\ttrain-rmse:2.987626\tval-rmse:3.808280\n",
      "[1009]\ttrain-rmse:2.987358\tval-rmse:3.808241\n",
      "[1010]\ttrain-rmse:2.987030\tval-rmse:3.808207\n",
      "[1011]\ttrain-rmse:2.986416\tval-rmse:3.808237\n",
      "[1012]\ttrain-rmse:2.985939\tval-rmse:3.808251\n",
      "[1013]\ttrain-rmse:2.985609\tval-rmse:3.808226\n",
      "[1014]\ttrain-rmse:2.985347\tval-rmse:3.808237\n",
      "[1015]\ttrain-rmse:2.985177\tval-rmse:3.808210\n",
      "[1016]\ttrain-rmse:2.984714\tval-rmse:3.808226\n",
      "[1017]\ttrain-rmse:2.984346\tval-rmse:3.808242\n",
      "[1018]\ttrain-rmse:2.983974\tval-rmse:3.808229\n",
      "[1019]\ttrain-rmse:2.983706\tval-rmse:3.808218\n",
      "[1020]\ttrain-rmse:2.983468\tval-rmse:3.808197\n",
      "[1021]\ttrain-rmse:2.983202\tval-rmse:3.808167\n",
      "[1022]\ttrain-rmse:2.982773\tval-rmse:3.808206\n",
      "[1023]\ttrain-rmse:2.982416\tval-rmse:3.808203\n",
      "[1024]\ttrain-rmse:2.981959\tval-rmse:3.808199\n",
      "[1025]\ttrain-rmse:2.981662\tval-rmse:3.808208\n",
      "[1026]\ttrain-rmse:2.981432\tval-rmse:3.808212\n",
      "[1027]\ttrain-rmse:2.981025\tval-rmse:3.808245\n",
      "[1028]\ttrain-rmse:2.980603\tval-rmse:3.808227\n",
      "[1029]\ttrain-rmse:2.980191\tval-rmse:3.808233\n",
      "[1030]\ttrain-rmse:2.979910\tval-rmse:3.808219\n",
      "[1031]\ttrain-rmse:2.979269\tval-rmse:3.808187\n",
      "[1032]\ttrain-rmse:2.978965\tval-rmse:3.808174\n",
      "[1033]\ttrain-rmse:2.978583\tval-rmse:3.808194\n",
      "[1034]\ttrain-rmse:2.978174\tval-rmse:3.808239\n",
      "[1035]\ttrain-rmse:2.977987\tval-rmse:3.808265\n",
      "[1036]\ttrain-rmse:2.977581\tval-rmse:3.808267\n",
      "[1037]\ttrain-rmse:2.977232\tval-rmse:3.808256\n",
      "[1038]\ttrain-rmse:2.976871\tval-rmse:3.808239\n",
      "[1039]\ttrain-rmse:2.976332\tval-rmse:3.808320\n",
      "[1040]\ttrain-rmse:2.975678\tval-rmse:3.808357\n",
      "[1041]\ttrain-rmse:2.974751\tval-rmse:3.808336\n",
      "[1042]\ttrain-rmse:2.974234\tval-rmse:3.808364\n",
      "[1043]\ttrain-rmse:2.973901\tval-rmse:3.808314\n",
      "[1044]\ttrain-rmse:2.973455\tval-rmse:3.808314\n",
      "[1045]\ttrain-rmse:2.972819\tval-rmse:3.808317\n",
      "[1046]\ttrain-rmse:2.972585\tval-rmse:3.808327\n",
      "[1047]\ttrain-rmse:2.972070\tval-rmse:3.808354\n",
      "[1048]\ttrain-rmse:2.971644\tval-rmse:3.808346\n",
      "[1049]\ttrain-rmse:2.971201\tval-rmse:3.808241\n",
      "[1050]\ttrain-rmse:2.970885\tval-rmse:3.808197\n",
      "[1051]\ttrain-rmse:2.970582\tval-rmse:3.808225\n",
      "[1052]\ttrain-rmse:2.970214\tval-rmse:3.808233\n",
      "[1053]\ttrain-rmse:2.969980\tval-rmse:3.808217\n",
      "[1054]\ttrain-rmse:2.969807\tval-rmse:3.808204\n",
      "[1055]\ttrain-rmse:2.969417\tval-rmse:3.808233\n",
      "[1056]\ttrain-rmse:2.969025\tval-rmse:3.808213\n",
      "[1057]\ttrain-rmse:2.968603\tval-rmse:3.808187\n",
      "[1058]\ttrain-rmse:2.967978\tval-rmse:3.808157\n",
      "[1059]\ttrain-rmse:2.967793\tval-rmse:3.808191\n",
      "[1060]\ttrain-rmse:2.967494\tval-rmse:3.808200\n",
      "[1061]\ttrain-rmse:2.967000\tval-rmse:3.808202\n",
      "[1062]\ttrain-rmse:2.966419\tval-rmse:3.808250\n",
      "[1063]\ttrain-rmse:2.966196\tval-rmse:3.808267\n",
      "[1064]\ttrain-rmse:2.965891\tval-rmse:3.808235\n",
      "[1065]\ttrain-rmse:2.965558\tval-rmse:3.808222\n",
      "[1066]\ttrain-rmse:2.965271\tval-rmse:3.808198\n",
      "[1067]\ttrain-rmse:2.964972\tval-rmse:3.808182\n",
      "[1068]\ttrain-rmse:2.964556\tval-rmse:3.808205\n",
      "[1069]\ttrain-rmse:2.964185\tval-rmse:3.808179\n",
      "[1070]\ttrain-rmse:2.963986\tval-rmse:3.808177\n",
      "[1071]\ttrain-rmse:2.963345\tval-rmse:3.808166\n",
      "[1072]\ttrain-rmse:2.963130\tval-rmse:3.808188\n",
      "[1073]\ttrain-rmse:2.962911\tval-rmse:3.808197\n",
      "[1074]\ttrain-rmse:2.962207\tval-rmse:3.808170\n",
      "[1075]\ttrain-rmse:2.961726\tval-rmse:3.808195\n",
      "[1076]\ttrain-rmse:2.961113\tval-rmse:3.808202\n",
      "[1077]\ttrain-rmse:2.960427\tval-rmse:3.808202\n",
      "[1078]\ttrain-rmse:2.959852\tval-rmse:3.808219\n",
      "[1079]\ttrain-rmse:2.959577\tval-rmse:3.808231\n",
      "[1080]\ttrain-rmse:2.959278\tval-rmse:3.808232\n",
      "[1081]\ttrain-rmse:2.958809\tval-rmse:3.808292\n",
      "[1082]\ttrain-rmse:2.958212\tval-rmse:3.808280\n",
      "[1083]\ttrain-rmse:2.957677\tval-rmse:3.808228\n",
      "[1084]\ttrain-rmse:2.957327\tval-rmse:3.808237\n",
      "[1085]\ttrain-rmse:2.956737\tval-rmse:3.808208\n",
      "[1086]\ttrain-rmse:2.956497\tval-rmse:3.808200\n",
      "[1087]\ttrain-rmse:2.956213\tval-rmse:3.808211\n",
      "[1088]\ttrain-rmse:2.956063\tval-rmse:3.808222\n",
      "[1089]\ttrain-rmse:2.955742\tval-rmse:3.808221\n",
      "[1090]\ttrain-rmse:2.955153\tval-rmse:3.808257\n",
      "[1091]\ttrain-rmse:2.954612\tval-rmse:3.808212\n",
      "[1092]\ttrain-rmse:2.954054\tval-rmse:3.808185\n",
      "[1093]\ttrain-rmse:2.953698\tval-rmse:3.808197\n",
      "[1094]\ttrain-rmse:2.953344\tval-rmse:3.808207\n",
      "[1095]\ttrain-rmse:2.952946\tval-rmse:3.808222\n",
      "[1096]\ttrain-rmse:2.952549\tval-rmse:3.808225\n",
      "[1097]\ttrain-rmse:2.952142\tval-rmse:3.808214\n",
      "[1098]\ttrain-rmse:2.951778\tval-rmse:3.808224\n",
      "[1099]\ttrain-rmse:2.951149\tval-rmse:3.808226\n",
      "[1100]\ttrain-rmse:2.950688\tval-rmse:3.808198\n",
      "[1101]\ttrain-rmse:2.950301\tval-rmse:3.808190\n",
      "[1102]\ttrain-rmse:2.949752\tval-rmse:3.808161\n",
      "[1103]\ttrain-rmse:2.949046\tval-rmse:3.808120\n",
      "[1104]\ttrain-rmse:2.948652\tval-rmse:3.808132\n",
      "[1105]\ttrain-rmse:2.948376\tval-rmse:3.808092\n",
      "[1106]\ttrain-rmse:2.947950\tval-rmse:3.808115\n",
      "[1107]\ttrain-rmse:2.947819\tval-rmse:3.808110\n",
      "[1108]\ttrain-rmse:2.947654\tval-rmse:3.808090\n",
      "[1109]\ttrain-rmse:2.947160\tval-rmse:3.808118\n",
      "[1110]\ttrain-rmse:2.946860\tval-rmse:3.808112\n",
      "[1111]\ttrain-rmse:2.946373\tval-rmse:3.808086\n",
      "[1112]\ttrain-rmse:2.945681\tval-rmse:3.808059\n",
      "[1113]\ttrain-rmse:2.945076\tval-rmse:3.808110\n",
      "[1114]\ttrain-rmse:2.944607\tval-rmse:3.808064\n",
      "[1115]\ttrain-rmse:2.944136\tval-rmse:3.808109\n",
      "[1116]\ttrain-rmse:2.943793\tval-rmse:3.808111\n",
      "[1117]\ttrain-rmse:2.943172\tval-rmse:3.808116\n",
      "[1118]\ttrain-rmse:2.942828\tval-rmse:3.808089\n",
      "[1119]\ttrain-rmse:2.942420\tval-rmse:3.808106\n",
      "[1120]\ttrain-rmse:2.942197\tval-rmse:3.808112\n",
      "[1121]\ttrain-rmse:2.942009\tval-rmse:3.808144\n",
      "[1122]\ttrain-rmse:2.941298\tval-rmse:3.808200\n",
      "[1123]\ttrain-rmse:2.941060\tval-rmse:3.808177\n",
      "[1124]\ttrain-rmse:2.940395\tval-rmse:3.808235\n",
      "[1125]\ttrain-rmse:2.940146\tval-rmse:3.808252\n",
      "[1126]\ttrain-rmse:2.939683\tval-rmse:3.808235\n",
      "[1127]\ttrain-rmse:2.939474\tval-rmse:3.808237\n",
      "[1128]\ttrain-rmse:2.938642\tval-rmse:3.808176\n",
      "[1129]\ttrain-rmse:2.938202\tval-rmse:3.808106\n",
      "[1130]\ttrain-rmse:2.938006\tval-rmse:3.808071\n",
      "[1131]\ttrain-rmse:2.937684\tval-rmse:3.808044\n",
      "[1132]\ttrain-rmse:2.937210\tval-rmse:3.808012\n",
      "[1133]\ttrain-rmse:2.937000\tval-rmse:3.807989\n",
      "[1134]\ttrain-rmse:2.936626\tval-rmse:3.807988\n",
      "[1135]\ttrain-rmse:2.936301\tval-rmse:3.808037\n",
      "[1136]\ttrain-rmse:2.935792\tval-rmse:3.808059\n",
      "[1137]\ttrain-rmse:2.935614\tval-rmse:3.808063\n",
      "[1138]\ttrain-rmse:2.935110\tval-rmse:3.808011\n",
      "[1139]\ttrain-rmse:2.934791\tval-rmse:3.807994\n",
      "[1140]\ttrain-rmse:2.934351\tval-rmse:3.807973\n",
      "[1141]\ttrain-rmse:2.933867\tval-rmse:3.807963\n",
      "[1142]\ttrain-rmse:2.933304\tval-rmse:3.807971\n",
      "[1143]\ttrain-rmse:2.933078\tval-rmse:3.807993\n",
      "[1144]\ttrain-rmse:2.932871\tval-rmse:3.808016\n",
      "[1145]\ttrain-rmse:2.932556\tval-rmse:3.808038\n",
      "[1146]\ttrain-rmse:2.932218\tval-rmse:3.807991\n",
      "[1147]\ttrain-rmse:2.931828\tval-rmse:3.808004\n",
      "[1148]\ttrain-rmse:2.931411\tval-rmse:3.807994\n",
      "[1149]\ttrain-rmse:2.930947\tval-rmse:3.808005\n",
      "[1150]\ttrain-rmse:2.930771\tval-rmse:3.807982\n",
      "[1151]\ttrain-rmse:2.930482\tval-rmse:3.807968\n",
      "[1152]\ttrain-rmse:2.929926\tval-rmse:3.807985\n",
      "[1153]\ttrain-rmse:2.929604\tval-rmse:3.808011\n",
      "[1154]\ttrain-rmse:2.929355\tval-rmse:3.808015\n",
      "[1155]\ttrain-rmse:2.928801\tval-rmse:3.807997\n",
      "[1156]\ttrain-rmse:2.928456\tval-rmse:3.807993\n",
      "[1157]\ttrain-rmse:2.928162\tval-rmse:3.807961\n",
      "[1158]\ttrain-rmse:2.927571\tval-rmse:3.807949\n",
      "[1159]\ttrain-rmse:2.927388\tval-rmse:3.807993\n",
      "[1160]\ttrain-rmse:2.926703\tval-rmse:3.807977\n",
      "[1161]\ttrain-rmse:2.926170\tval-rmse:3.808021\n",
      "[1162]\ttrain-rmse:2.925881\tval-rmse:3.808014\n",
      "[1163]\ttrain-rmse:2.925403\tval-rmse:3.807969\n",
      "[1164]\ttrain-rmse:2.925015\tval-rmse:3.807938\n",
      "[1165]\ttrain-rmse:2.924674\tval-rmse:3.807888\n",
      "[1166]\ttrain-rmse:2.924455\tval-rmse:3.807904\n",
      "[1167]\ttrain-rmse:2.924154\tval-rmse:3.807905\n",
      "[1168]\ttrain-rmse:2.923762\tval-rmse:3.807883\n",
      "[1169]\ttrain-rmse:2.923597\tval-rmse:3.807870\n",
      "[1170]\ttrain-rmse:2.923339\tval-rmse:3.807846\n",
      "[1171]\ttrain-rmse:2.922941\tval-rmse:3.807870\n",
      "[1172]\ttrain-rmse:2.922537\tval-rmse:3.807899\n",
      "[1173]\ttrain-rmse:2.922010\tval-rmse:3.807896\n",
      "[1174]\ttrain-rmse:2.921882\tval-rmse:3.807901\n",
      "[1175]\ttrain-rmse:2.921530\tval-rmse:3.807902\n",
      "[1176]\ttrain-rmse:2.921307\tval-rmse:3.807908\n",
      "[1177]\ttrain-rmse:2.920862\tval-rmse:3.807906\n",
      "[1178]\ttrain-rmse:2.920494\tval-rmse:3.807899\n",
      "[1179]\ttrain-rmse:2.920017\tval-rmse:3.807873\n",
      "[1180]\ttrain-rmse:2.919734\tval-rmse:3.807902\n",
      "[1181]\ttrain-rmse:2.919350\tval-rmse:3.807950\n",
      "[1182]\ttrain-rmse:2.919050\tval-rmse:3.807962\n",
      "[1183]\ttrain-rmse:2.918860\tval-rmse:3.807961\n",
      "[1184]\ttrain-rmse:2.918712\tval-rmse:3.807973\n",
      "[1185]\ttrain-rmse:2.918427\tval-rmse:3.807958\n",
      "[1186]\ttrain-rmse:2.917880\tval-rmse:3.807989\n",
      "[1187]\ttrain-rmse:2.917360\tval-rmse:3.807939\n",
      "[1188]\ttrain-rmse:2.916711\tval-rmse:3.807903\n",
      "[1189]\ttrain-rmse:2.916364\tval-rmse:3.807875\n",
      "[1190]\ttrain-rmse:2.915868\tval-rmse:3.807890\n",
      "[1191]\ttrain-rmse:2.915623\tval-rmse:3.807864\n",
      "[1192]\ttrain-rmse:2.915367\tval-rmse:3.807849\n",
      "[1193]\ttrain-rmse:2.915045\tval-rmse:3.807894\n",
      "[1194]\ttrain-rmse:2.914438\tval-rmse:3.807921\n",
      "[1195]\ttrain-rmse:2.914308\tval-rmse:3.807915\n",
      "[1196]\ttrain-rmse:2.913941\tval-rmse:3.807959\n",
      "[1197]\ttrain-rmse:2.913548\tval-rmse:3.807984\n",
      "[1198]\ttrain-rmse:2.913229\tval-rmse:3.807956\n",
      "[1199]\ttrain-rmse:2.912870\tval-rmse:3.807918\n",
      "[1200]\ttrain-rmse:2.912547\tval-rmse:3.807934\n",
      "[1201]\ttrain-rmse:2.912306\tval-rmse:3.807944\n",
      "[1202]\ttrain-rmse:2.911912\tval-rmse:3.807975\n",
      "[1203]\ttrain-rmse:2.911506\tval-rmse:3.807994\n",
      "[1204]\ttrain-rmse:2.911231\tval-rmse:3.807984\n",
      "[1205]\ttrain-rmse:2.910657\tval-rmse:3.808033\n",
      "[1206]\ttrain-rmse:2.910227\tval-rmse:3.808054\n",
      "[1207]\ttrain-rmse:2.910110\tval-rmse:3.808025\n",
      "[1208]\ttrain-rmse:2.909488\tval-rmse:3.808013\n",
      "[1209]\ttrain-rmse:2.908859\tval-rmse:3.808018\n",
      "[1210]\ttrain-rmse:2.908341\tval-rmse:3.807987\n",
      "[1211]\ttrain-rmse:2.908211\tval-rmse:3.807964\n",
      "[1212]\ttrain-rmse:2.907983\tval-rmse:3.807962\n",
      "[1213]\ttrain-rmse:2.907665\tval-rmse:3.807993\n",
      "[1214]\ttrain-rmse:2.907183\tval-rmse:3.807945\n",
      "[1215]\ttrain-rmse:2.906945\tval-rmse:3.807949\n",
      "[1216]\ttrain-rmse:2.906330\tval-rmse:3.807889\n",
      "[1217]\ttrain-rmse:2.905775\tval-rmse:3.807897\n",
      "[1218]\ttrain-rmse:2.905542\tval-rmse:3.807939\n",
      "[1219]\ttrain-rmse:2.905325\tval-rmse:3.807948\n",
      "[1220]\ttrain-rmse:2.904842\tval-rmse:3.807925\n",
      "[1221]\ttrain-rmse:2.904616\tval-rmse:3.807897\n",
      "[1222]\ttrain-rmse:2.904194\tval-rmse:3.807806\n",
      "[1223]\ttrain-rmse:2.903692\tval-rmse:3.807833\n",
      "[1224]\ttrain-rmse:2.903284\tval-rmse:3.807878\n",
      "[1225]\ttrain-rmse:2.902961\tval-rmse:3.807883\n",
      "[1226]\ttrain-rmse:2.902757\tval-rmse:3.807918\n",
      "[1227]\ttrain-rmse:2.902298\tval-rmse:3.807891\n",
      "[1228]\ttrain-rmse:2.902132\tval-rmse:3.807883\n",
      "[1229]\ttrain-rmse:2.901425\tval-rmse:3.807928\n",
      "[1230]\ttrain-rmse:2.900949\tval-rmse:3.807914\n",
      "[1231]\ttrain-rmse:2.900412\tval-rmse:3.807926\n",
      "[1232]\ttrain-rmse:2.899886\tval-rmse:3.807935\n",
      "[1233]\ttrain-rmse:2.899525\tval-rmse:3.807933\n",
      "[1234]\ttrain-rmse:2.899262\tval-rmse:3.807936\n",
      "[1235]\ttrain-rmse:2.898980\tval-rmse:3.807984\n",
      "[1236]\ttrain-rmse:2.898632\tval-rmse:3.808007\n",
      "[1237]\ttrain-rmse:2.898381\tval-rmse:3.808021\n",
      "[1238]\ttrain-rmse:2.898198\tval-rmse:3.808021\n",
      "[1239]\ttrain-rmse:2.897381\tval-rmse:3.808014\n",
      "[1240]\ttrain-rmse:2.896817\tval-rmse:3.808049\n",
      "[1241]\ttrain-rmse:2.896425\tval-rmse:3.808066\n",
      "[1242]\ttrain-rmse:2.895733\tval-rmse:3.808164\n",
      "[1243]\ttrain-rmse:2.895238\tval-rmse:3.808127\n",
      "[1244]\ttrain-rmse:2.894713\tval-rmse:3.808058\n",
      "[1245]\ttrain-rmse:2.894526\tval-rmse:3.808062\n",
      "[1246]\ttrain-rmse:2.894213\tval-rmse:3.808070\n",
      "[1247]\ttrain-rmse:2.893709\tval-rmse:3.808103\n",
      "[1248]\ttrain-rmse:2.893645\tval-rmse:3.808102\n",
      "[1249]\ttrain-rmse:2.893012\tval-rmse:3.808093\n",
      "[1250]\ttrain-rmse:2.892798\tval-rmse:3.808104\n",
      "[1251]\ttrain-rmse:2.892195\tval-rmse:3.808084\n",
      "[1252]\ttrain-rmse:2.891705\tval-rmse:3.808127\n",
      "[1253]\ttrain-rmse:2.891560\tval-rmse:3.808113\n",
      "[1254]\ttrain-rmse:2.891044\tval-rmse:3.808097\n",
      "[1255]\ttrain-rmse:2.890507\tval-rmse:3.808075\n",
      "[1256]\ttrain-rmse:2.890043\tval-rmse:3.808108\n",
      "[1257]\ttrain-rmse:2.889639\tval-rmse:3.808103\n",
      "[1258]\ttrain-rmse:2.889180\tval-rmse:3.808072\n",
      "[1259]\ttrain-rmse:2.888789\tval-rmse:3.808054\n",
      "[1260]\ttrain-rmse:2.888519\tval-rmse:3.808020\n",
      "[1261]\ttrain-rmse:2.888222\tval-rmse:3.808038\n",
      "[1262]\ttrain-rmse:2.887745\tval-rmse:3.807986\n",
      "[1263]\ttrain-rmse:2.887523\tval-rmse:3.807965\n",
      "[1264]\ttrain-rmse:2.887341\tval-rmse:3.807964\n",
      "[1265]\ttrain-rmse:2.887119\tval-rmse:3.807972\n",
      "[1266]\ttrain-rmse:2.886878\tval-rmse:3.807982\n",
      "[1267]\ttrain-rmse:2.886485\tval-rmse:3.807985\n",
      "[1268]\ttrain-rmse:2.885873\tval-rmse:3.808028\n",
      "[1269]\ttrain-rmse:2.885376\tval-rmse:3.808016\n",
      "[1270]\ttrain-rmse:2.885121\tval-rmse:3.807996\n",
      "[1271]\ttrain-rmse:2.884682\tval-rmse:3.808008\n",
      "[1272]\ttrain-rmse:2.884396\tval-rmse:3.808003\n",
      "[1273]\ttrain-rmse:2.884003\tval-rmse:3.807997\n",
      "[1274]\ttrain-rmse:2.883425\tval-rmse:3.807963\n",
      "[1275]\ttrain-rmse:2.883177\tval-rmse:3.807997\n",
      "[1276]\ttrain-rmse:2.882937\tval-rmse:3.808048\n",
      "[1277]\ttrain-rmse:2.882772\tval-rmse:3.808049\n",
      "[1278]\ttrain-rmse:2.882269\tval-rmse:3.808065\n",
      "[1279]\ttrain-rmse:2.881845\tval-rmse:3.808115\n",
      "[1280]\ttrain-rmse:2.881544\tval-rmse:3.808178\n",
      "[1281]\ttrain-rmse:2.881292\tval-rmse:3.808170\n",
      "[1282]\ttrain-rmse:2.880691\tval-rmse:3.808194\n",
      "[1283]\ttrain-rmse:2.880252\tval-rmse:3.808208\n",
      "[1284]\ttrain-rmse:2.879934\tval-rmse:3.808253\n",
      "[1285]\ttrain-rmse:2.879638\tval-rmse:3.808300\n",
      "[1286]\ttrain-rmse:2.879247\tval-rmse:3.808352\n",
      "[1287]\ttrain-rmse:2.878988\tval-rmse:3.808372\n",
      "[1288]\ttrain-rmse:2.878676\tval-rmse:3.808378\n",
      "[1289]\ttrain-rmse:2.878466\tval-rmse:3.808358\n",
      "[1290]\ttrain-rmse:2.878177\tval-rmse:3.808364\n",
      "[1291]\ttrain-rmse:2.877728\tval-rmse:3.808346\n",
      "[1292]\ttrain-rmse:2.877535\tval-rmse:3.808351\n",
      "[1293]\ttrain-rmse:2.877346\tval-rmse:3.808320\n",
      "[1294]\ttrain-rmse:2.876985\tval-rmse:3.808307\n",
      "[1295]\ttrain-rmse:2.876654\tval-rmse:3.808273\n",
      "[1296]\ttrain-rmse:2.876398\tval-rmse:3.808299\n",
      "[1297]\ttrain-rmse:2.875959\tval-rmse:3.808257\n",
      "[1298]\ttrain-rmse:2.875676\tval-rmse:3.808256\n",
      "[1299]\ttrain-rmse:2.875573\tval-rmse:3.808273\n",
      "[1300]\ttrain-rmse:2.875262\tval-rmse:3.808266\n",
      "[1301]\ttrain-rmse:2.875054\tval-rmse:3.808287\n",
      "[1302]\ttrain-rmse:2.874592\tval-rmse:3.808295\n",
      "[1303]\ttrain-rmse:2.874345\tval-rmse:3.808274\n",
      "[1304]\ttrain-rmse:2.873931\tval-rmse:3.808228\n",
      "[1305]\ttrain-rmse:2.873329\tval-rmse:3.808202\n",
      "[1306]\ttrain-rmse:2.873135\tval-rmse:3.808179\n",
      "[1307]\ttrain-rmse:2.872813\tval-rmse:3.808190\n",
      "[1308]\ttrain-rmse:2.872265\tval-rmse:3.808179\n",
      "[1309]\ttrain-rmse:2.872041\tval-rmse:3.808175\n",
      "[1310]\ttrain-rmse:2.871775\tval-rmse:3.808190\n",
      "[1311]\ttrain-rmse:2.871242\tval-rmse:3.808221\n",
      "[1312]\ttrain-rmse:2.870998\tval-rmse:3.808211\n",
      "[1313]\ttrain-rmse:2.870667\tval-rmse:3.808196\n",
      "[1314]\ttrain-rmse:2.870166\tval-rmse:3.808191\n",
      "[1315]\ttrain-rmse:2.869721\tval-rmse:3.808161\n",
      "[1316]\ttrain-rmse:2.869408\tval-rmse:3.808111\n",
      "[1317]\ttrain-rmse:2.869198\tval-rmse:3.808107\n",
      "[1318]\ttrain-rmse:2.868873\tval-rmse:3.808129\n",
      "[1319]\ttrain-rmse:2.868546\tval-rmse:3.808186\n",
      "[1320]\ttrain-rmse:2.868405\tval-rmse:3.808184\n",
      "[1321]\ttrain-rmse:2.868059\tval-rmse:3.808199\n",
      "[1322]\ttrain-rmse:2.867783\tval-rmse:3.808218\n",
      "[1323]\ttrain-rmse:2.867343\tval-rmse:3.808227\n",
      "[1324]\ttrain-rmse:2.866907\tval-rmse:3.808275\n",
      "[1325]\ttrain-rmse:2.866617\tval-rmse:3.808229\n",
      "[1326]\ttrain-rmse:2.866211\tval-rmse:3.808223\n",
      "[1327]\ttrain-rmse:2.865974\tval-rmse:3.808241\n",
      "[1328]\ttrain-rmse:2.865561\tval-rmse:3.808274\n",
      "[1329]\ttrain-rmse:2.865222\tval-rmse:3.808284\n",
      "[1330]\ttrain-rmse:2.864813\tval-rmse:3.808247\n",
      "[1331]\ttrain-rmse:2.864393\tval-rmse:3.808282\n",
      "[1332]\ttrain-rmse:2.863958\tval-rmse:3.808319\n",
      "[1333]\ttrain-rmse:2.863766\tval-rmse:3.808336\n",
      "[1334]\ttrain-rmse:2.863161\tval-rmse:3.808414\n",
      "[1335]\ttrain-rmse:2.862891\tval-rmse:3.808395\n",
      "[1336]\ttrain-rmse:2.862620\tval-rmse:3.808433\n",
      "[1337]\ttrain-rmse:2.862462\tval-rmse:3.808433\n",
      "[1338]\ttrain-rmse:2.862190\tval-rmse:3.808404\n",
      "[1339]\ttrain-rmse:2.861920\tval-rmse:3.808343\n",
      "[1340]\ttrain-rmse:2.861490\tval-rmse:3.808346\n",
      "[1341]\ttrain-rmse:2.860906\tval-rmse:3.808392\n",
      "[1342]\ttrain-rmse:2.860822\tval-rmse:3.808370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.378967905928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[1222]\ttrain-rmse:2.904194\tval-rmse:3.807806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.005\n",
    "params[\"min_child_weight\"] = 6\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "# params[\"max_delta_step\"] = 10\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 9 #7\n",
    "params[\"scale_pos_weight\"] = 1.0\n",
    "# params[\"gamma\"] = 0\n",
    "\n",
    "\n",
    "plst = list(params.items())\n",
    "\n",
    "max_rounds = 2000\n",
    "# xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(y_binned, n_folds=3,\n",
    "                      shuffle=True,\n",
    "                      random_state=np.random.randint(0,100))\n",
    "train, valid= iter(skf).next()\n",
    "# X_train_k = X_train[train]\n",
    "# X_valid_k = X_train[valid]\n",
    "# X_train_k = X_fa40_train[train]\n",
    "# X_valid_k = X_fa40_train[valid]\n",
    "X_train_k = np.c_[X_fa40_train, X_train][train]\n",
    "X_valid_k = np.c_[X_fa40_train, X_train][valid]\n",
    "\n",
    "y_train_k = y_train[train]\n",
    "y_valid_k = y_train[valid]\n",
    "\n",
    "\n",
    "#create a train and validation dmatrices \n",
    "xgtrain = xgb.DMatrix(X_train_k, label=y_train_k)\n",
    "xgval = xgb.DMatrix(X_valid_k, label=y_valid_k)\n",
    "\n",
    "#train using early stopping and predict\n",
    "watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "model = xgb.train(plst, xgtrain, max_rounds, watchlist, early_stopping_rounds=120)\n",
    "\n",
    "preds_val = model.predict(xgval)\n",
    "\n",
    "s = metrics.normalized_gini(y_valid_k, preds_val)\n",
    "print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train\n",
    "# [912]\ttrain-rmse:3.202105\tval-rmse:3.772708\n",
    "\n",
    "# X_fa10\n",
    "# [708]\ttrain-rmse:3.526680\tval-rmse:3.874051\n",
    "\n",
    "# np.c_[X_fa10_train, X_train]\n",
    "# [986]\ttrain-rmse:3.106901\tval-rmse:3.801840\n",
    "\n",
    "# X_fa40_train\n",
    "# [1071]\ttrain-rmse:3.103334\tval-rmse:3.839233\n",
    "\n",
    "#np.c_[X_fa40_train, X_train]\n",
    "#[1222]\ttrain-rmse:2.904194\tval-rmse:3.807806\n",
    "\n",
    "\n",
    "\n",
    "model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until val error hasn't decreased in 30 rounds.\n",
      "[0]\ttrain-merror:0.603477\tval-merror:0.628669\n",
      "[1]\ttrain-merror:0.595741\tval-merror:0.627140\n",
      "[2]\ttrain-merror:0.593329\tval-merror:0.625846\n",
      "[3]\ttrain-merror:0.590652\tval-merror:0.626081\n",
      "[4]\ttrain-merror:0.586240\tval-merror:0.625257\n",
      "[5]\ttrain-merror:0.581328\tval-merror:0.624551\n",
      "[6]\ttrain-merror:0.580005\tval-merror:0.623375\n",
      "[7]\ttrain-merror:0.579181\tval-merror:0.622493\n",
      "[8]\ttrain-merror:0.575828\tval-merror:0.623022\n",
      "[9]\ttrain-merror:0.571975\tval-merror:0.623610\n",
      "[10]\ttrain-merror:0.569739\tval-merror:0.622963\n",
      "[11]\ttrain-merror:0.566739\tval-merror:0.623963\n",
      "[12]\ttrain-merror:0.564504\tval-merror:0.622787\n",
      "[13]\ttrain-merror:0.560915\tval-merror:0.623610\n",
      "[14]\ttrain-merror:0.557445\tval-merror:0.623375\n",
      "[15]\ttrain-merror:0.554680\tval-merror:0.623846\n",
      "[16]\ttrain-merror:0.552591\tval-merror:0.624610\n",
      "[17]\ttrain-merror:0.551003\tval-merror:0.623728\n",
      "[18]\ttrain-merror:0.548621\tval-merror:0.625316\n",
      "[19]\ttrain-merror:0.545826\tval-merror:0.624551\n",
      "[20]\ttrain-merror:0.543355\tval-merror:0.625257\n",
      "[21]\ttrain-merror:0.541032\tval-merror:0.625493\n",
      "[22]\ttrain-merror:0.538855\tval-merror:0.625375\n",
      "[23]\ttrain-merror:0.536473\tval-merror:0.625728\n",
      "[24]\ttrain-merror:0.535031\tval-merror:0.625022\n",
      "[25]\ttrain-merror:0.531825\tval-merror:0.623904\n",
      "[26]\ttrain-merror:0.530796\tval-merror:0.623846\n",
      "[27]\ttrain-merror:0.528825\tval-merror:0.623669\n",
      "[28]\ttrain-merror:0.527266\tval-merror:0.623316\n",
      "[29]\ttrain-merror:0.524766\tval-merror:0.623846\n",
      "[30]\ttrain-merror:0.521884\tval-merror:0.623963\n",
      "[31]\ttrain-merror:0.519913\tval-merror:0.624316\n",
      "[32]\ttrain-merror:0.518178\tval-merror:0.623904\n",
      "[33]\ttrain-merror:0.514766\tval-merror:0.623552\n",
      "[34]\ttrain-merror:0.513883\tval-merror:0.622669\n",
      "[35]\ttrain-merror:0.511177\tval-merror:0.622199\n",
      "[36]\ttrain-merror:0.508736\tval-merror:0.623022\n",
      "[37]\ttrain-merror:0.507000\tval-merror:0.621728\n",
      "[38]\ttrain-merror:0.504677\tval-merror:0.622258\n",
      "[39]\ttrain-merror:0.503177\tval-merror:0.621493\n",
      "[40]\ttrain-merror:0.501765\tval-merror:0.621375\n",
      "[41]\ttrain-merror:0.500000\tval-merror:0.621963\n",
      "[42]\ttrain-merror:0.498294\tval-merror:0.621905\n",
      "[43]\ttrain-merror:0.495970\tval-merror:0.621434\n",
      "[44]\ttrain-merror:0.494323\tval-merror:0.622787\n",
      "[45]\ttrain-merror:0.491794\tval-merror:0.622905\n",
      "[46]\ttrain-merror:0.490999\tval-merror:0.622905\n",
      "[47]\ttrain-merror:0.488235\tval-merror:0.623257\n",
      "[48]\ttrain-merror:0.485470\tval-merror:0.623434\n",
      "[49]\ttrain-merror:0.482146\tval-merror:0.623081\n",
      "[50]\ttrain-merror:0.480911\tval-merror:0.622493\n",
      "[51]\ttrain-merror:0.478028\tval-merror:0.623022\n",
      "[52]\ttrain-merror:0.476646\tval-merror:0.622493\n",
      "[53]\ttrain-merror:0.475322\tval-merror:0.623552\n",
      "[54]\ttrain-merror:0.473851\tval-merror:0.624434\n",
      "[55]\ttrain-merror:0.471087\tval-merror:0.625199\n",
      "[56]\ttrain-merror:0.469969\tval-merror:0.625904\n",
      "[57]\ttrain-merror:0.468086\tval-merror:0.625140\n",
      "[58]\ttrain-merror:0.465792\tval-merror:0.624904\n",
      "[59]\ttrain-merror:0.463763\tval-merror:0.624257\n",
      "[60]\ttrain-merror:0.461527\tval-merror:0.623728\n",
      "[61]\ttrain-merror:0.459880\tval-merror:0.623963\n",
      "[62]\ttrain-merror:0.459262\tval-merror:0.624434\n",
      "[63]\ttrain-merror:0.457556\tval-merror:0.624316\n",
      "[64]\ttrain-merror:0.455792\tval-merror:0.625434\n",
      "[65]\ttrain-merror:0.453850\tval-merror:0.626022\n",
      "[66]\ttrain-merror:0.452938\tval-merror:0.625728\n",
      "[67]\ttrain-merror:0.451468\tval-merror:0.626610\n",
      "[68]\ttrain-merror:0.450938\tval-merror:0.626728\n",
      "[69]\ttrain-merror:0.448497\tval-merror:0.626022\n",
      "[70]\ttrain-merror:0.446379\tval-merror:0.625846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.191175929337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[40]\ttrain-merror:0.501765\tval-merror:0.621375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gbm categorical\n",
    "\n",
    "params = {}\n",
    "params[\"objective\"] = \"multi:softmax\"\n",
    "params[\"num_class\"] = len(np.unique(y_binned))\n",
    "params[\"eta\"] = 0.3\n",
    "params[\"min_child_weight\"] = 6\n",
    "params[\"subsample\"] = 1.0\n",
    "params[\"colsample_bytree\"] = 1.0\n",
    "# params[\"max_delta_step\"] = 10\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 6 #7\n",
    "# params[\"gamma\"] = 0\n",
    "\n",
    "\n",
    "plst = list(params.items())\n",
    "\n",
    "max_rounds = 2000\n",
    "# xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(y_binned, n_folds=3,\n",
    "                      shuffle=True,\n",
    "                      random_state=np.random.randint(0,100))\n",
    "train, valid= iter(skf).next()\n",
    "X_train_k = X_train[train]\n",
    "X_valid_k = X_train[valid]\n",
    "y_train_k = (y_binned-1)[train]\n",
    "y_valid_k = (y_binned-1)[valid]\n",
    "\n",
    "\n",
    "# create a train and validation dmatrices \n",
    "xgtrain = xgb.DMatrix(X_train_k, label=y_train_k)\n",
    "xgval = xgb.DMatrix(X_valid_k, label=y_valid_k)\n",
    "\n",
    "# train using early stopping and predict\n",
    "watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "model = xgb.train(plst, xgtrain, max_rounds, watchlist, early_stopping_rounds=30)\n",
    "\n",
    "preds_val = model.predict(xgval)\n",
    "\n",
    "s = metrics.normalized_gini(y_valid_k, preds_val)\n",
    "print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_binned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "reload(rpfnn)\n",
    "clf = rpfnn.rpfnn(leaf_size=50, no_trees=10, num_neighbors=10)\n",
    "\n",
    "param_dist = {\"leaf_size\": sp_randint(20, 500),\n",
    "              \"no_trees\": sp_randint(10, 400),\n",
    "              \"num_neighbors\": sp_randint(1, 200),\n",
    "             }\n",
    "\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   cv=skf,\n",
    "                                   scoring=metrics.gini_score,\n",
    "                                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print random_search.best_score_\n",
    "print random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Param Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "k = 3\n",
    "skf = StratifiedKFold(y_binned, n_folds=k,\n",
    "                          shuffle=True,\n",
    "                          random_state=np.random.randint(0,100))\n",
    "\n",
    "# clf = RandomForestRegressor()\n",
    "clf = ExtraTreesRegressor()\n",
    "\n",
    "\n",
    "param_dist = {\"n_estimators\": sp_randint(10, 200),\n",
    "              \"max_features\": ['auto', 'sqrt', 'log2'],\n",
    "              \"max_depth\": [None] + range(1, 15),\n",
    "              \"min_samples_split\": sp_randint(2, 10),\n",
    "              \"min_samples_leaf\": sp_randint(1, 10),\n",
    "              \"min_weight_fraction_leaf\": sp_uniform(0,0.5),\n",
    "              \"max_leaf_nodes\": [None] + range(2, 20),\n",
    "              \"bootstrap\": [True, False],\n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "n_iter_search = 256\n",
    "random_search = RandomizedSearchCV(clf, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   cv=skf,\n",
    "                                   scoring=metrics.gini_score,\n",
    "                                   n_jobs=-1,\n",
    "                                   verbose=2\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "toc = time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Time:', toc\n",
    "print random_search.best_score_\n",
    "print random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF:\n",
    "Time: 4913.59136486\n",
    "0.348998319125\n",
    "{'max_leaf_nodes': None, 'bootstrap': False, 'min_samples_leaf': 8, 'n_estimators': 135, 'min_samples_split': 8, 'min_weight_fraction_leaf': 0.1810718592717216, 'max_features': 'sqrt', 'max_depth': 12}\n",
    "\n",
    "ET:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tic = time()\n",
    "stack.extra_data['y_binned'] = y_binned\n",
    "stack.fit(X_train, y_train)\n",
    "toc = time() - tic\n",
    "\n",
    "print toc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = stack.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_pd = pd.DataFrame({\"Id\": test_ind, \"Hazard\": preds})\n",
    "preds_pd = preds_pd.set_index('Id')\n",
    "preds_pd.to_csv('submissions/stack_random_crap.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
