{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/afs/ee.cooper.edu/user/t/a/tam8/documents/ml_misc/semi_supervised/')\n",
    "import coreg\n",
    "reload(coreg)\n",
    "import trireg\n",
    "reload(trireg)\n",
    "sys.path.append('/afs/ee.cooper.edu/user/t/a/tam8/documents/ml_misc/ordinal/')\n",
    "import simple\n",
    "reload(simple)\n",
    "sys.path.append('/afs/ee.cooper.edu/user/t/a/tam8/documents/ml_misc/ensemble/')\n",
    "import stacking\n",
    "reload(stacking)\n",
    "\n",
    "sys.path.append('/afs/ee.cooper.edu/user/t/a/tam8/documents/ml_misc/neighbors/')\n",
    "import rpfnn\n",
    "reload(rpfnn)\n",
    "import ann\n",
    "reload(ann)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "\n",
    "import transformers as tforms\n",
    "reload(tforms)\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion, make_union\n",
    "\n",
    "import metrics\n",
    "reload(metrics)\n",
    "from sklearn.cross_validation import StratifiedKFold, train_test_split\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC, SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, ElasticNet, Ridge, Lasso, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier, DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import Counter\n",
    "import minirank as mr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "from pysofia.compat import RankSVM, RankSVMCV\n",
    "\n",
    "def wgmean(x, w):\n",
    "    return np.exp(np.sum(w*np.log(x), axis=1) / np.sum(w, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_pd  = pd.read_pickle('saved/train_pd_enc.p')\n",
    "test_pd  = pd.read_pickle('saved/test_pd_enc.p')\n",
    "labels = pd.read_pickle('saved/labels.p')\n",
    "test_ind = pickle.load(open('saved/test_ind.p'))\n",
    "y_binned = np.load('saved/y_binned.npy')\n",
    "\n",
    "fi = np.load('saved/feature_importances.npy')\n",
    "y_binned[y_binned==6] = 5\n",
    "\n",
    "drop_cols = ['T1_V10', 'T1_V13', 'T2_V7', 'T2_V10']\n",
    "# drop_cols = train_pd.columns[fi < 0.01]\n",
    "\n",
    "\n",
    "for col in drop_cols:\n",
    "    train_pd.drop(col, axis=1, inplace=True)\n",
    "    test_pd.drop(col, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data le instead\n",
    "# train_pd  = pd.read_pickle('saved/train_pd_l_enc.p')\n",
    "# test_pd  = pd.read_pickle('saved/test_pd_l_enc.p')\n",
    "\n",
    "train_pd  = pd.read_pickle('saved/train_pd_le_and_oh_enc.p')\n",
    "test_pd  = pd.read_pickle('saved/test_pd_le_and_oh_enc.p')\n",
    "\n",
    "labels = pd.read_pickle('saved/labels.p')\n",
    "test_ind = pickle.load(open('saved/test_ind.p'))\n",
    "y_binned = np.load('saved/y_binned.npy')\n",
    "fi = np.load('saved/feature_importances.npy')\n",
    "\n",
    "y_binned[y_binned==6] = 5\n",
    "\n",
    "drop_cols = ['T1_V10', 'T1_V13', 'T2_V7', 'T2_V10']\n",
    "# drop_cols = []\n",
    "\n",
    "# drop_cols = train_pd.columns[fi < 0.01]\n",
    "\n",
    "\n",
    "for col in drop_cols:\n",
    "    train_pd.drop(col, axis=1, inplace=True)\n",
    "    test_pd.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Data binary instead\n",
    "train_pd  = pd.read_pickle('saved/train_pd_binary_enc.p')\n",
    "test_pd  = pd.read_pickle('saved/test_pd_binary_enc.p')\n",
    "labels = pd.read_pickle('saved/labels.p')\n",
    "test_ind = pickle.load(open('saved/test_ind.p'))\n",
    "y_binned = np.load('saved/y_binned.npy')\n",
    "\n",
    "y_binned[y_binned==6] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50999, 2)\n",
      "(51000, 2)\n",
      "(50999, 2)\n",
      "(51000, 2)\n"
     ]
    }
   ],
   "source": [
    "X_tsne2_26 = np.load('saved/X_tsne2_26important.npy')\n",
    "X_tsne2_26_train = X_tsne2_26[:len(train_pd), :]\n",
    "X_tsne2_26_test = X_tsne2_26[-len(test_pd):, :]\n",
    "\n",
    "X_tsne2 = np.load('saved/X_tsne2.npy')\n",
    "X_tsne2_train = X_tsne2[:len(train_pd), :]\n",
    "X_tsne2_test = X_tsne2[-len(test_pd):, :]\n",
    "\n",
    "print X_tsne2_train.shape\n",
    "print X_tsne2_test.shape\n",
    "print X_tsne2_26_train.shape\n",
    "print X_tsne2_26_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (50999,)\n",
      "X_train (50999, 125)\n",
      "X_test (51000, 125)\n",
      "X_hold 50\n",
      "5\n",
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "train = np.array(train_pd)\n",
    "test = np.array(test_pd)\n",
    "\n",
    "X_train = train.astype(float)\n",
    "X_test = test.astype(float)\n",
    "y_train = np.array(labels)\n",
    "\n",
    "try:\n",
    "    X_train = np.c_[X_train, X_tsne2_26_train]\n",
    "    X_test = np.c_[X_test, X_tsne2_26_test]\n",
    "#     X_train = X_tsne2_26_train\n",
    "#     X_test = X_tsne2_26_test\n",
    "except:\n",
    "    pass\n",
    "\n",
    "holdout = False\n",
    "if holdout:\n",
    "    X_train, X_hold, \\\n",
    "    y_train, y_hold, \\\n",
    "    y_binned, y_binned_hold \\\n",
    "    = train_test_split(\n",
    "        X_train, y_train, y_binned, \n",
    "        test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "pipe_x = make_pipeline(\n",
    "    make_union(\n",
    "        tforms.IdentityTformer(),\n",
    "#         make_pipeline(AddTformer(1), BoxCoxTformer()),\n",
    "#         AnscombeTformer(),\n",
    "    ),\n",
    "#     StandardScaler(),\n",
    ")\n",
    "pipe_y = make_pipeline(\n",
    "    tforms.IdentityTformer(),\n",
    "#     tforms.BoxCoxTformer(),\n",
    "#     tforms.LogTformer(),\n",
    "#     tforms.AnscombeTformer(),\n",
    "#     tforms.FreemanTukeyTformer(),\n",
    "#     tforms.ArcsinhTformer(),\n",
    "#     StandardScaler(),\n",
    "    \n",
    ")\n",
    "pipe_x.fit(np.r_[X_train, X_test])\n",
    "pipe_y.fit(y_train)\n",
    "\n",
    "X_train = pipe_x.transform(X_train)\n",
    "X_test = pipe_x.transform(X_test)\n",
    "try:\n",
    "    X_hold = pipe_x.transform(X_hold)\n",
    "except:\n",
    "    pass\n",
    "# y_train = pipe_y.fit_transform(y_train)\n",
    "\n",
    "# small_n = 5000\n",
    "# X_train = X_train[:small_n,:]\n",
    "# y_train = y_train[:small_n]\n",
    "# y_binned = y_binned[:small_n]\n",
    "\n",
    "print 'y_train', y_train.shape\n",
    "print 'X_train', X_train.shape\n",
    "print 'X_test', X_test.shape\n",
    "try:\n",
    "    print 'X_hold', X_hold.shape\n",
    "except:\n",
    "    pass\n",
    "print len(np.unique(y_train))\n",
    "print len(np.unique(y_binned))\n",
    "print type(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Train time: 1.404 s\tPred time: 0.295 s\tScore [0.328038698049521]\n",
      "Score avg ensemble 0.32803869805\n",
      "Fold 1 Train time: 1.411 s\tPred time: 0.292 s\tScore [0.31757442121902096]\n",
      "Score avg ensemble 0.317574421219\n",
      "Fold 2 Train time: 1.414 s\tPred time: 0.294 s\tScore [0.30003639874794225]\n",
      "Score avg ensemble 0.300036398748\n",
      "done\n",
      "Score: [ 0.31521651]\n",
      "Base Score: 0.315216506005\n",
      "lol [] nan\n"
     ]
    }
   ],
   "source": [
    "ord_gaussnb_bin = simple.SimpleOrdinalClassifier(GaussianNB(), n_jobs=-1)\n",
    "gbm = xgb.XGBRegressor(\n",
    "    objective=\"reg:linear\",\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.005,\n",
    "#     gamma=0.0,\n",
    "    max_depth=9,\n",
    "    min_child_weight=6,\n",
    "#     max_delta_step=10,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "#     scale_pos_weight=1.0,\n",
    "    base_score=0.5,\n",
    "    nthread=-1,\n",
    "    seed=np.random.randint(0,100),\n",
    "    silent=True,\n",
    ")\n",
    "\n",
    "# clfs = [RankSVM(max_iter=1000)]\n",
    "# clfs = [LinearRegression()]\n",
    "# clfs = [gbm]\n",
    "clfs = [Ridge()]\n",
    "\n",
    "\n",
    "scores = []\n",
    "scores_base = []\n",
    "lols = []\n",
    "n_reps = 1\n",
    "k = 3\n",
    "for reps in range(n_reps):\n",
    "    skf = StratifiedKFold(y_binned, n_folds=k,\n",
    "                          shuffle=True,\n",
    "                          random_state=np.random.randint(0,100))\n",
    "    for ii, (train, valid) in enumerate(skf):\n",
    "        \n",
    "        \n",
    "#         history = LossHistory()   # for keras\n",
    "        print 'Fold %d' % ii,\n",
    "        X_train_k = q[train]\n",
    "        X_valid_k = q[valid]\n",
    "        y_train_k = y_train[train]\n",
    "        y_valid_k = y_train[valid]\n",
    "        y_train_binned_k = y_binned[train]\n",
    "        y_valid_binned_k = y_binned[valid]     \n",
    "        \n",
    "        \n",
    "        X_all = np.r_[X_train_k, X_valid_k]\n",
    "        y_all = np.r_[y_train_k, np.nan*np.ones(len(y_valid_k))]\n",
    "        \n",
    "        tic = time()\n",
    "#         clf.fit(X_train_k, y_train_k)\n",
    "#         clf.fit(X_all, y_all)\n",
    "\n",
    "        for clf in clfs:\n",
    "            clf.fit(X_train_k, pipe_y.transform(y_train_k))\n",
    "#             clf.fit(X_train_k, y_train_binned_k)\n",
    "#             clf.fit(X_train_k, y_train_binned_k,\n",
    "#                    nb_epoch=60, batch_size=1024*16, )\n",
    "#             clf.fit(X_train_k, y_train_k, \n",
    "#                     base0_y=y_train_binned_k,\n",
    "#                     base1_y=y_train_binned_k,\n",
    "# #                     base2_y=y_train_binned_k,\n",
    "#                    )\n",
    "    \n",
    "    \n",
    "        \n",
    "        # Minirank\n",
    "#         w, theta = mr.ordinal_logistic_fit(X_train_k, y_train_k, verbose=False,\n",
    "#                                 solver='TNC')\n",
    "\n",
    "        \n",
    "        toc = time() - tic\n",
    "        print 'Train time: %2.3f s\\t' % toc,\n",
    "        tic = time()\n",
    "\n",
    "        \n",
    "        \n",
    "        valid_preds = [clf.predict_weighted(X_valid_k,) \n",
    "                       if hasattr(clf, 'predict_weighted') \n",
    "                       else clf.predict(X_valid_k)\n",
    "                       for clf in clfs]\n",
    "        \n",
    "#         valid_preds = [clf.predict_weighted(X_valid_k, batch_size=1024*16) \n",
    "#                if hasattr(clf, 'predict_weighted') \n",
    "#                else clf.predict(X_valid_k)\n",
    "#                for clf in clfs]\n",
    "        \n",
    "        try:\n",
    "            lol = metrics.normalized_gini(y_valid_k, \n",
    "                                          clfs[0].predict_weighted(X_valid_k, geometric=True))\n",
    "            lols.append(lol)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Minirank\n",
    "#         valid_preds = mr.ordinal_logistic_predict(w, theta, X_valid_k)\n",
    "        \n",
    "        valid_base_preds = np.mean([clf.predict(X_valid_k) for clf in clfs\n",
    "                                   ], \n",
    "                                   axis=0)\n",
    "\n",
    "        \n",
    "        score = [metrics.normalized_gini(y_valid_k, v) for v in valid_preds]\n",
    "        score_base = metrics.normalized_gini(y_valid_k, valid_base_preds)\n",
    "        \n",
    "        toc_pred = time() - tic\n",
    "        print 'Pred time: %2.3f s\\t' % toc_pred, \n",
    "        \n",
    "        print 'Score', score\n",
    "        print 'Score avg ensemble', score_base\n",
    "        scores.append(score)\n",
    "        scores_base.append(score_base)\n",
    "        \n",
    "#         break\n",
    "        \n",
    "        \n",
    "print \"done\"\n",
    "print 'Score:', np.array(scores).mean(axis=0)\n",
    "print 'Base Score:', np.array(scores_base).mean()\n",
    "print 'lol', lols, np.mean(lols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import dump_svmlight_file, load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_train, y_train, 'saved/train.svmlight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = np.r_[X_train, X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_all, np.zeros(len(X_all)), 'saved/X_all.svmlight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5081407.,  7292202.,  8151778.,  7961079.,  7241560.,  6197011.,\n",
       "         4813680.,  3009285.,  1121432.,   129566.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAECCAYAAADQEYGEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsjhAzMwsiwPEzMyyOEDMzCzL/wdFM/n8XrO/jgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb2d450a210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50999, 50)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import Popen, call, PIPE\n",
    "from sklearn.datasets import dump_svmlight_file, load_svmlight_file\n",
    "\n",
    "def call_stuff(cmd):\n",
    "    p = Popen(cmd, stdout=PIPE, stderr=PIPE)\n",
    "    while True:\n",
    "        line = p.stdout.readline()\n",
    "        if line != '':\n",
    "            print line.rstrip()\n",
    "        else:\n",
    "            break\n",
    "    output, err = p.communicate()\n",
    "    print output\n",
    "    print err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read training data from saved/X_all.svmlight: 0.72912\n",
      "Time to initialize cluster centers: 54.0341\n",
      "Objective function value for initialization: 1.70301e+07\n",
      "Time to compute objective function: 20.0283\n",
      "Time to optimize cluster centers: 15.8199\n",
      "Objective function value for training: 1.21412e+07\n",
      "Time to compute objective function: 20.2886\n",
      "\n",
      "Reading data from: saved/X_all.svmlight\n",
      "Writing model to: saved/model_sofia2000\n",
      "   Done.\n",
      "   Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_call = [\n",
    "    'sofia-kmeans',\n",
    "    '--k', str(n_clusters),\n",
    "    '--init_type', 'optimized_kmeans_pp',\n",
    "    '--opt_type', 'mini_batch_kmeans', \n",
    "    '--mini_batch_size', '100',\n",
    "    '--iterations', '800', \n",
    "    '--objective_after_init',\n",
    "    '--objective_after_training',\n",
    "    '--training_file', 'saved/X_all.svmlight',\n",
    "    '--model_out', 'saved/model_sofia%d'%n_clusters,\n",
    "]\n",
    "\n",
    "call_stuff(fit_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read training data from saved/train.svmlight: 0.331031\n",
      "\n",
      "Reading data from: saved/train.svmlight\n",
      "Writing cluster mappings to: saved/mapped2000_train.libsvm\n",
      "   Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "map_call = [\n",
    "    'sofia-kmeans',\n",
    "    '--model_in', 'saved/model_sofia%d'%n_clusters,\n",
    "    '--test_file', 'saved/train.svmlight',\n",
    "    '--cluster_mapping_out', 'saved/mapped%d_train.libsvm'%n_clusters,\n",
    "    '--cluster_mapping_type', 'rbf_kernel',\n",
    "    '--cluster_mapping_param', '0.0003',\n",
    "    '--cluster_mapping_threshold', '0.01',\n",
    "]\n",
    "\n",
    "call_stuff(map_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.save('saved/X_train_1000means.npy', q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "mapped_train, _y = load_svmlight_file('saved/mapped%d_train.libsvm'%n_clusters)\n",
    "q = mapped_train.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1628907.,   5668079.,   9077358.,  13035766.,  15994524.,\n",
       "         17308853.,  16765833.,  13896728.,   7555212.,   1066740.]),\n",
       " array([ 0.0129577 ,  0.11166193,  0.21036616,  0.30907039,  0.40777462,\n",
       "         0.50647885,  0.60518308,  0.70388731,  0.80259154,  0.90129577,  1.        ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEHCAYAAABV4gY/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXZIKZLhLUoEMd0kqkOEuSQX6f9zSzVD7it9tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f060d94a810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.hist(np.ravel(q))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
